1. 你不能仅仅查看代码就知道智能体会做什么。你必须实际运行它。
2. 我真希望我能想出"上下文工程"这个词。它实际上很好地描述了我们 LangChain 一直在做的一切。
3. 代码是告诉计算机做有用事情的相当好的方式。
4. 如果有一个方式让系统能够自我学习，那就减少了作为开发者你需要进行的迭代次数。
5. 以前人们会说"给我看看代码"，现在他们会说"给我们发个 LangSmith trace"。

---

```
📝 创作说明
嘉宾：Harrison Chase
选题方向：LangChain 联合创始人解析上下文工程如何重新定义长时程智能体开发范式
内容评分：信息密度 8/10，数据支撑 6/10，洞见深度 9/10
目标字数：2100 字
核心价值：帮助开发者理解智能体开发与传统软件开发的本质差异，以及上下文工程为何成为当前最关键的技术杠杆
```

---

## AutoGPT 点燃的那个梦，现在才真正开始兑现

2023 年，AutoGPT 在 GitHub 上的 star 数在几天内突破十万。不是因为它好用——它其实相当难用——而是因为它让人第一次看到了一个具体的可能性：让 AI 自己决定下一步做什么，然后一直做下去，直到任务完成。

那个梦想，在当时只是个演示。

Harrison Chase 是 LangChain 的联合创始人，也是过去两年里见证智能体从概念走向实用的核心人物之一。他的判断是：AutoGPT 当年失败，不是因为想法错了，而是因为两件事同时没准备好——"模型还不够好，围绕它们的脚手架（scaffolding）和 Harness 也还不够完善。"

现在这两件事都在快速收敛。而真正让智能体开始工作的，不是模型变得更聪明，而是一个此前没有名字的东西：上下文工程（Context Engineering）。

## 三层架构：模型、框架、Harness 不是一回事

在讨论智能体之前，有必要厘清一个经常被混用的概念层次。

最底层是模型。tokens 进，messages 出。这是基础设施，不是应用。

中间层是框架，比如 LangChain 本身。框架提供抽象——让你可以轻松切换不同的模型，添加工具调用、向量存储、记忆等能力，但它刻意保持中立，不替你做架构决策。

最上层是 Harness，比如 LangChain 推出的 Deep Agents。这是"开箱即用"的解决方案，带有预设的规划工具、上下文压缩机制，以及文件系统交互能力。Harrison 的描述很直接："我们实际上给它一个规划工具作为默认配置。这是相当有主见的——认为这是正确的做事方式。"

这个区分很重要。很多人在讨论"用什么框架构建智能体"时，其实混淆了这三层。框架给你自由度，Harness 给你约束，而约束本身就是一种价值——它把最佳实践固化进来，让你不用每次都从零开始做架构决策。

上下文压缩是 Harness 层最核心的能力之一。长时程智能体运行时间长，上下文窗口虽然在扩大，但终究有限。"在某个时刻你需要压缩它。"不同的 Harness 采用不同的压缩策略，这是一个仍在快速演进的研究领域。

## 智能体的三个时代，第三个才刚开始

Harrison 把智能体架构的演进划分为三个阶段，这个框架相当清晰。

第一个时代是纯文本时代。模型没有聊天界面，没有工具调用，没有推理能力。开发者能做的只是单一提示或简单的链式（chains）结构，把几个步骤串起来。

第二个时代是工具调用时代。模型开始内置工具调用能力，开发者开始尝试让模型进行规划。但模型还不够强，所以需要大量定制化的认知架构（cognitive architectures）来辅助——明确告诉模型"在这种情况下你应该走哪条路"，然后沿着预设分支执行。这个时代的特征是：开发者在用代码弥补模型的不足。

第三个时代，大约从 2024 年中期开始。Claude Code、Deep Research、Manus 相继出现，社区开始注意到一件有趣的事：这些产品在底层使用的是相同的核心架构——LLM 在一个循环中运行，自主决定下一步做什么。

但真正的差异不在循环本身，而在循环里装了什么。

"我们基本上看到它们使用相同的核心算法，但在上下文工程上做了改进……我们开始想，哦，这很有趣，这和以前很不一样。"

Harrison 坦言自己没有发明"上下文工程"这个词，但他认为这个词精准地描述了 LangChain 一直在做的事情——只是之前没有一个统一的名字。

## 智能体开发和软件开发的本质差异，不是你想的那个

很多人说"构建智能体不同于构建软件"，但说不清楚哪里不同。Harrison 给出了一个非常具体的答案。

在传统软件开发中，所有逻辑都在代码里。你可以打开代码，追踪任意一个输入会经过哪些函数、产生什么输出。逻辑是确定的、可检查的。

智能体不是这样。"应用的工作逻辑并非全部在代码里——很大一部分来自模型本身。"

这意味着什么？意味着你不能仅仅读代码就知道智能体在特定场景下会做什么。你必须运行它。

这个差异带来了一系列连锁反应。

首先是追踪（traces）的地位发生了根本变化。在传统软件开发中，追踪日志主要是生产环境出问题时才用的调试工具。在智能体开发中，追踪从第一天就是核心工具。原因很简单：智能体运行过程中会经历多个步骤，每一步都可能拉入不同的上下文。你无法预知第 14 步的上下文是什么，因为前面 13 步可能已经引入了任意内容。追踪是你唯一能看清"上下文里到底有什么"的方式。

"以前人们会说'给我看看代码'，现在他们会说'给我们发个 LangSmith trace'。"

这句话不是在做产品广告，而是在描述一个真实的工作流变化。真相的来源从代码变成了代码加追踪的组合。

其次是迭代节奏的变化。软件开发也是迭代的，但有一个关键区别：在软件中，你在发布前就知道软件会做什么。在智能体中，"你在发布前并不知道智能体会做什么。你有一个想法，但你真的不知道。"这不是在说智能体不可靠，而是在说它的行为空间更大，需要更多轮次的实际运行才能收敛到你想要的结果。

### 评估是个人类问题，不只是技术问题

传统软件的测试相对直接：写断言，跑测试，通过或失败。

智能体做的很多事情原本是人类的工作，所以评估它们必然需要引入人类判断。这是 LangSmith 中"标注队列"（annotation queues）功能的来源——允许团队成员对智能体的行为进行评判，提供自然语言反馈，而不只是二元的通过/失败。

这也是为什么数据标注这个赛道在智能体时代重新变得重要。不是因为需要更多训练数据，而是因为评估本身需要人类在循环中。

## 记忆是上下文工程的长时间尺度版本

Harrison 对记忆（memory）的定义很有意思。他不把记忆看作一个独立的模块，而是把它理解为上下文工程在更长时间尺度上的延伸。

短期上下文工程解决的是：在这次运行中，把什么信息放进上下文窗口。

记忆解决的是：跨越多次运行，把什么信息保留下来，在未来的运行中重新放进上下文。

两者的本质是一样的——决定模型在做决策时能看到什么。

更进一步，如果系统能够从自己的运行历史中学习，自动更新自己的记忆，那就意味着开发者需要手动迭代的次数会减少。"如果有一个方式让系统能够自我学习，那就减少了作为开发者你需要进行的迭代次数，让构建这类智能体变得更容易。"

这是一个还没有被充分解决的问题，但方向已经很清晰。

## 所有智能体都是编码智能体吗

Harrison 留下了一个他自己也没有答案的问题，但这个问题本身值得认真对待。

目前表现最好的长时程智能体，几乎都是编码智能体。Claude Code、Cursor、GitHub Copilot Workspace——杀手级应用都在代码领域。这不是偶然的。编码任务符合一个完美的模式：运行时间长，产出是可审查的"初稿"（first draft），人类可以在最后介入审查和修改。

但 Harrison 的问题更深：通用智能体是否就是编码智能体？

"代码是告诉计算机做有用事情的相当好的方式。"

如果你想让智能体操作文件系统、调用 API、控制浏览器、执行数据分析——这些操作最终都可以用代码来表达。代码不只是软件工程师的工具，它是智能体与计算机世界交互的通用语言。

这个问题的答案，可能会决定未来几年智能体产品的形态。

上下文工程的核心算法已经相当简单：让 LLM 在循环中运行，让它自主决定拉入什么上下文。简单到几乎让人觉得不够。但正是这个简单的循环，在被精心设计的上下文填满之后，开始做出让人惊讶的事情。
