# Context Engineering Our Way to Long-Horizon Agents: LangChain's Harrison Chase

**Platform:** YouTube
**URL:** https://www.youtube.com/watch?v=vtugjs2chdA
**Source:** Sequoia Capital

---

视频简介

在这场深度对话中，LangChain 联合创始人 Harrison Chase 分享了他对 AI 智能体发展的前沿洞察。从早期基于脚手架的智能体架构，到如今基于 Harness 的系统，Harrison 解释了为什么“上下文工程”（Context Engineering）而非仅仅是更好的模型，已经成为智能体开发的核心要素。他深入探讨了为什么编码智能体率先取得突破、文件系统在智能体工作流中的关键作用，以及构建智能体与传统软件开发的本质差异——从追踪（Traces）作为新的真相来源，到使智能体能够自我改进的记忆系统。这是一场关于 AI 智能体过去、现在与未来的思想盛宴。

详细内容

长时程智能体的崛起 [00:00 - 03:00]

Harrison Chase 开场就表达了他对智能体领域的热情。当被问及什么是长时程智能体时，他指出这实际上是智能体概念的最初愿景：让大语言模型（LLM）在一个循环中自主运行，完全自主决定该做什么。AutoGPT 之所以能够引起如此广泛的想象，正是因为它实现了这个简单而又强大的想法。

然而，早期的尝试面临两个主要问题：“模型还不够好，围绕它们的脚手架（scaffolding）和 Harness 也还不够完善。” Harrison 解释道，随着模型能力的提升，以及社区对如何构建好的 Harness 有了更深入的理解，智能体终于开始真正发挥作用。

他特别强调了编码领域的突破：“你首先会在编码领域看到这一点，我认为这是它们发展最快的领域。” 编码智能体之所以成为杀手级应用，是因为它们符合一个关键模式：运行很长时间，但产出的是一个“初稿”（first draft）——无论是代码 PR、研究报告还是客户支持分析，都可以先给智能体运行，然后由人工审查和完善。

框架、模型与 Harness 的关系 [03:00 - 07:10]

Pat Grady 询问 Harrison 如何界定 Harness 与模型的关系。Harrison 巧妙地引入了第三个概念——框架（Framework），形成了一个清晰的层次结构：

模型是最底层：tokens 进，messages 出。

框架（如 LangChain）提供抽象层：让切换模型变得容易，添加工具、向量存储、内存等抽象，但保持相对中立，不强制特定的使用方式。

Harness（如 Deep Agents）则是“开箱即用”的解决方案：带有预设的规划工具、上下文压缩机制，以及文件系统交互能力。Harrison 强调：“我们实际上给它一个规划工具作为默认配置。这是相当有主见的——认为这是正确的做事方式。”

他特别提到了上下文压缩的重要性：“这些长时程智能体运行很长时间，上下文窗口虽然越来越大，但仍然不是无限的。所以在某个时刻你需要压缩它。” 这是一个活跃的研究领域，不同的 Harness 采用不同的策略。

智能体开发的三个时代 [07:10 - 14:35]

当被问及智能体架构的主要演进节点时，Harrison 将其划分为三个时代：

第一个时代：早期的纯文本输入输出模型，甚至没有聊天界面，没有工具调用能力，也没有内容块或推理功能。开发者主要使用单一提示或简单的链式（chains）结构。

第二个时代：模型开始内置工具调用能力，尝试让模型进行思考和规划。但此时模型还不够强大，因此需要大量定制化的认知架构（cognitive architectures）来辅助——明确询问模型“在这种情况下我该做什么”，然后沿着特定的分支执行。

第三个时代（现在）：大约在今年六七月，随着 Claude Code、Deep Research、Manus 等产品的兴起，社区发现它们都在使用相同的核心架构——LLM 在循环中运行，但真正的突破在于上下文工程（Context Engineering）。Harrison 回忆道：“我们基本上看到它们使用相同的核心算法，但在上下文工程上做了改进……我们开始想，哦，这很有趣，这和以前很不一样。”

他坦言：“我真希望我能想出‘上下文工程’这个词。它实际上很好地描述了我们 LangChain 一直在做的一切，尽管我们之前不知道这个词存在。但追踪（traces）就是告诉你上下文中有什么，这太重要了。”

构建智能体 vs 构建软件 [14:35 - 23:05]

Harrison 深入探讨了构建智能体与传统软件开发的本质差异。他指出，当人们说“构建智能体不同于构建软件”时，往往流于表面。真正核心的区别在于：

在软件开发中，所有逻辑都在代码中，你可以直接查看代码就知道软件在特定场景下会做什么。而在智能体中，应用的工作逻辑并非全部在代码里——很大一部分来自模型本身。“这意味着你不能仅仅查看代码就能准确知道智能体在特定场景下会做什么。你必须实际运行它。”

这一差异带来了几个关键影响：

追踪成为核心工具：在软件开发中，追踪日志主要用于生产环境调试；而在智能体开发中，“人们从一开始就使用追踪来告诉底层发生了什么”。这是因为智能体在运行过程中会经历多个步骤，每一步都可能引入不同的上下文——你无法预知第 14 步的上下文是什么，因为前面 13 步可能拉入了任意内容。

真相来源的转变：对于软件，真相在代码中；对于智能体，真相是代码和追踪的结合。追踪成为测试的起点、团队协作的焦点。“以前人们会说‘给我看看代码’，现在他们会说‘给我们发个 LangSmith trace’。”

更加迭代的开发过程：虽然软件开发也是迭代的，但有一个关键区别——在软件中，你在发布前就知道软件会做什么；而在智能体中，“你在发布前并不知道智能体会做什么。你有一个想法，但你真的不知道。”因此需要更多轮次的迭代才能使其准确运行。

评估与人机协作 [23:05 - 28:30]

Harrison 进一步阐述了智能体评估的挑战。传统软件可以通过程序化的测试和断言来评估，但智能体做的很多事情原本是人类的工作，因此评估它们需要引入人类判断。

这正是 LangSmith 试图解决的问题——如何让人们对追踪进行标注和反馈。他提到了数据标注创业公司的兴起，以及 LangSmith 中的“标注队列”（annotation cues）功能，允许团队成员对智能体的行为进行评判，甚至提供自然语言反馈：“这是好的，这是不好的，应该这样做。”

这种将人类判断融入评估流程的方式，对于改进智能体至关重要。因为智能体的行为具有非确定性，传统的自动化测试无法捕捉所有细微之处，人类的专业判断成为不可或缺的环节。

记忆与自我改进 [28:30 - 结束】

访谈最后，Harrison 强调了记忆（memory）在智能体发展中的关键作用。他指出，记忆本质上也是一种上下文工程——只是发生在更长的时间尺度上。

“如果有一个方式让系统能够自我学习，那就减少了作为开发者你需要进行的迭代次数，让构建这类智能体变得更容易。” 这与构建智能体需要大量迭代的特性相辅相成：记忆系统可以记录过去的交互和反馈，使智能体能够自我改进，而不需要开发者不断手动调整系统提示。

关于未来，Harrison 认为核心算法——让 LLM 在循环中运行并自主决定拉入什么上下文——已经相当简单且通用。“我觉得会有大量围绕它的上下文工程技巧。也许其中一部分是把上下文工程本身交给 LLM，就像 Anthropic 做的那样。也许另一部分只是拉入新类型的上下文。”

他特别好奇的是，目前这些 Harness 大多是编码专用的，但通用智能体是否就是编码智能体？“代码是告诉计算机做有用事情的相当好的方式。” 这个问题——是否所有智能体都是编码智能体——是 LangChain 团队正在深入思考的核心问题之一。

