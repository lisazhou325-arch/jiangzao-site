# State of AI in 2026: LLMs, Coding, Scaling Laws, China, Agents, GPUs, AGI | Lex Fridman Podcast #490

**Platform:** youtube
**URL:** https://www.youtube.com/watch?v=EV7WhVT270Q
**Duration:** 4:25:13
**Published:** 2026-02-21

---

以下是一段对话 关于人工智能领域的最新进展 情报，包括一些 激动人心的技术突破和 人工智能领域在过去一段时间里取得的发展 过去一年以及部分 我们认为可能会发生一些有趣的事情 即将到来的一年。有时确实会这样 技术性很强，但我们确实努力做到 确保它仍然对人们开放 在场外，却从未愚蠢 把它放下来。这是莫大的荣幸， 能够做这种事，我感到非常荣幸。 与我最喜欢的两个人一起录制的节目 在人工智能领域，塞巴斯蒂安·拉什卡 以及内森·兰伯特。它们都非常受欢迎。 受人尊敬的机器学习研究人员 以及碰巧也是工程师的人 优秀的沟通者、教育家、作家 以及推特用户泄露信息。 塞巴斯蒂安是两本书的作者。 强烈推荐给初学者和 专家们也持相同观点。首先是建造一个大型 从零开始构建语言模型 从零开始构建推理模型。我真的 相信机器学习计算机 科学世界是学习的最佳途径， 理解事物就是创造事物。 从零开始。 内森是训练后的负责人。 艾伦人工智能研究所和作者 关于强化的权威著作 从人类反馈中学习。 他们俩的Exac账户都很棒。 很棒的子堆栈，Sebastian 有课程 Nathan 在 YouTube 上有一个播客节目， 每个人都应该严格遵守所有规定。 那些。这是 Lex Freedman 的播客。 为了支持它。请查看我们的 描述中的赞助商，你 您还可以找到联系我的链接，向我提问 提出问题、获得反馈等等。和 亲爱的朋友们，现在，这位是塞巴斯蒂安。 拉什卡和内森·兰伯特。所以，我认为 嗯，一个可以用来观察一切的实用镜头 这就是所谓的“深层探索”。 深潜时刻。这件事大约发生在 一年前，也就是2025年1月，当时 公开市值中国公司深潜 发布了 Deepseek R1，呃，我想 可以说，这让所有人都感到惊讶。 接近或达到最先进水平 据称性能大幅下降 计算成本要低得多，而且从那时起…… 时至今日，人工智能竞赛已经取得了巨大的成功。 无论是在研究层面还是其他方面，都令人难以置信 产品层面目前就是这样。 加速。我们来讨论一下这些吧。 今天，或许我们可以从一些事情开始。 如果可以的话，我们问一些比较刺激的问题。呃，他是谁？ 在国际赛场上取得胜利？ 你会说它是一系列公司吗？ 在中国或中国的公司集合 美国？还有塞巴斯蒂安、内森 很高兴见到你们。呃，所以 塞巴斯蒂安，你觉得谁会赢？ 嗯，所以“赢”这个概念非常宽泛…… 了解术语。我想说，你提到过 深潜时刻，我确实认为 DeepSeek 绝对胜出 那些从事开放工作的人们的内心 体重模型，因为它们共享这些 作为开放模型。嗯，我觉得获胜是有的。 它具有多种时间尺度。我们有 今天我们有明年，10年后我们有 年。我确信的一件事是： 嗯，我不认为现在到2026年会是这样。 任何公司都会愿意这样做。 比如说，拥有某种技术 其他公司都无法获得这种资源。而那 主要是因为研究人员 频繁更换工作、更换实验室 它们会旋转。所以我认为不会有。 在技术方面成为明显的赢家 使用权。不过，我确实认为会有 区别因素将是 预算和硬件限制。所以，我 别以为这些想法会…… 专有的，但方式或资源 实施这些措施需要这些，因此 我目前没看到有人会全盘接受。 赢家通吃的情景 目前还看不到。 内森，你怎么看？你看 各个实验室投入的精力各不相同，具体包括哪些方面。 他们正在尝试这样做，我认为…… 确定我们何时处于这个时间点 正在录制。炒作结束了 Anthropics Cloud Opus 4.5 模型已经 简直疯了，我的意思是…… 我过去用过它，也用它搭建过一些东西。 几周时间，就快要…… 感觉有点像…… 就炒作而言，这是个梗。而且它很友善 很有趣，因为这一切都很自然。 如果我们回到几个月前， 我们可以在备注中看到发布日期。 随着谷歌的 Gemini 3 发布， 看起来像是 营销和令人惊艳的效果 那次释放量非常高。但后来 11月底，克劳德作品4.5号 发布后，热度持续攀升。 但双子星3号是在它之前发射的。而且它 感觉好像人们并不真正 多谈论这件事。即使当 事情一出来，大家都说：“这……” 嗯，现在是双子座重新夺回某种地位的时刻了。 谷歌在人工智能领域的结构性优势。 双子座3号是一款非常棒的模型，而且 还在用。就有点像 分化程度较低。我同意 塞巴斯蒂安，你到底在说什么？ 所有这些都像创意空间一样非常 流动，但文化人类学是 以在代码上下注而闻名 云端代码这方面进展顺利。 对他们来说，现在就是这样。所以我认为即使 如果想法能够非常自由地涌现，那就太好了。 这其中的瓶颈在于人类的努力 以及组织的文化类型 人类学似乎至少在 呈现得最为井然有序。是 这算是一个优势，如果他们能保持下去的话。 这样做了一段时间。但另一方面 另一方面，有很多不祥之兆。 来自中国的技术，那里有办法 比Deep Seek多得多的实验室。如此深 Seek在中国掀起了一场运动。 我说的有点像查德·GBT那样 在美国发起了一场运动， 几乎所有东西都有聊天机器人。现在已经 中国有很多科技公司 释放非常强大的前沿 开放重量级模型，以至于我 可以说，Deep Seek 有点像 失去了其作为最杰出公开赛的桂冠 中国模型制作商。以及像…… 嗯，Z.AI 的 GLM 模型，以及 Miniax 的 模特，嗯，Kimmy Moonshot，尤其是在 过去几个月，已经显示出更多 明亮地。新款深海搜寻机型是 仍然非常强劲，但这有点…… 它或许会被视为一个宏大的叙事。 2025年，Deep Seek出现了， 然后这一切，它就提供了这种东西。 面向更多中国企业的平台 发布这些精彩内容 一些模型似乎拥有这种新型的 手术。所以这些模型来自这些 中国公司是公开的权重， 取决于业务发展轨迹 这些美国公司所采用的模式 这样做可能会有风险。但目前 很多人都在为人工智能软件付费。 在美国，历史上在中国也是如此。 世界其他地区的人们则不然 软件价格昂贵。 所以其中一些模型，比如 DeepSeek 之类的 他们深受人民爱戴，因为他们 均为公开组体重。你觉得要多久？ 中国公司不断发布 公开组体重级别模型？ 我认为在未来几年内，这种情况可能会持续一段时间。 就像在美国一样，没有明确的 它的商业模式。我一直 我写了一段时间关于开放模型的文章。 这些中国公司拥有 我明白了。所以我收到了一些来电 他们都很聪明，而且意识到这一点。 同样的限制条件有很多。 美国科技公司和其他IT公司 企业不会为 API 付费 订阅中国公司 安全隐患。这一直是 长期以来 嗯，科技行业的习惯以及这些人 公司随后将开放体重模型视为 具有影响和参与的能力 人工智能支出市场正在蓬勃发展 美国。他们对此非常务实。 这样做对他们和我来说都有效。 我认为政府会明白这一点。 这正在积累巨大的影响力。 国际上，就采用率而言 这项技术。所以将会有一个 有很多理由让它继续下去，但是 构建这些模型并进行 研究费用非常昂贵。所以在某些方面 我预期会出现整合，但我并不这么认为。 预计这将是2026年的故事。 将会有更多开放的模型构建者 2026 年全年数量将超过 2025 年。 许多知名人士都将出席。 中国。你本来想说什么。 嗯，是的。你提到Deep Seek亏损 它的王冠。我确实在某种程度上这么认为。 是的，但我们也必须考虑到这一点。 他们仍然，我想说略微。 前面那些，还有其他的，不是这样的。 情况变得更糟了。它和其他的一样 有人正在使用Zepseek的理念。 例如，你提到了Kimmy，同样如此。 建筑学。他们正在训练它。和 然而，我们又有了这种跳跃式发展。 他们可能会在某个时候身处那里 时间稍微好了一些，因为他们有 更新的型号。我觉得这一点 归根结底，还是因为存在以下事实： 不会有明显的赢家。就是它 就像那样，一个人 发布一些东西后，另一个就来了。 在。以及最近的。 该模型可能始终是最佳模型。 是的。我们还会看到中国人 各公司的激励机制各不相同。所以 比如DeepSeek就非常神秘。 有些创业公司就像…… Minia Maxes 和 Z.AI 等世界级企业。那些 两家公司确实已经提交了IPO申请文件。 他们试图影响西方思想。 在那里分享信息并开展大量宣传活动。所以 我不知道这些激励措施是否会奏效 某种程度上改变了模型开发，因为 Deep Seek 的建立众所周知地基于对冲策略。 为高飞资本提供资金，而我们没有。 非常清楚他们喜欢什么。我们不 知道他们使用这些模型做什么，或者是否 他们很在意这件事。 就此而言，它们是秘密的。 沟通。而且它们并非秘密 技术报告条款 描述一下他们的模型是如何运作的。他们是 这方面仍未有定论。我们应该 也想说说 Opus 45 的炒作，还有…… 呃，某种东西的那层 成为X回音室的宠儿 在推特回音室和实际 使用人数 模型。我认为这么说应该比较公平。 Chbt 和 Gemini 专注于 拥有广泛用户群体的用户只想解决问题 他们日常生活中遇到的问题以及 用户群体非常庞大。所以，关于……的炒作 编码可能无法正确表示。 实际使用。我还要说，嗯，很多 使用模式正如你所说。 品牌知名度、品牌等等 但肌肉记忆也几乎无处不在。 你知道，像 Chipd 这样的公司已经存在很久了。 长久以来，人们已经习以为常了。 使用它，感觉就像几乎 他们建议像飞轮一样使用它 其他用户和那些东西 有趣的一点是…… 例如，对 L&M 芯片进行定制 它有记忆功能，对吧？所以你 你可能订阅了服务，并且你正在使用它。 是些私事，但我不知道是否 你想在工作中也使用同样的东西。 你知道，因为那是一条界限。 区分私人生活和工作生活。如果你是 在一家公司工作，他们可能不会 允许这样做，或者你可能不希望这样做。和 我觉得这也是个很有意思的观点。 你可能拥有多个 订阅。一个很干净 代码。它与你没有任何关系 你或你的爱好相关的个人照片 里面的项目。就像…… 工作上的事，然后另一件事是…… 你的私人物品。所以我觉得那就是 还有两种不同用途的情况 案例，但这并不意味着你只有 拥有一个。我觉得是…… 未来也是多种多样的。 你认为哪款车型会赢得2025年？ 你认为哪款车型会胜出 26？我认为，从消费者的角度来看…… 聊天机器人的问题在于你是否愿意成为聊天机器人。 愿意押注双子座胜过塔蒂普特 我凭直觉感觉就像这样 这有点冒险，因为 OpenAI 有 担任现任职务，而且还有很多其他情况。 这在科技领域是有好处的，但我认为 如果你看看2025年的发展势头，就会发现它正处于上升期。 双子座一方，但他们开始行动了。 从如此低谷来看，我想愿逝者安息。 巴德和这些早期的尝试 入门指南 他们为项目提供动力，功不可没。 穿过组织混乱局面，做出 那件事发生了。但同时，也很难打赌。 反对 OpenAI，因为他们总是…… 表面上看起来很混乱，但他们其实很棒 在着陆点。我觉得就像 就我个人而言，我对……的评价褒贬不一。 GPT5，但它肯定救了他们。 隐藏线功能可以赚很多钱 路由器，大多数用户都不在 充电时间比给GPU充电更长。 成本也一样高。所以我认为这非常困难。 将我喜欢的事物剥离出来 模型与事物之间的区别 实际上将成为公众 差异化因素。 你对2026年有什么看法？谁是 你会赢吗？ 即使是这样，我还是要说几句。 有风险。我想说，我认为双子座 将继续关注乍得的进展 GPT。我认为谷歌规模的扩大是两者兼顾的时候 这些设备运行状态极其极端。 规模化，就像谷歌一样，具备这种能力 将研究和产品分开 情况好一些，因为你经常听到关于…… OpenAI 在运营上混乱不堪 追逐高影响力的事物，这本身就是一种 非常创业文化，然后是 我认为软件和企业方面都存在问题。 人类将继续取得成功 因为他们一次又一次地被设立 为此，当然还有谷歌云。 有很多选择，但我认为这 有点像双子座这个品牌名。 对他们来说，建设和发展至关重要。 谷歌云服务将继续保持良好发展势头。 但这其实更复杂一些。 在生态系统中解释这一点，因为 它与 Azure 等公司展开竞争。 而且是 AWS，而不是模型 提供方方面。所以基础设施你 认为TPU具有优势 主要原因是英伟达的利润率。 芯片技术非常强大，谷歌可以开发出来。 从上到下都完美贴合 他们的堆叠无需支付这笔费用 利润率高，而且他们已经抢占了先机 建设数据中心。所以所有这些 交货周期长的事物 高成本带来高利润， 谷歌拥有某种历史渊源。 这方面有优势。如果要…… 如果这是一种新的范式，那么它很可能 他们来自 OpenAI，在那里他们有点像…… 他们的研究部门一次又一次地 已经展现出这种能力，能够成功着陆 新的研究思路或产品。我认为 就像深入研究一样，Sora，01 思考 所有这些定义模型 很多东西都来自 OpenAI，就是这样。 这肯定是他们最重要的特质之一。 组织。所以这有点难…… 反其道而行之。但我认为很多 今年将侧重于规模和 优化可以被描述为 模型中容易实现的目标。 显然，这两者之间存在权衡取舍。 智慧和速度。这就是 查德 GPT5 一直在幕后尝试解决这个问题。 这就像人们真的想要什么一样。 情报机构是面向广大公众的，还是他们不面向公众？ 想要速度？我觉得这种类挺不错的。 实际上，或者说，可以选择添加一个切换开关。 那里。首先就我个人而言，我的意思是，首先就我个人而言。 大多数时候，当我查看时都会用到它 出了点问题，我用JGPD快速问了一下。 问题：获取我想要的信息 快速完成大多数日常任务我都用它 我认为，如今的快速模式是 自动模式在不需要手动调节的情况下相当不错。 必须明确说明你在想什么，否则你 我知道无意识之类的东西，然后我又…… 有时也非常需要专业模式 我经常会这样做，当我有…… 我把它写进JBD里，然后说嘿，做 非常彻底的检查是我的所有情况。 参考文献正确，以上都是我的想法。 没错。呃，我做过什么吗？ 格式错误？而这个数字 数字出错之类的？ 我暂时不需要那个。它是 好了，我把事情做完了。 或许可以吃顿晚饭，让它运行一会儿，然后再回来。 然后逐条检查。而且我觉得，你看， 我认为在这里很重要…… 可以选择这个选项。我会疯掉的 每次查询我都需要等待30分钟。 分钟或 10 分钟。 这就是我。 是的。 嗯，我感觉自己快要失去理智了。 请注意您使用路由器和 非思考模型。我当时就想，“哦，怎么会这样？” 你如何与你一起生活？ “接受现实吗？”这大概就是我的反应。 我最近一直在疯狂迷恋Chad BT。 嗯，从未接触过五个不思考的人。我 找到它的基调，然后是它的倾向 错误。它就像拥有更高的 出错的可能性。这其中有些是 从 Openi 发布 03 版本的时候开始， 是第一个进行这种深度建模的模型。 搜索并找到许多资源 我们会自动为您整合它们。于是，我变成了 已经习惯了。所以，我只会 当我在思考或专业时使用 GPT 5.2 查找任何类型的信息查询 为了工作，无论是论文还是其他什么 我找到的代码参考是： 就像我一样，我会经常有这样的想法 五个专业问题同时进行 每个人都在寻找一篇特定的论文或 对某个方程式或其他内容的反馈。我 我举个有趣的例子，我当时只是需要 尽快回答这个问题 旅行前我先听了播客。 嗯，我有一个本地GPU正在运行 家。我想跑一个很长的……RL 实验。而且我通常还会拔掉电源。 因为你永远不知道你是否 不在家，你不想有 插着东西。我不小心 拔掉了GP的插头。就像我妻子一样 当时我已经在车里了，感觉就像是…… “哦，糟糕。”然后，我基本上想要 尽可能快地运行一个 bash 脚本 我在实验中进行了不同的实验。 评估。我做了一件我知道自己知道的事情。 我学会了如何使用 bash 呃 界面或 bash 终端，但就此而言 我只需要10秒钟。 给我指令。 这情况确实很搞笑，不过是的。 你用的是什么？所以我做了 无需思考的最快模型。它给了我 我使用的 bash 命令是串联不同的…… 互相编写脚本，然后就是那件事。 就像你有个T字形的东西，你 想把这个路由到一个锁定文件中。顶部 我当时脑子里一片混乱，感觉很匆忙。我 我本来也可以想到这一点。 顺便问一下，我不知道是否有…… 典型案例：妻子在等候。 车。你得跑，你知道，插上插头 GPU。你需要生成一个bash脚本。 听起来像电影《碟中谍》。 不可能的。 我用的是Gemini。所以我运用了思考 所有信息都在这里，然后 双子座适合快速的事情或者我 有时可以谷歌一下，就像 它很擅长解释事物，而且我 相信它拥有这种能力 知识背景很简单 Gemini应用程序也改进了很多。 它很适合做这类事情。 然后是代码和任何类型的 我运用克劳德的哲学讨论 作品 4.5 也总是带有扩展部分 思维拓展和推理 时间缩放只是实现这一目标的一种方式。 模型略微聪明一些，我会 总是倾向于那一边 进步非常快，因为你没有 知道何时会解锁新的应用场景 然后有时也会用 Grock 来…… 实时信息或查找 我在人工智能推特上看到一些我认识的东西 我看到了，我需要挖出来，我只是 尽管格罗克4号来了，但我还是执着于此。 Gro 4 超重，哪个最重？ 就像他们的专业版一样 非常好，我印象很深刻。 我挺喜欢肌肉的。 由于拥有……，我的记忆力下降，忘记了这件事。 chatbt 应用打开了，所以我使用了许多不同的 事物。是的，我确实在使用 Gro 4。 对于像硬核玩家来说，调试起来非常吃力 调试其他程序无法完成的任务 解决。我发现它在这方面做得最好，而且 我觉得很有意思，因为你提到了JPT。 对我来说，这是最好的界面吗？ 原因相同，但这可能只是 势头。呃，双子座 对我来说，这是更好的界面。我认为 因为我爱上了他们最好的一面。 针在钩子上。如果我曾经放过 这其中包含很多背景信息，但是 我正在寻找非常特定类型的 确保它能追踪所有信息。 它。我觉得至少双子座挺适合我的。 一直以来都是最好的。所以，这很有趣。 对于其中一些模型，如果他们获胜 你为某人倾心 在某一天，它成为了一个特色节目。 对于该特定查询，该提示， 你会想，“这个型号更好。”和 所以，你得坚持一段时间。 直到它做出一些非常愚蠢的事情。 这就像存在一个阈值效应，一些 聪明的做法，然后你就爱上了它 它用它做了些蠢事 然后你就想，你知道吗，我是 准备切换一下，试试爪式编程，也试试GPT编程。 以及诸如此类的事情。 这和你使用它的方式完全一样，直到它 休息直到出现问题，然后 然后你更改了LM，我想 我们使用任何东西的方式都一样，比如 我们最喜欢的文本编辑器嗯操作 系统或浏览器。我的意思是，有 浏览器选择很多，比如Safari、Firefox等等。 Chrome，所有这些都相对相似，但 那么可能存在一些特殊情况。 你想使用的扩展程序，然后你 切换，但我认为没有。 输入相同内容的人 网站在不同的浏览器中显示和 对它们进行比较。只有当……的时候你才会这样做 如果出现某些情况，网站将无法渲染。 我觉得是休息。所以，这很好。 观点。我认为你会一直用它直到它 休息一下，然后你再去探索其他地方。 选项。我认为 关于长远背景，我也是一个 Gemini 用户对此表示赞同，但 GPT 5.2 版本也支持。 发布博客的内容简直长得离谱。 很多人都喜欢的分数 他们是不是刚刚弄明白了一些 算法变更。它从类似 大概占30%到70%左右 模型小幅更新。所以它也非常 很难记住所有这些 事物。但现在我的看法更积极了。 在 GPT 5.2 的长上下文中。所以就是这样 就像我该如何才能真正到达那里一样 测试这个 永无止境的战斗。这很有意思 我们谁也没谈论中国人。 从用户使用角度出发的模型。 那是什么意思？那是否意味着 中国型号不如其他型号好，或者说它们不好。 这意味着我们非常有偏见，而且我们 专注吗？我确实认为那是 目前，两者之间的差异仅为 模型和平台。所以我觉得 他们更广为人知的就是这种开放式模式。 公开组重量级选手，而不是他们的平台 然而。 还有很多公司 愿意向你出售开放式模型 以极低的成本进行推理。我认为 就像开放路由器一样，很容易做到这一点 看看你可以运行的多模型程序 deepseek 对困惑的看法，我认为所有 我们坐在这里就像在使用 OpenAI 一样 GPT5 专业版始终如一，我们都愿意 为边缘智力买单 获得以及任何像这些人一样的人 美国的车型更好，而且 就产出而言，我认为 问题是，它们会一直保持良好状态吗？ 今年以及过去几年都是如此，但 只要他们更好，我就去。 我认为要付费才能使用它们。 还有分析表明： 比如 中国模特的呈现方式 你可能会认为这是出口造成的。 无论是否使用控制措施，关键在于他们使用的控制措施较少。 用于副本的 GPU 会降低它们的速度 并且出现不同的错误，就像 这些速度和智能 作为用户，您处于有利地位。我 我认为在美国，很多用户会选择 为此，我认为这是一个原因。 这会刺激这些中国人 公司希望在其他领域展开竞争 无论是免费还是其他方式 大幅降低成本，否则就会繁殖 在产品供应方面具有创造力 这对生态系统有好处，但我只是 认为简单来说，美国模式是 目前情况有所改善，我们正在使用它们，而且我 试试中文，我试了这些其他的开放方式 模特们，我觉得挺有意思，但不会去。 我不会再回去看了。呃，我们没有。 一定要重点介绍编程。那是 另一个很多人都用到的用例 非常关心。所以，我基本上是使用 一半是光标代码，一半是爪形代码 因为我发现他们就像 截然不同的体验和 两者都很有用。呃，你们怎么看？ 程序相当多。所以，接下来该做什么？ 你用什么？现在的气氛如何？ 所以我使用了 VS Code 的 codeex 插件。 你知道，这非常方便。它是 就像插件一样，然后就可以聊天了。 可以访问您的界面 仓库。我知道云代码是我 换个角度思考。稍微多一点 代理人。它涉及的方面更多。它确实 整个项目都由你负责。我还没完全 但我还没到让我感到舒适的程度。 那是因为，呃，也许我是一个控制狂。 虽然有点怪异，但我还是想看看。 到底发生了什么事？而且Codex很友好 就像现在对我来说，就像甜蜜的 找到它对我有帮助的地方，但是…… 并非完全接管。我应该 提到我使用的原因之一 克劳德代码旨在培养技能 用英语进行编程。我的意思是…… 体验从根本上来说是不同的。 你反对事无巨细地进行微观管理 生成过程的详细信息 代码，然后查看差异 如果那是光标所在位置，你可以将其显示在光标中。 你使用的想法，然后改变 改变查看和阅读代码的方式 并深入理解代码，就像你 进步与仅仅是有点儿像 在这个设计空间里思考，而且只是 在宏观层面上进行指导， 我认为“呃”是另一种思考方式。 关于编程过程。此外，我们 应该说云代码，它只是 似乎这是一种更好的利用方式。 云之作品 45。 这对人们来说是一个很好的并排比较。 做。所以，你可以打开云端代码， 你可以打开光标，你可以 VS Code 打开后，您可以选择 所有型号都一样，然后问 问题。这很有意思。喜欢 云端代码在这方面要好得多。 领域。真是不可思议。好的，我们 应该说你们俩都是合法的。 多线作战。研究人员， 程序员、教育工作者、推特用户、 在图书方面也是如此。所以，内森 希望不久的将来能有一个右手高频设备。 新书即将出版。 目前可以预购， 有完整的电子版预印本。只是 让它更美观、更有条理 就实物而言，这很重要。 我这么做的原因是因为这很有趣。 创造你认为是……的东西 就物理形态而言，这方面非常出色。 我们的生活很大程度上已经数字化了。我应该 塞巴斯蒂安，你说你在这里会感到困惑吗？ Rashka是一位机器学习研究员。 一位因其多部有影响力的作品而闻名的作家。 图书。其中有几个我想…… 值得一提的是，这是一本我强烈推荐的书。 建议构建大型语言模型 从零开始，新建一个 从零开始构建推理模型。所以，我是 对此我感到非常兴奋。建筑 从零开始做东西是其中最…… 高效的学习方法。 说实话，从……构建一个元素 Scratch 真的很有趣。这也很多。 去学习。正如你所说，是的 这可能是学习如何操作的最佳方法 有些东西确实有效，因为你可以看看。 就数字而言，但数字可能具有 错误。你可以看看概念， 解释，但你可能会 误解他们。但如果你看到 代码存在，而且代码可以运行，你 我知道它是正确的。我的意思是，没有 误解。它就像是精准的 否则就行不通了。我觉得 那就像是美的某种体现。 代码背后的故事。有点像这样 不说谎。本质上就是数学。所以 即使运用数学，我认为你也可以 书中存在错误。你永远不会 注意，因为你没有运行 当你阅读这本书时，你就会明白数学的奥妙。 无法核实。而对于代码来说，什么是…… 好处在于你可以验证这一点。 是的，我同意你对LM的看法。 刮刮画。屏蔽外界干扰真好 其他一切，比如互联网等等。 只管专心看书就好。但是，你 我知道，我读过一些，你知道的， 呃，历史书。只是没那么孤独了。 不知怎么的。真的更有趣。比如，呃， 例如，在编程方面，我 我觉得编程真的更有趣。 拥有法学硕士学位。 而且我觉得这样做真的更有趣 读过法学硕士论文 但你说得对，就像这种分心一样。 应尽量减少。所以，呃，你用 法学硕士（LLM）基本上是为了丰富…… 经验，或许可以补充更多背景信息。 也许我只是顿悟时刻的频率比较高 对我来说，小规模的规模真的很高 拥有法学硕士学位。 100%。我也想 更正一下。我并不是说不要 使用 LM。呃，我建议这样做。 多次传球就像一次传球一样 离线对焦模式，然后…… 呃，我的意思是，我也会做笔记，但我会尽量 克制住立即观看的冲动 事情进展顺利。我再进行第二遍。它是 对我来说，这就像更有条理一样。 方式，我有时会明白我的意思。 本章将解答这些问题。但 有时候，顺其自然也有助于解决问题。 仔细想想。别人 个人喜好不同。我会 强烈建议在阅读时使用LLM 图书。对我来说，这根本不是问题所在。 首先要做的事情。这就像第二个 经过。 作为建议，我同意。 恰恰相反。我喜欢使用LLM 开始 完整阐述诸如此类的内容 这就是我此刻踏入的世界吗？ 进入。但我尽量避免点击退出。 进入推特的世界，学习法学硕士学位 还有博客，因为那时你现在 掉进这个兔子洞里去了。您正在阅读 某人的意见。一场骂战爆发了 关于某个特定主题以及所有 突然间，你不再是，你现在身处…… 在互联网领域和 Reddit 等等。但如果你纯粹是 让法学硕士学位为你提供背景信息 为什么这很重要？有哪些重大影响？ 图片创意，嗯，但有时是书籍 他们自己就很擅长这样做，但是 不总是如此。所以 这就是我喜欢聊天 GPT 应用的原因 因为它为人工智能提供了一个在你生活中的栖身之所。 当你使用电脑时，你可以专注于 它不仅仅是另一个标签页。 我的网络选择太多了，我觉得 克劳德代码和这些特定的 做得很好，把这变成了一件令人愉快的事情。 作为一款产品，它似乎非常吸引人。 旨在成为您的人工智能的界面 然后，他将走向世界，并且是 非常友善的 它与法典之间的无形区别在于： 感觉很温暖，也很吸引人。 Codex 通常也能达到同样的效果 开放人工智能，但感觉就像…… 边缘略显粗糙，而 就像云代码一样，构建过程变得很有趣。 尤其是从零开始的事情 你只是不喜欢，你没必要…… 关心，但你相信它会成功 显然，这很好。 对于网站来说，这是一种令人耳目一新的体验。 我用的工具和类似的东西 它用于数据分析，所以我在我的博客上 我们刮掉拥抱膏，我们保留 每个数据集的下载次数和 随着时间的推移，我们已经有了这些模型，并且 就像云朵在说，是的，我已经…… 使用这些数据没有任何问题。我 我当时想，那得花我好几天时间。 我当时就想，那我就已经足够了。 具备情境意识，就像，好的， 这些趋势显然是合理的， 你可以查一下。但这只是 一个非常棒的界面，你 可以有中间人，而不必 做那种糟糕的底层工作 你需要做些什么来维持 不同的网络项目并这样做 东西。 好的，我们刚才谈到了一个 一系列封闭式权重模型。我们开始吧 谈谈那些开放的。呃，所以告诉我 关于 Open LM 模型的概况。 哪些是值得关注的有趣例子 你为什么会这样？我们之前已经提到过 深入探寻。 你想看看我们能说出多少个名字吗？ 凭记忆？ 是的。是的。不看笔记。 Deepseek、Kimmy、Miniaax、Z.A.I.、 蚂蚁，语言。我们难道要走中式路线吗？ 嗯，我们再加入 Mistral AI 吧，Gemma。 嗯， 是的，GPTOSS，开源模式 Chet GPT。实际上，Nvidia Neimotron 曾经 或者英伟达也有一个非常酷的， Neotron 3。嗯，那里有很多 东西，尤其是在结尾部分 年。或许昆恩一号就是那个人。 哦，是的。昆恩这个名字显而易见。 我当时想问的就是这个名字。 通过这种方式，你至少可以获得 10 个 中国人，以及至少 10 名西方人。我认为 我的意思是，OpenAI 发布了他们的第一个版本。 自 GPT2 以来，它一直采用开放模型。那时我 我当时想说的是，我在写作的时候谈到了这件事。 关于OpenAI的开源模型发布，他们 他们都说：“别忘了……” GPT2。”我觉得这真的很好笑。 因为时代已经完全不同了。但 DP OSS 实际上是一个非常强大的模型 并且做了一些其他的事情。 模型表现不太好。我觉得 出于私心，我会推广一大堆 就像西方公司一样。所以两者都是 美国和欧洲已经完全开放了这些设施。 模型。所以我在艾伦研究所工作。 我们一直在构建的人工智能领域 发布数据、代码以及所有这些内容。 现在我们有了真正的竞争对手。 试图释放的人 一切都是为了方便其他人。 训练这些模型。所以，这就是…… 基础模型研究所或法学硕士 360，就像他们之前的 K2 型号一样 各种类型。 Apparis是一家瑞士公司 研究联盟。拥抱脸嗯有 小型LM非常受欢迎。嗯，还有 NVIDIA 的 Neator 已经开始发布 数据也是如此。然后是斯坦福大学的马林 社区项目，有点像 从而形成一条管道 人们可以在 GitHub 上创建一个 issue，并提交一个 issue。 实施一个新想法，然后拥有它 在稳定的语言建模堆栈中运行。 所以这个空间 2024年，这份名单要短得多。所以…… 我觉得它就像人工智能2一样。所以这就是一个 让更多人受益是件好事。 参与并理解语言 那些没有类似样子的模型 一家中国公司，它有类似的产品。 趁我说话的这段时间，我再说一句…… 中国开放语言模型往往是 规模更大，这赋予了他们这种能力 更高的峰值性能，就像很多地方一样。 我们非常喜欢这些东西。 无论是 Gemma 还是 Neatron 都…… 通常是来自美国的较小型号。 正在发生变化的是 来自美国和欧洲。 U先生，大三 出来的是一个巨大的模型，非常 与 Deepseek 架构类似 12月，然后是初创公司RCAI和 Neatron 和 Nvidia 都是 Neatron 和 Nvidia 的结合体。 已经放出过更大尺寸的模型。 超过1000亿个像这样的参数 4000亿参数范围即将到来 这类似于2026年第一季度的时间表。所以，我认为 这种平衡注定会改变。 今年就人们而言 使用中国公开赛与美国公开赛的模式 因为，这将是我个人的 非常期待观看。 首先，非常佩服你能够做到这一点。 例如，还有很多其他例子。你…… 给羊驼取个名字？ 嗯，不。 我觉得这并非有意为之。 安息吧，羊驼。 嗯。 好的。你能列举一些例子吗？ 有哪些引人注目的有趣模型？所以 你提到昆恩3，这显然是 出类拔萃。 所以我觉得这一年差不多就结束了。 以 DeepSeek 版本 3 和 R1，另一方面在 十二月 Deepseek 版本 3.2，因为 我喜欢它们的一点是，它们总是 一个有趣的架构调整 别人没有的。但除此之外，如果 你想和……你知道，就像…… 熟悉但又非常精彩的表演 quen 3，还有Nathan说的GPD。 开源软件。我认为 GPT OSS 是什么？ 有趣的是，它有点像…… 第一个公开或类似开放体重模型 那人确实接受过工具使用方面的训练 我觉得这有点像是一种…… 这算是一种范式转变吧 生态系统还没有完全做好准备。所以 工具使用方面，我指的是LLM（法学硕士） 能够通过网络搜索调用 Python 翻译，而且我确实认为这是一个 之所以说它很突出，是因为我认为它非常重要。 解锁是因为……其中一个最…… 人们对法学硕士课程的常见抱怨是 例如幻觉等等 我认为解决此问题的最佳方法之一 幻觉就是不要总是试图 记住信息还是编造信息 做数学题为什么不使用计算器应用程序呢？ Python 如果我问美国国家医学图书馆谁赢了，我不知道。 1998年，我对足球世界了如指掌。而不是 只是想记住，它可能会这样做 搜索。我觉得大多数情况下都是如此。 仍然是谷歌搜索。所以 JPD、GPOSS、 他们会向谷歌发起一个工具调用， 或许可以找到国际足联的网站，找到就行了。 那是法国。它会让你得到那个 可靠地获取信息，而不仅仅是 试着记住它。所以我认为这是 巨大的解锁，我认为就是现在这样。 尚未被充分利用 开源开源生态系统。很多 很多人不使用工具调用模式 因为我认为信任是首要的。 事物。你不想在 您的计算机，它可以访问 这些工具可能会擦除您的硬盘驱动器或 任何。所以你可能想 将其容器化。嗯，但我确实认为你 要知道，那就像真的 这是未来几年重要的一步。 拥有这种能力。是的。 嗯，简单说几句。首先， 谢谢你解释你的意思。 工具使用。我觉得这很棒。 一般来说，对于我们提出的概念而言…… 谈论。甚至有些事情 已确立为 呃，你得说那意味着混合物 专家们，你得慢慢积累起来。 人们凭直觉就能明白这意味着什么。 它实际是如何被利用的，它有哪些用途？ 不同的口味。那么，这究竟是什么意思呢？ 开放的领域出现了如此巨大的爆发式增长。 模型？你的直觉是什么？ 如果你要发布一个开放模型，那么 希望人们将其作为首选和 首要之事。然后，在那之后…… 随之而来的是透明度等问题。 相信。我认为当你审视中国时， 最大的原因是他们想要 世界各地的人们都在使用这些 模型，而且我认为很多人都会 如果你把目光投向美国以外的地区，情况就未必如此了。 很多人不会为软件付费，但 他们可能拥有计算资源 你可以在上面放置一个模型并运行 它。我认为也可能存在这样的数据： 你不想发送到云端。所以 这是最重要的事情。 人们使用模型、人工智能或使用你的 可能无法做到这一点的AI 在没有模型访问权限的情况下。 我想我们应该明确说明。所以 我们一直在谈论这些中国人 模型和公开重量级模型通常 有时它们的运行方式是本地化的。所以 这又不是你在发送数据。 到中国或者其他任何发展了呃……的国家 硅谷，无论谁开发了 模型。 许多美国初创公司通过以下方式赚钱： 接待这些来自中国的模特 把它们卖掉，卖掉 tok。它叫做 比如出售代币，这意味着有人 将调用模型来执行一些操作 一件杰作。我认为另一个原因是 是为像Chad OpenAI这样的美国公司准备的 所以他们就像是GPU资源匮乏一样，所以他们是 当它们达到GPU的极限时 发布消息，他们一直在谈论这件事。 感觉就像我们的显卡快不行了，而且我 我觉得其中一个就像…… 像 GPTOSS 发布会 Sam Alman 就像是说，哦，我们要发布这个 因为我们可以使用你们的GPU，所以我们不需要 必须使用 我们不必使用我们的 GPU 和 OpenAI 仍然可以获得 从中分配出来，即 另一件非常现实的事情，因为它并非如此 但这都要付出代价，而且是为了…… 用户，我想也是，我的意思是，有用户 那些只在本地使用该模型的人是如何做的？ 会使用呃 CHPD，但对公司来说也是如此。 我认为拥有这些是一项巨大的突破。 因为你可以定制这些模型 你可以训练他们，你可以添加帖子 培训增加了更多数据，例如专业化 将它们纳入，比如说，法律医学模型 无论你拥有什么以及你的吸引力 喇嘛提到了开放的吸引力 来自中国的体重模型是…… 公开级车型也需要获得许可 我觉得他们甚至更友好。 仅提供不受限制的开源许可证 如果你使用像羊驼或 杰玛，这其中是有附加条件的。 我认为这就像一个上限。 你的用户数量是多少？ 如果你超过这个限度，我就不知道了，就这样吧。 数百万用户，你必须汇报 你的财务状况，比如说 元之类的东西，我觉得 嗯，这是一个免费模型，但是…… 附带条件，人们确实喜欢 不附加任何条件的事物。 所以我认为这也是其中之一 除了性能之外，还有其他原因导致开放 来自中国的体重管理模型非常受欢迎 因为你可以直接使用它们。 这里面没有任何陷阱。 感觉。是的， 生态系统在这方面已经有所改善。 前端，但主要是这些的下游 提供此类开放服务的新供应商 许可证。你拉扯的时候真搞笑 困惑加剧。它说金米K2在思考 在美国举办，就像…… 没错，我以前从未见过这种情况，但这确实是一个 这就是我们所讨论的确切例子。 关于人们对哪些方面比较敏感 这。就像 Kimmy K2 的想法和 Kimmy K2是一款非常受欢迎的机型。 人们说它非常好 创意写作，以及做一些其他事情 软件相关的东西。就只有这些 人们会注意到的一些小怪癖 他们喜欢不同的型号。 嗯，有哪些有趣的想法？ 其中一些模型已经探讨了这一点。 你可以和那个特定的人交谈。 你感兴趣吗？ 或许我们可以按时间顺序来。我是说 当然还有Deepseek，嗯，Deepseek R1于1月份发布。如果我们只是 重点放在2025年，但这是基于…… Deepseek 版本 3 于 嗯，比2024年12月早一年。 建筑设计包含多个方面。 边。最令人着迷的是，你可以 不过我的意思是，这就是我平时做的事。 Scratch编程项目。你仍然可以 从 GPD2 开始，您可以添加 要使该模型成为 另一个型号。所以一切都还算友善。 就像同一种血统一样，它也是如此。 他们之间有着非常密切的关系 但我脑海里立刻浮现出“deepsee”这个词……呃 独特之处在于它融合了各种实验元素。 这意味着他们并没有发明混合物 专家。我们或许可以再多聊一会儿。 专家混合团队的含义是什么？嗯，但是 首先列出这些事项 我们深入探讨细节。专家混合 但他们也有多头的 潜在注意力是对……的一种调整 注意力机制，我当时就在这里 可以说，2025 年是主要区别。 这些公开重量级模型之间的因素 不同的调整方法可以进行推理或KV 缓存大小。我们还可以定义KV缓存 稍等片刻，但要做到这一点 更长的背景信息更经济实惠 缩小KV缓存大小。那么，什么是…… 我们可以做的调整，以及大多数 他们专注于注意力机制。 存在多头潜在注意力 在 deepseek 中。存在分组查询 关注度仍然非常高。 它并非由这些人中的任何一个发明的。 模型。这可以追溯到几年前，但 那将是另一种选择。 滑动窗口的注意力，我觉得几乎 如果我没记错的话，它会被重新使用。所以 这些不同的调整使 这些模型各不相同。否则，嗯，我放 它们曾经一起出现在一篇文章中 我刚才做了个比较。他们是 非常相似，令人惊讶。只是 不同的数字，就数量而言 重复执行变压器模块 中心位置，而且很小 人们用来调节的小旋钮。但是但是 它最棒的地方就在于它就是它 无论如何都能用。您可以进行调整 事物。您可以移动归一化 周围有层。你获得了一些性能 收益。而且我几乎总是表现得非常好。 消融研究表明了什么 实际上，它对模型做了什么？ 你移动了某个东西。消融 研究结果表明，这样做会使情况更好还是更糟？ 但是有很多方法，比如说…… 可以实现一个转换器并使其 仍然有效。一些仍然很大的想法 普遍存在的是多种专家的混合。 潜在注意力，嗯，滑动窗口 注意力组查询注意力，然后 年底我们看到重点放在了 使注意力机制规模化 与推理标记呈线性关系 预言。所以接下来是女王3。 例如，它添加了一个门控增量 网。这就像是……嗯，有点像…… 受状态空间模型的启发，其中 你保持着一种固定的状态 更新，但本质上就是这样 注意力 更便宜，或者用……取代注意力 更便宜的运营 或许退一步是有益的。 并讨论架构转型 一般的。 是的。所以或许我们应该从……开始。 GPT2架构的转换器 这一切都源于关注。 你需要纸。 嗯。所以，你只需要关注就够了。 纸张具有变压器架构 它由两部分组成：编码器和 解码器和 GPT 只专注于 解码器部分。它本质上是一个 仍然是一个神经网络，嗯，它有 这种内在的注意力机制，还有你 一次预测一个令牌。你把它传下去 通过嵌入层。那里有 变压器模块。变压器模块 具有注意力模块和完全 连接层，并且有一些 中间有归一化层，但它是 本质上，神经网络层具有 这种注意力机制。所以，来自 GPT2，嗯，当我们转向 GPT OSS 时…… 例如，专家混合体 层并非由GPOSS发明，而是一个 虽然只有几年历史，但它本质上是一个 调整模型尺寸，使其更大 每次前向传播都会消耗更多计算资源。 经过。所以，这是一个完全连接的过程。 层，如果听众熟悉 嗯，你可以想想多层感知器。 微型多层感知器，完全 内部连接的神经网络层 变压器，而且非常昂贵。 因为如果你有的话，它就是完全连接的。 一千个输入，一千个输出，就是这样 就像一百万个连接一样，而且这是一个 这款变压器中非常昂贵的部件。 而这个想法就是要扩展这一点。 进入多个前馈网络。所以 与其只有一个，不如假设你 有256个，但那样会更多。 贵是因为你现在有256个，但是 你不会同时使用它们。 时间。所以你现在有了一个路由器 他说，好的，基于这个输入标记， 充分利用这个功能会很有用。 已连接的网络。在这种背景下， 这叫做专家。所以是混合物 专家是指您有多位专家。 而这取决于你的输入内容， 假设它更侧重数学运算，那么它会 相比之下，我们可能会使用不同的专家。 例如，将输入的文本从英语翻译成英语。 西班牙语。它或许会咨询 不同的专家。不太清楚。 我的意思是，要明确地说，好的，这就是 只精通数学和西班牙语 有点模糊。但这个想法是 本质上，你掌握了更多知识。 进入网络，但并非所有 知识无时无刻不在被运用。那 那样做非常浪费。所以你很善良 例如在代币生成过程中， 你更有选择性。这里有一台路由器 选择哪些令牌应该发送到 哪位专家？增加了复杂性。它是 训练难度更大。你们人很多。 要知道这可能会出问题，比如坍塌和 一切。所以我觉得这就是几乎 3 仍然使用 uh dense。我的意思是，你有我 考虑所有融合专家观点的模型 但密集模型中，密集意味着如此 而且这是行话。这两者之间是有区别的。 介于密集和稀疏之间。所以混合物 专家数量稀少，因为我们 有很多专家，但只有少数人 它们都很活跃。所以这叫做稀疏分布。 那么，密度高则恰恰相反。 那里你只有一个完全 连接的模块，而且总是你。 已知并已利用。所以，也许，也许这就是一个 这里也是讨论KV缓存的好地方。 但实际上，在那之前甚至在放大之前 从根本上来说，有多少新的 想法已从……开始实施 GPT2 至今 这些到底有多大区别？ 架构？想象一下混合物 专家们对注意力机制的讨论 GPToss，也就是分组查询 注意力机制。所以这只是轻微的 从多头注意力调整为群体注意力 请求关注。所以我们现在有两个了。我 他们认为他们用 RMS 取代了层均方根。 虽然这很正常，但它却截然不同。 归一化层。变化不大。 就像做了个小小的调整。嗯，非线性 激活函数熟悉的人 建立深厚的新网络。我的意思是，这是 相当于用 ReLU 函数替换 Sigmoid 函数。它是 它不会改变网络 从根本上来说。就像做了个小小的调整。 你做了一点小小的调整。嗯，就是这样。 关于它。我觉得并非如此。 本质上是不同的。它仍然是 相同的架构。所以你可以 从一个转换到另一个，你可以从 只需将这些元素相加，即可将它们融合在一起。 这些变化基本上 从根本上来说，这仍然是一样的。 建筑学。 是的。例如，你提到了我的 前面提到的那本书里有一款GPD2模型 这本书很简单，而且非常 小的。嗯，所以有1.24亿个参数。 大约，但在附加材料中 我确实从零开始做了将近三个。 gemma 3 从零开始以及其他类型的 我总是从零开始建模。 我用的是GPD2，你知道的 调整了一个不错的添加不同 组件，你可以从一个到另一个 其他。这就像…… 从某种意义上说，是血统。是的。你能建造吗？ 提高人们对排序的直觉 当你缩小视角观察它时 该领域发展如此迅速 人工智能世界，同时 从根本上讲，这些架构还没有 已更改 那么，湍流都到哪里去了？ 进步带来的动荡 收益在哪里？ 所以，这里有不同的阶段， 你开发网络或者训练 你现在有预训练网络了。嗯。 以前那只是预备训练。 带有 GPD2。现在你已经接受了预备培训， 训练中期和训练后。嗯，所以…… 我认为我们现在正处于 训练后重点阶段。我是说 预先训练仍然能给你带来…… 如果将其规模扩大，优势会更好。 更高质量的数据。但后来我们有 解锁了原本不存在的功能 带有 GPD2。例如，呃，聊天 GBT 就是 基本上就是 GPT3 模型，而 GPD3 是 架构方面与GPD2相同。 新的地方在于加入了“嗯”。 监督式微调和 利用人类进行强化学习 反馈。所以更多的是关于 算法方面，而不是 建筑学。 我认为系统也会发生变化。 很多。我认为如果你听取英伟达的意见…… 公告中，他们谈到了这些 像你现在做的 FP8 这样的事情，你现在可以了 执行 FP4。而现在发生的事情是这样的 实验室正在研究如何利用 需要更多计算才能将其整合到一个模型中 这让他们能够更快地训练，而且 让他们输入更多数据。然后你 可以通过以下方式更快地找到更好的配置 这样做。所以你可以这样看…… 本质上是每秒令牌数 GPU性能是你在以下情况下需要关注的一个指标： 你们正在进行大规模培训， 你可以从大约 1 万美元开始。 开启FP8训练后可达13k， 这意味着你每分钟使用的内存更少。 模型中的参数，并通过保存 信息越少，你做的事情就越少。 沟通可以让你训练得更快。所以 所有这些系统性的东西都支撑着 数据实验速度更快 算法有点像…… 这就是这种 循环往复，一直进行下去，有点像…… 当你看着它的时候，很难描述它 建筑，它们正是如此 相同，但用于训练的代码库不同 这些模型将会非常…… 不同且 你可能像我一样，不了解GPU。 虽然不同，但你可能也在接受训练。 GPTOSS 20B 速度更快，且运行时间更短 比当时 GPT2 的训练时间还要长。 是的，就像你说的，他们有 例如，在专家混合小组中 例如，NV FP4 优化 您将获得更高的吞吐量。但我确实 我认为这是为了速度。这是 没错，但是它没有给出模型。 从某种意义上说，是新的能力。只是 我们能生产多少？ 计算更粗糙而不受影响 模型性能下降方面。 嗯，但我确实认为我的意思是，有 替代方案层出不穷 变压器。存在文本扩散 模型采用完全不同的范式。 嗯，还有，我的意思是，虽然是文字。 扩散模型可能使用转换器 架构，但它不是自动的 激进的变压器，而且 曼巴模型，呃，它是一个状态空间模型。 但它们也各有优缺点，嗯…… 正确的是，没有任何东西…… 取代了自动渐进式 变压器作为最先进的模型。 所以，对于最先进的技术来说，你会…… 仍然要和那东西一起做，但是 现在有了替代方案 价格更低的替代品 算是做出一些妥协吧，但是…… 不再只有一种建筑风格了。 孩子们快要长大了，但如果我们谈谈 就目前最先进的技术而言，它相当不错。 变压器仍然很大。 架构自递归衍生 基本上来自 GPT2 我想这里最大的问题是： 这里谈了很多关于…… 预训练背后的架构 尺度定律是否依然有效？ 贯穿训练前、训练后， 推理、上下文大小、数据、合成 数据？ 我喜欢从技术层面入手。 尺度定律的定义，哪种尺度定律 这一切都与此有关。标度律是 你可以与幂律关系 想想x轴。所以，你到底想表达什么？ 正在扩展为计算能力的组合 和数据 它们有点相似，然后是 y轴就像是预先设定的预测值 下一个标记的准确率。我们谈论 模型具有自退化性。就像 如果你保留一套 模型未见过的文本，如何 训练后准确率会提高吗？和 尺度定律的概念是在……时期产生的 人们意识到那是一个非常 可预测的关系。我觉得 该技术术语仍在沿用。 然后问题就变成了：我们该怎么办？ 用户如何退出？然后还有 更多类型的扩展，例如 OpenAI 的 01 因引入推理而闻名。 时间尺度。而且我认为不太出名的是 也展示了你可以扩展 强化学习训练并获得 这种对数 x 轴，然后是 a 性能的线性增长 y轴。所以这里大致有这三种情况。 现在，传统的缩放轴位于此处。 法律是人们谈论的话题。 预训练，也就是你的模型有多大 是，以及你的数据集有多大，然后 扩展强化学习 比如，这个审判可以持续多久？ 我们将讨论错误学习。 我们将进一步定义这个，然后再定义这个。 推理时间计算，这只是 让模型生成更多令牌 针对具体问题。所以，我有点…… 他们都非常看好市场。 还在努力，但都是些唾手可得的成果。 主要是在…… 去年，我们通过以下方式加强了学习： 可验证的奖励，也就是这个RLVR 然后是推理时间缩放，即 为什么这些模型感觉如此不同 以前你会得到的地方现在可以使用 第一个令牌立即生效 它们会停止几秒钟或几分钟。 甚至几个小时都会生成这些隐藏的内容 在给你第一个之前的一些想法 你的回答就这么简单，仅此而已。 这种推断时间尺度 如此美妙的阶跃函数 就模型如何变化而言 能力。他们某种程度上促成了这件事。 工具使用相关内容并启用了这些功能 我们拥有更好的软件工程技术 谈论。而当我们说 几乎完全在下游实现 事实上，这强化了学习效果。 仅通过可验证的奖励培训 某种程度上让模特们自己去挑选这些 技能很容易掌握。所以它让模型 学习。所以，如果你看一下 当模型是时，推理过程是 生成大量代币会是什么样呢？ 它经常尝试使用一个工具，它看起来 它得到回复后，会尝试另一个。 API 会查看返回的内容，以及它是否返回了什么。 解决了这个问题，所以模型是 你训练他们学得很快 这样做，然后在最后 赋予这种普遍意义的一天 该模型可以使用 CLI 的基础架构 你的仓库里命令写得非常好， 帮你处理 Git 并移动文件 四处走动并整理物品或寻找 查找更多信息，如果我们是 一年前坐在这些椅子上的 这是我们之前没怎么考虑到的。 模型正在运行。所以，这只是 类似的事情已经发生了 这一年彻底改变了我们的生活方式。 想想人工智能的应用，我认为这非常 神奇。这真是一件有趣的事 进化，以及由此解锁的一切 价值，但感觉不太清楚 下一步的发展方向是什么？ 解锁类似这样的内容。我认为 我们会继续讨论这个问题。 后来才知道，但有很多 人工智能某些领域引发热议，但没有 人们知道何时会遇到下一个阶跃函数 真的会来的。 所以，你其实已经说了不少话了。 那里发生了很多事，他说了一些深刻的话。 迅速地。把它们拆开看看就好了。 一点点。你说你看好市场。 基本上在所有缩放版本中都是如此。 那么，我们能直接从这里开始吗？ 开始进行岗前培训吗？ 我们是不是在暗示…… 预训练规模化方面的唾手可得的成果 被选中了吗？这是预培训吗？ 遇到瓶颈期，或者甚至是训练前准备阶段 你仍然看好吗？ 岗前培训已经变得极其重要 昂贵的。我认为要扩大规模 预训练也意味着 你将要服务于一个非常大的模型 对用户而言。所以我认为已经是这样了。 粗略地建立了像 GPT4 这样的技术 类似型号的型号约为 1 万亿，就像这个万亿的量级一样 最大尺寸的参数。有 有很多传言说他们实际上已经…… 随着训练的进行，规模越来越小。 效率更高。你想制作 模型尺寸小一些，因为这样可以降低你的成本。 份量相应减少。这些 模型的训练成本是 相对于成本而言，价格确实很低 为他们服务于数亿人 用户。我认为Deepseek曾有过这个著名的 约500万美元 以云市场价格进行预训练 想想论文第 2.4 节中的三个部分。 我们刚才详细说明了我们拥有这块GPU的时间。 集群闲置待训练 其中包括工程问题 很多种子，大概2美元。 数百万美元用于租用该集群以达成类似交易 以及所有的问题和烦恼 训练模型。所以这些模型是 就像很多人都能得到1 需要花费1000万美元来训练模型，但是 为数百万用户提供服务的经常性成本 用户实际上价值数十亿美元 计算。我认为你可以看看 就像租用一千块GPU一样，你可以…… 每天花10万美元买这些 公司可能拥有数百万个GPU 你可以看看这些有多少 闲坐着也是要付出代价的。就是这样。 这算是一件大事，然后就好像…… 如果规模化确实能给你带来什么 更好的模型会是什么样的？ 从经济角度来看是值得的，而且我认为它会 会慢慢地把它推向人工智能时代。 解决更具挑战性的任务。所以就像 类似 Cloud Opus 4.5 这样的云平台 代码只是用来运行的。我觉得我 启动了一个名为“like”的项目 原子计划类似于美国 7月份真正开放的模式就是这样。 就像一个真正充满氛围感的网站，就像我 有份工作，嗯，就是写剧本之类的。 然后我回来刷新了一下。 过去几周，就像爪子一样。 4.5 与当时的任何型号相比 简直把所有问题都碾碎了。 那是我六月份建造时得到的 七月，或许会有一个更大的模型 有很多因素会影响到这一点 但这就像还有…… 即将取得进展。所以，所以你到底想说什么？ 指的是y轴的细微差别 缩放定律就是这样的 经验丰富的人与以基准为参照的人 实际的智力可能是 虽然不同，但仍然是你对……的直觉 如果调整预训练规模 计算能力的提升能否使模型性能更佳？ 不是它在经济上是否可行，而是 仅从法律角度来看，你觉得呢？ 我认为模型会变得更智能。 是的，而且我认为有这个 有时感觉几乎就像 对人事领导感到失望 人工智能公司这么说，但他们 就像它被保留了13个订单一样 计算机的规模大概是这样的 为什么这一切会结束？所以我觉得 从根本上来说，这种情况发生的可能性很小。 停止。就像最终我们会…… 甚至连测试都做不了。 规模更大，因为所有这些 随着计算能力的增强而出现的问题。我 我认为有很多关于如何……的讨论 2026年是布莱克威尔规模非常大的一年 计算集群，就像千兆瓦一样。 规模化设施，超大规模数据中心是 上线和 这些都是电力合同。 已分配的数据中心和 预计在2022年和2023年会有人寻找。所以 在 ChatgBT 之前或之后。所以它 这需要两到三年的准备时间。 构建这些更大的集群来训练 模型。嗯，显然有很多。 对构建更多数据的兴趣 比那更中心。所以，这就像某种 人们所说的关键在于 就像这些新的集群即将到来一样。这 实验室将拥有更多的计算能力。 训练。他们会利用这一点。 但这并非必然。感觉就像我 我看到了如此多的进步，我期望 它。我预计会更大一些。 模型。我估计，嗯，我会说是 更有可能的是，我们会看到 2000 美元。 今年的订阅。我们已经见过 200 美元 订阅。就像那样，可能会增加10倍。 再次。诸如此类的事情 这种情况可能会发生，而且他们都是 下游就像一个比特大比特 更大的型号，但功能却很少 更前沿一些。 所以你知道，有报道称 XAI 是 准备达到1吉瓦的规模 年初 26 瓦，年底前达到 2 吉瓦。 你认为他们会如何利用这一点？ 尺度定律的背景是什么？很多 这种推论有很多方面都与此有关。 训练。最终，这一切都…… 多于。所以我认为你们所有人 在训练模型时做出的决策 回到训练前阶段。所以如果你是 如果要在模型上缩放 RL，你仍然 需要决定你的架构， 实现了这一点。我们说的是类似这样的东西 与其他架构不同的 注意力类型。我们也在谈论 关于混合专家模型。这 模型的稀疏性使其非常容易受到影响。 更高效地进行发电 成为训练后工作的重要组成部分。 就好像你需要拥有你的 建筑设计已准备就绪，您可以 实际上，需要扩大计算规模。我仍然 我认为大部分计算都在进行中 预训练，因为你仍然可以…… 更好的型号。你仍然想去， 再看看这个。你仍然想要最好的 你可以使用的基本型号，只需几个步骤即可完成。 几年后，RL 将饱和。 计算时间会更长。有没有 那些与你意见相左的人会说 基本上，岗前培训已经过时了。这一切都是 关于尺度推理， 脉冲训练规模化、上下文规模化 持续学习，呃，数据规模化， 合成数据。 人们有这种感觉，并用以下方式描述它： 那样的话，但我认为不是这样。 正在进行的练习。 那只是人们普遍的感受。 说这些话 精彩之处在别处。所以 RL 中唾手可得的成果在其他方面。 例如，我们发布了我们的模型 11月份，每家公司都有 截止日期。我们的截止日期就像 11月20日，以及我们为此奔跑 是5天，与2024年相比是 花了很长时间发帖 以大约 300 亿的模型进行训练 参数。它不是一个大型模型， 然后在12月，我们又发布了一款产品。 我们只是让RL运行了而已。 再过三个半星期， 模型明显改进了，所以我们 放手一搏，那可是一大笔钱啊！ 抽出时间来做类似的事情 这将是你的…… 顶峰 一年之内。所以就像有这些 当……时发生的决策类型 他们正在训练一个模型，他们只是 他们不能永远离开这里。 你必须保持 你必须继续拉动 你从你的 研究人员。所以这就好比你重做一遍。 训练前准备。你会这么做 训练结束后休息一个月，然后你 需要把它提供给你的用户。你需要 进行安全测试。所以有点…… 就像我觉得很多事情都已就绪一样。 这强化了这种不断重复的循环。 更新模型。有一些事情 提升。如果你得到一台新的电脑 集群可以让你做一些事情 更稳定或更快。就像你 经常听到关于布莱克威尔的消息。 AI2 大部分部署问题 我们正在预训练的模型大约是 1。 最多可达 2，000 个 GPU，但当你…… 在 10，000 或 100，000 个 GPU 上进行预训练， 你们遇到的失败情况截然不同。所以GPU 它们以奇怪的方式断裂而闻名， 进行 10 万次 GPU 运算就像你 几乎可以肯定的是，总是会拥有 至少有一块GPU宕机了，你需要 让你的训练代码处理这个问题 冗余，这本身就是一种非常 不同的问题。然而，比如什么 我们现在做的就像我在玩后置摄像头一样 DJX Spark 培训或者你有 书。这就像人们学习机器学习一样。 这就像他们正在努力训练的东西一样 这些最大的模型就像质量一样。 分布式规模，而且非常 不同，但又有点不同。 比这更像这些，就像那是一个 系统问题。为了启用 规模定律，尤其是在训练前 你需要同时使用所有这些GPU。当我们 转向强化学习，它 实际上，它本身就具有异质性。 计算是因为你有很多副本 模型。和 语言模型入门指南 强化学习，你正在做的事情 你拥有两组GPU。一个是你 你可以称他为演员，也可以称他为…… 学习者。学习者是你 实际的强化学习更新是 准备去做。这些传统上 策略梯度算法。嗯，近端 策略优化、采购订单和集团 相对策略优化，GRPO 是 这两个热门课程以及另一方面 另一边，你会有一些演员， 正在生成完成情况，这些 完成的事情就是你正在做的事情 去上课。因此，加强 学习的本质就是最大化奖励。 在实践中，你可以这样做： 你可以有很多不同的演员。 在世界各地做 不同类型的问题，然后你 把它送回这台高效率的计算机 集群用于进行实际学习 你去的地方，你去的地方 渐变，你需要紧密地 您可以访问网状网络，并进行以下操作： 不同类型的平行结构和 为了提高效率，请展开您的模型。 训练。所以有很多 各种不同类型的培训和 服务过程中需要考虑以下几点： 需要扩大规模。就像我们之前讨论的那样 在训练前，我们讨论了强化学习和 那么推理时间缩放就像这样 你是否服务于一个思考的模型？ 一小时内用户量达到1亿。我就像我 我不太了解那件事，但我知道 这是一个难题，为了…… 把这种智慧赋予人们 所有系统问题，我们需要 计算能力越强，就需要越稳定。 计算即可完成。但你看好…… 所有这些类型的扩展都是 我听到了关于推断的 即使在预训练阶段也需要推理。 是的。这可真是个棘手的问题。 这里。所以基本上有两个旋钮。 训练和推理 在能够获得收益的地方扩大规模，因此 在一个我们拥有……的世界里 你想要无限的计算资源 把它们全都做一遍，这样你就接受过训练了。 你有推理缩放和训练 就像一个层级结构，这是预训练。 训练中途，雨后发生变化 模型规模更大，需要更多训练数据。 训练更大的模型可以获得更多 模型中的知识比模型本身的知识更多 假设它更好，就像…… 以前更好的基础型号 我们仍然称之为基础模型，而且 解锁。所以你，但你不，比如说 让模型能够解决你的问题 最复杂的任务 训练前或训练后。你 还有这些其他的解锁阶段 你在训练中途遇到了非语境问题。 例如，在接受 LRVR 训练后 这解锁了该模型所具备的功能。 就知识而言 预先培训，我想如果你愿意的话，当然可以。 多做些赛前训练，你会得到更好的结果。 基础型号，稍后可以解锁，但 就像内森说的那样，它就变得太过了。 昂贵的。所以我们没有无限。 计算。所以你必须决定我是否想要 把这些计算资源更多地用于制造 型号更大一些。但你知道，这就像…… 权衡。就像在理想世界里一样 你想把它们全都做一遍。我觉得 从这个意义上讲，规模仍然相当可观。 生机勃勃。你仍然会得到更好的 模型。但就像我们在GPD 4.5中看到的那样…… 根本不值得。我的意思是，就像因为 可以说，你可以解锁更多 与其他技术结合使用 此刻。尤其是如果 你看看推理扩展，那是其中之一。 今年涨幅最大的是 01。 嗯，它进一步扩展了一个较小的模型。 比预训练一个更大的模型要好得多 4.5 英镑。所以，我就好像不会说 预训练扩展就是这么回事。 好像还有其他更有吸引力的东西。 目前有哪些方法可以实现规模化发展？ 但你知道，总有一天你会 仍然希望在以下方面取得一些进展： 训练前准备。问题还在于 想想看，你想去哪里？ 花钱？如果你花掉它 关于预备训练，它就像…… 固定成本。你训练模型，然后 它永远具备这种能力。你可以 总是使用它等等。和 推理规模化，你不需要花钱 训练期间。你以后再花钱 每个查询。然后它也像…… 数学。我的模型要用多久？ 如果我把它在市场上以半价出售，我会把它换掉 年？或许不值得花5美元 百万，1000万，一亿 训练时间更长。也许只是 我将继续进行推理缩放。 然后从那里获得最佳表现。它 可能让我损失200万用户。 查询。这就变成了如何操作的问题。 你有很多用户，然后执行 数学。嗯，我觉得也是在那里。 JGBD 所处的位置很有意思 我认为他们有很多立场 用户需要去的地方 有GP5的地方更便宜。 尺寸稍小一些的型号。其他 那些仿佛你的客户一样的公司 还有其他一些权衡取舍。为了 例如，还有数学。 奥林匹克竞赛或其中一些数学比赛 问题可能出在 JJBT 或其他方面。 专有模型，我很确定 就像一个模型可能已经存在一样 稍作调整，但大部分 这是在推理缩放过程中发生的 在某些方面达到这种巅峰表现 有些任务并不需要用到所有这些 时间，总之，长话短说，我的确有时间。 想想所有这些呃，预备训练 训练中期训练后婴儿缩放 它们仍然是你想做的事情。 目前只是在寻找这个。 今年的关键在于找到合适的比例。 性价比最高 基本上 我认为这里或许是个好地方 定义训练前、训练中和训练中期 训练后 因此，预备训练就是经典的训练。 一次预测一个代币 拥有大量数据，还有内森 可能还有非常有趣的东西 因为有三点，所以有以下见解： 论文的大部分内容都集中在…… 正确的数据组合，以便进行预训练。 基本上就是你知道的火车交叉口。 对下一个标记进行熵损失训练 基于大量语料库的预测 互联网数据、书籍、论文等等 第四。它已经略有变化了。 人们过去常说的“岁月” 把他们能想到的一切都投入进去。现在是 不仅仅是原始数据。它也是合成的。 数据中人们……嗯，比如说 换一种方式表达某些内容。呃，所以是合成的 数据并不一定意味着纯粹的人工智能。 捏造的数据。它还需要一些东西。 摘自一篇文章、维基百科文章和 然后将其重新表述为问答题或 嗯，总结一下，给予奖励，以及 这样就能得到更好的数据。因为我 也可以像对待人类那样去想，如果 比如说，某人读了一本书 与混乱相比，我不知道，不 冒犯，但就像Reddit帖子或 差不多就是这样。我确实认为你 告诉你，别介意，呃，但是我觉得 之后会发一篇关于这件事的帖子。 嗯，Reddit上的一些数据非常抢手。 非常适合训练。你只是 需要过滤一下。 是的， 我想这就是我的想法。呃，我觉得 就好像有人拿走了它一样 换句话说，让我们更详细地说明一下。 简洁而有条理的方式 我认为这是更高质量的数据。 得到LM可能和你得到的结果一样 最后还是从LLM中出来了，但是 到达目的地更快，训练速度也更快。 因为，比如说，如果语法和 标点符号是正确的，它已经 学习正确的方法而不是获取 以一种混乱的方式获取信息，然后 后来才学会如何纠正这一点。 诸如此类的事情。所以我觉得就是这样。 预训练是如何演变的，以及它是如何演变的。 尽管如此，为什么缩放仍然有效呢？ 这不仅仅关乎数量 数据。这也是实现这一点的诀窍。 从某种意义上说，数据对你更有利。进而 训练中期，我的意思是以前是这样 称为预训练。我觉得是。 训练中途被叫去，因为…… 进行岗前培训会很尴尬 训练后，但中间没有任何内容 对，听起来有点奇怪。你有 训练前和训练后，但 实际的培训内容是什么？所以 训练中期通常类似于 训练前，但你知道这有点 更确切地说，我更擅长于…… 训练前准备。算法是一样的。 但你要做的就是集中注意力，例如 像你举的一个例子那样，长时间持续下去 篇幅较长的背景文档。你的理由 不要在纯粹的状态下这样做 预备训练是因为你没有 很多篇幅很长的背景文档。所以你 具有特定阶段和一个问题 LMS 仍然是一个神经网络 网络。它存在以下问题： 灾难性的遗忘。所以你就教它 它忘记了一些事情，却忘记了其他事情。和 你想做到，但这并不意味着百分之百会忘记。 但你知道，天下没有免费的午餐。 你不能。这和……也是一样的。 人类。如果你问我一些数学问题，我会…… 十年前学的，我不知道。我 我得再看一下。 呃，内森其实是说他…… 消费了太多内容，以至于…… 灾难性的遗忘问题。 是啊，我努力想学到很多东西。 关于人工智能。我当时就像在学习一样 关于预训练并行性。我就像 我丢了东西，但我不知道是什么。 确实如此。我不想对LLM进行形态化，但是 我认为两者性质相同。 感受人类学习的方式，我指的是数量 并不总是更好，因为，是的，它是。 就像有选择一样，而我处于中间状态 训练方面要有所选择 最后呈现的是高质量的内容，所以最后…… LM所看到的是质量 训练结束后的一切就是这些了。 呃，微调，监督式微调，呃 DPO um 强化学习与 可验证的奖励和人工反馈 等等。因此，精炼阶段 而且有趣的是，它就像…… 成本问题，我的意思是，就像 你在岗前培训上花费了很多钱 现在现实生活中，你稍微少一些现实生活。 我觉得没必要教它。 知识更像是解锁 知识更像是一种技能 学习如何解决问题 它所拥有的知识 培训前确实有论文。 今年三篇论文，去年2025年 RL 用于预训练，但我的意思是，我不 我觉得生产过程中有人会这么做。 目前先举几个玩具例子吧。 玩具例子没错，但要推广强化学习 嗯，训练后更像是 技能解锁，其中预训练就像 本质上就是吸收知识。 是的。 以下几点可能对您有所帮助 人们。很多人都有这种感觉 把合成数据看作是不利的 训练模型。你提到了喜欢 深海也获得了光学字符识别（OCR）。 字符识别试卷。很多 实验室确实进行了测试。 AI2 有一个，就像有多个一样。 而这些实验室之所以如此，原因在于…… 之所以有这些，是因为存在着大量的 其他数字媒体中的PDF数量 网络上的文档格式 不容易用文本编码的。所以 你几乎使用这些 CR 这些或更深层 我们称之为几乎完全CR提取 数万亿个代币 用于预训练的候选数据和 预训练数据集正在按顺序排列 万亿的计量单位是万亿。 代币。研究人员的小型模型 可能达到 5 到 10 万亿左右。 Um Quen 记录了升至类似水平的过程 50万亿，而且有传言说 这些封闭式实验室可以达到100人左右。 万亿代币。刚刚收到这个 我认为他们可能会输入一些潜在数据。 他们有一个很大的漏斗，然后是 你实际用来训练模型的数据是 一小部分人喜欢这样 字符识别数据将是 被描述为合成数据 实验室预训练。然后还有…… 此外，像聊天 GPT 现在也提供了一些功能。 精彩的回答，你可以进行相关训练。 那些最佳答案，而且是合成的。 数据。它与类似情况非常不同 早期聊天 GPT 出现大量幻觉 当人们对数据有了深入的了解时 合成数据。一个有趣的问题 如果我没记错的话，3号接受过训练。 比某些特定数据更少 其他 OpenW 重量模型，甚至可能有两个 但你的性能仍然更好， 这或许就是一个例子，说明…… 数据很有帮助。 这主要取决于数据质量。我 想想如果我们有更多的计算能力，我们会…… 延长训练时间。我认为我们最终 把它看作是某种东西。 我们想这么做。尤其是 大型号的模型，你需要更多 因为我们谈论拥有 更多参数，我们来讨论一下 知识，本质上来说，存在着 大型号可以吸收更多 从数据中，你将得到 从中获得更多益处。就像 这些对数图之一 你的思维就像一个小模型 如果你正在测量，那么很快就会趋于平稳。 大量的代币和更大的模型 还需要更多。但大多数情况下，我们并非如此。 现在正在训练如此庞大的模型 利用AI2并获得最高质量 我们能够获得的数据是自然而然的起点。 观点。 有什么要说的吗？ 数据质量这个话题？是否有一些 那些唾手可得的成果仍然在哪里？ 质量还有提升空间吗？ 这就像转动曲柄一样。所以我觉得 历史上，公开场合一直存在着…… 就像一个标准的最佳预训练数据 这套设备在谁之间来回移动过 拥有最新版本或最佳版本 近期的努力。就像AI2的dolmo非常 早期与第一个 OLO 和拥抱 脸上蛛网细密，而且还有DCLM 这个项目有点像…… 它代表数据计算。 语言模型中已经存在数据竞争 用于其他机器学习项目和 他们拥有非常强大的数据集 很多时候，互联网就是其中之一。 变得越来越封闭，所以我们有 常见的爬行，我认为有数百个。 数万亿个代币，然后你进行筛选 看起来有很多 你正在接受培训的科学工作 分类器和基于分类器的决策 如何精简这些数据 采用最高品质的材料和 适合你任务的东西。所以 之前对语言模型进行了测试 还有很多关于知识和各种方面的内容 以前是闲聊的话题，但现在他们是 需要进行数学运算和编程。所以 训练一个推理模型，你需要 重新组合你的整个数据集，就会出现一个 很多非常棒的科学 这里有一些方法，你可以像这样 假设你有一个庞大的数据集，你对其进行了抽样调查。 来自不同地方的很多非常小的东西 来源。你说你有GitHub账号， Stack Exchange、Reddit、维基百科。你 可以从中采集少量样品 你在每个模型上训练小型模型 混合并衡量它们的性能 你的评估，你就可以这么做了。 就像基本的线性回归一样，它是 比如，这是你的最佳数据集。但 如果您的评估发生变化，您的数据也会发生变化。 场景变化很大。所以很多都是旧模式 3 是新的推理来源 数学和编程能力更强，然后你 按照这个混合步骤操作，即可得到 答案就在你手里。我觉得这很多。 今年实验室里就发生过这样的事。 就像总会有新的热门事物一样，无论 它就像编码环境或网络环境。 导航，你只需要把它带进来。 新数据。你需要彻底改变你 雨前训练，这样你雨后就能…… 工作效率更高等等。所以 那就像不断的再进化一样。 重新确定他们关心什么 就像他们的模型一样。 有没有什么关于来源的有趣轶事 数据质量特别高。 出乎我们意料的？你提到 Reddit 有时可以作为一个信息来源。 Reddit 非常有用。我觉得…… 比如PDF肯定就是其中之一。 尤其是档案。 是的。所以就像AI2运行语义一样 长期从事学术研究，这很…… 就像一个你可以称之为竞争对手的人 谷歌学术搜索还有更多功能 功能，而AI2已经找到了实现这些功能的方法。 并抓取了大量公开的PDF文件 可能不太容易获取的论文 就像在封闭的付费花园后面一样 某出版商。所以就像真正开放一样 科学PDF文件，如果你喜欢，你可以坐下来。 对所有这些进行处理，然后你再进行分析。 你可以从中获得价值，而且我认为 就像很多那种风格的工作一样。 前沿实验室已经做了很多工作。 更早的时候，就像你需要的那样 有一位相当熟练的研究员 了解事物如何改变模型和 他们把它带进来，然后清洗干净。 这需要很多劳动，就像我一样。 想想很多前沿实验室 他们扩大了研究人员的规模，这方面进展很大。 进入数据。有些人就像你一样 想加入 Frontier Lab 吗？ 你想以最佳方式产生影响。 要做到这一点，只需找到新数据即可。 这样更好，然后就像花哨的 诸如此类的迷人算法 弄清楚如何制作 01 就像…… 科学家最性感的想法 哦，我已经弄清楚如何缩放RL了，而且还有…… 有一个团体做过这件事，但我认为大多数 贡献就像 我要么改进数据，要么…… 改善基础设施 这样我的团队里的每个人都能跑 实验速度提升 5%。 与此同时，我认为它也是一个 最密不可分的秘密是什么？ 出于法律原因，任何训练数据都是必要的。 所以我觉得还有很多 隐藏你的秘密所花费的工作 交易数据本质上就像尝试 不泄露消息来源的模式 是的，因为有法律方面的原因。另一个 需要补充的是，有些人 正在尝试仅使用授权设备进行培训。 其中常见的爬虫操作是对数据进行抓取。 就像整个互联网一样。所以，嗯，如果我我 托管多个网站，我很开心。 它们训练语言模型，但我不是。 明确规定其适用范围。 因此，这就是常见的爬行 基本上没有获得许可，这意味着 您实际上并未提供同意。 关于如何使用这些数据。还有另一个 一个可以用来训练语言模型的想法 仅限已获许可的数据。 明确地。所以那种治理方式 合同已提供。我不太确定 如果专业知识是版权问题的话 驾照的事。我知道 他们这样做的原因是为了欧盟 他们想遵守合规规定。 确保他们的模型符合以下条件之一 那些检查。 此外，就这一点而言，例如： 还有嗯之间的区别。 许可证。所以有些人像你一样。 他们说，他们只是购买了许可证而已。 假设他们在网上买了一本书，假设 比如说亚马逊 Kindle 电子书，或者说…… 然后用那本明代古籍之类的东西。 在训练数据中。那就像 因为你付了钱，所以才处于灰色地带。 内容，您可能需要对其进行训练。 但同时也存在一些限制。 即使那样也不应该被允许。 所以，这就是它到达的地方。 有点模糊，嗯，我想就是这样。 目前这仍然是一个热门话题，而且影响很大。 他们曾与OpenAI等公司接洽。 私营公司因其专有性而获得专利 它们成为数据和私营公司。 越来越，比如说，对……的保护 他们收集数据是因为他们知道这一点。 几年后这将成为我的模式 而且我觉得，嗯，这就像…… 有趣的问题在哪里 如果法学硕士学位变得更加商品化，而我 我认为很多人都在了解法学硕士（LLM）。 将会有更多的人能够…… 培养LLM。当然有 基础设施面临挑战，但如果你 想想那些大型行业，比如 制药行业、法律、金融 在某些行业，我确实认为他们在某些方面做得更好。 该点将从其他地方招聘人员 前沿实验室将建立其内部 基于其专有数据的模型 然后又会解锁一次。 目前尚不存在的岗前培训 因为即使你想，你也做不到。 获取你无法获取的数据 大多数情况下，临床试验和 这类事情。所以我认为 从这个意义上讲，规模可能仍然会扩大。 基本还活着。如果你也看看 特定领域的应用程序，因为我们 今年仍然如此 正在研究通用LLM课程 JPD 人类学等等，他们只是 通用型。他们甚至都不是 I 想想看，这只是触及了皮毛而已。 如果LLM真的非常具体，它就可以做到。 经过专门培训和设计 任务。我认为关于数据方面有些问题 这是其中一件事情，比如 这件事发生在2025年，我们完全 别忘了，人类学在法庭上败诉了。 作者们应得的报酬高达15亿美元。 我觉得Anthropic公司买了成千上万件商品。 我扫描了书籍，并已通过审核。 他们这样做是合法的，因为他们购买了 书籍，以及那种经历。 系统。而另一方面，他们 我还下载了一些电子书。我觉得 这种种子下载方式是通往……的途径 法院裁定他们当时负有罪责。 支付这数十亿美元 作者们，就像这样 令人难以置信的诉讼，简直就是 就这样来来去去，花了好多钱。 来自风险投资生态系统。 这些案件将决定未来走向。 人类文明的未来，因为 很明显，数据驱动着很多事情 这。而且还有非常复杂的问题 人类的紧张感，我的意思是，你可以 感同身受。你们俩 作者。是的。在某种程度上 我的意思是，你倾注了你的心血和灵魂。 以及你倾注其中的汗水和泪水 你写的那些东西，感觉…… 有点像偷窃 让别人来训练你的数据，而无需 给你信用 就像内森说的那样，还有两个 这本书有很多层次，或许有人会买它。 然后进行相关训练，这可能是 争论是否公平，但后来…… 简直就是彻头彻尾的……公司 在不合法的地方使用盗版书籍的人 即使是补偿作者也是…… 我想这就是人们有点儿误解的地方。 对此我尤其感到愤怒。 是的，但必须要有某种…… 补偿方案。这就像搬家一样 向 朝着类似 Spotify 流媒体的方向发展 最初是为了音乐而做的，你知道，什么 补偿方案具体是什么样的？你 需要对这些类型的模型进行定义。 你必须把所有这些都仔细考虑一遍。 呃，还有一件事我认为人们是 我对此很感兴趣，我很想了解。 你的想法。随着学习管理系统（LMS）的使用越来越广泛， 如果你查看档案，就会发现更多，但是…… GitHub，越来越多的数据 由LLM生成。 在那种世界里，你会做什么？ 这个问题有多严重？ 最大的问题是基础设施和 系统，但从人工智能的角度来看， 这几乎是不可避免的。 所以，它基本上是由LLM生成的数据。 基本上都是由人工策划的， 正确的？ 是的。而且我认为很多开放 来源贡献者是合法的 精疲力竭。如果你有一个很受欢迎的开放 源代码库里有人说：“哦，我 想做开源人工智能。它对……有好处 我的事业。”他们之间很有默契。 他们把什么东西扔进了你 可能比我得到的更多。 是的。所以我实际上有一个案例研究 这里。嗯，我有一个名为 ML 的代码仓库。 我将自己作为学生时所培养的能力扩展到…… 不知道15年前，10年前，而且 仍然是一个相当受欢迎的图书馆。 我认为对于某些算法来说 尤其喜欢频繁的数据挖掘 东西，最近好像有两个。 或者三个提交了很多作品的人 在极短时间内取得PR（个人最佳成绩）。我愿意 认为LMS参与其中 提交这些 PR。我作为 维护者，有两件事。第一的， 我有点不知所措，感觉自己好像什么都没有。 是时候通读一遍了，因为 尤其是这是一个比较老的图书馆。 对我来说这不是优先事项。同时， 我其实也挺感激的，因为…… 人们常常忘记的一点是…… 不仅仅是使用LLM。仍然存在 人性中，你拥有人性的一面。 验证某些事情，而这正发生在 也要留意数据的标签方式，对吧？ 所以，这算是最……之一 昂贵的东西会被贴上标签。 用于强化学习反馈和人类反馈的数据 阶段，这有点像那样 它经历各个阶段，然后 实际上，您可以获得更高质量的数据。 你知道的，所以我并不介意。 感觉到了，这可能会让人不知所措，但我 我认为这其中也有价值。 感觉存在一个根本性的问题 原始LLM生成的差异 数据和LLM生成的数据与人类 在执行某种操作的循环中 即使需要验证，该验证 占比很小 代码行数。 嗯。我觉得这跟什么都搭。 比如在哪里 人们有时也会想，哦，我可以 只需使用法学硕士学位来学习XYZ即可 确实可以，但可能会有…… 一位可能是专家的人 在那里使用了LLM编写特定代码。 这有点像人类的这种工作 投入其中是为了把它做得漂亮， 把不太好的部分扔掉 让它有点像预先消化一下。 这样可以节省你的时间，而且我认为 这就是它的价值所在。 有人负责过滤东西 甚至正确使用LLM。我 认为这仍然是劳动，你 例如，阅读一篇文章即可免费获得。 文章，比如说子文章。我 或许可以请一位法学硕士给我授课。 我对此没有看法，但我甚至都不想说。 或许知道该问什么了。我认为有 阅读那篇文章仍然很有价值 相比之下，我去读法学硕士就…… 你是专家。你选择什么 知识实际上应该是完全正确的 包括你给我的这个 这份执行摘要和这份 这算得上是一则极具价值的广告，因为现在我 不必浪费三到五个小时去 或许通过这种方式，我自己也能得到一些 错误信息等等，所以我 我认为未来仍然在于此。 即使有作家，也是为作家准备的 法学硕士（LLM）专家可以起到类似拯救的作用。 你的时间 观看这个节目其实挺有意思的。 我知道你们肯定也这么做，但是…… 对我来说，要观察两者之间的区别 摘要 以及原始内容，即使它是 一页长的摘要 内容方面，看看如何呈现很有意思。 LMBA总结摘要缓解了紧张情绪 它移除的是什么信号？ 从那东西里。 我经常谈到声音这个问题。 好声音，我很想听听。 你说的“声音”是什么意思？那真是 强大的。但有时候也会有这样的情况： 字面意义上的洞察。 就像删除一个洞察一样，你是 实际上从根本上改变了 事物的含义。所以我是 持续失望，LMS真是太糟糕了。 真正触及核心 深刻的见解，正是优秀总结的精髓所在。 做。是的。即使你去了，而我也有 这些规模庞大、极其精细的 提示，我真的想 深入挖掘，仍然找不到答案。 确实如此，嗯，我的意思是，那是一个 关于整个深刻的哲学问题 人类的知识和智慧是什么？ 洞察力意味着什么？ 诸如此类，但当你谈到声音时…… 你是什么意思 所以当我写作时，我会想很多关于…… 我只是想了解你的想法。 作为一名研究人员，这非常原始， 一位研究人员试图概括 他们在其前沿领域吸收了一个想法。 他们正在努力理解并融入其中。 用语言表达感觉是什么？我认为 我尝试在我的写作中做到这一点 使之得以呈现的文字 既原始又包含大量信息 有些人会明白的。 有些人不会，这就是某种程度上的…… 研究的本质，我认为这是 这是语言模型做不到的。 尤其是他们都受过训练。 通过这种强化学习，我们从人类身上学习 旨在获取的反馈 来自很多人的反馈，以及在 平均而言，该模型如何表现 这个和我，那里有，它将会是 模型很难做到非常敏锐 当其中存在那种过滤器时。 我觉得这真是太棒了 研究人员面临的根本问题是 RHF 就像这样提供了如此多的东西 在改进模型方面具有实用性，但是 此外，问题的表述方式也有些…… 就像里面有个结一样 你过不去。这就是我 可以把它想象成这些语言模型。 之前没有这种经历，而且他们很深刻 他们试图表达的意思 在。我认为这并非不可能。 做。我认为有一些关于模特的故事。 这真的让人很震惊。我觉得 我很想试试必应。 悉尼，而且确实喜欢那里，那里有更多 声音，因为它经常会突然消失 对人们进行抨击以及什么是 从历史上看，这显然是一种可怕的方式，比如 让记者离开他的妻子 一个可能被采用的疯狂模型 一般性普遍收养。但那是 有点像权衡取舍，比如这样 RHF 过程在某些方面类似于添加 局限性？那真是个可怕的地方 成为这些前沿实验室之一 以及公司，因为数百万人 正在使用它们。 去年有很多负面反应。 移除 GPT40。我 我个人从未使用过这种模型，但是 我曾与OpenAI的一些人交谈过， 他们已经到了喜欢这样的地方 来自用户的电子邮件可能是 检测细微差别 半夜部署 他们给他们发邮件，内容大概是这样的： 我的朋友不一样。他们喜欢 找到这些人的员工电子邮件 给他们寄东西，因为他们太棒了 与此套装相关的是什么？ 模型权重和配置 已部署给用户。我们看到这一点 与 TikTok 合作。你打开它，我不用。 TikTok，但据说在五岁左右就能实现 几分钟后算法就会找到你。它是 感觉像是被锁住了，我不喜欢这样 这些是语言模型在执行 我认为有一些建议。 你可以用以下几种方式做到这一点 五分钟内即可建立语言模型 和它聊天。模型就这么变成了 你，还有一件事 人们还没真正准备好接受我这样的人 想想那些像孩子一样不给糖就捣蛋的事 不要给孩子吃那种东西 至少在我们知道什么是孩子之前是这样。 发生 但也会有这个 机制将会发生什么？ 这些LLM（法学硕士）的使用越来越广泛 呃，很不幸，这就是人性的本质。 这种情况会导致人们犯罪 自杀，以及记者们会怎么做？ 他们将就此进行广泛报道。 那些自杀的人，他们会 很可能与法学硕士学位有关，因为 他们掌握着关于……的数据 对话。如果你真的 如果你在生活中遇到困难， 如果你正在思考……，那你就会感到沮丧。 自杀，你可能会谈到 向法学硕士们咨询此事。所以呢？ 记者们会做的就是他们会说： “嗯，自杀事件的起因是……” 法学硕士。”而这将导致 这些公司 因为法律问题等等原因 越来越能缓解这种紧张感 法学硕士。所以，它会很通用。 尽可能。这太难了 当然，之所以在这个领域运作，是因为它本身就具有这种特性。 你不希望法学硕士学位对任何人造成伤害。 达到那种水平的人类。但是也 这也是人类的本性。 经验就是拥有丰富的 对话，一次有意义的对话 一个挑战你的东西，让你从中受益匪浅。 发展需要优势。而那 那是一件极其困难的事情 RHF领域的AI研究人员 实际上你必须解决这个问题，因为你 实际上与人类打交道 健康）状况。就像很多研究人员一样 这些公司动力十足。 他们绝对是这样的 人类学和 OpenAI 在文化上是如此的 想通过这件事做好事。 世界就是这样，就像我一样 我不想做这个 因为一方面很多人 将人工智能视为健康的盟友，就像他们所认为的那样 可以谈论他们的健康 表面上很平静，但最终却全部泄露了。 进入这个领域的方法 比如谈论心理健康和 那些事情真是令人心碎 这将推动事情发展。 有人越过悬崖，但是 其他人或许能因此得救。而我是 比如，我不喜欢有些东西…… 作为一名研究人员，在训练模型时，这是 比如我不想训练图像 生成模型并发布它们 公开承认这一点，是因为我不想启用它 有人需要在笔记本电脑上安装一个工具 这可能会伤害他人。就像我不这样 我公司具备相应的基础设施 务必注意安全。但这就像…… 像这样的地区有很多。 只是需要一些愿意付出的人。 以应对其复杂性和目的来处理它。 某种信念，就像就是这样 真是个难题。 但作为社会的一份子，我们也是……的用户 这些技术需要确保 我们正在经历复杂的情况 对此进行讨论，而不是仅仅讨论。 散布恐慌。大型科技公司正在造成 对人类造成伤害或窃取您的数据。 诸如此类的东西。是它的 比这复杂得多。而你是 正确的。数量非常庞大 这些公司内部的人员。许多 你知道的，其中很多我也知道。 真心实意想要帮助别人。 他们正在考虑完整的人性。 来自世界各地的人们的经历 世界。不仅仅是硅谷，还有人们 在美国各地，人们遍布 世界。这意味着什么，他们的 需求是。这真的很难 设计这样一个系统，使其能够 帮助所有这些不同类型的人 在不同年龄组中， 文化、心理状态、精神 各种条件等等。我已经 希望人工智能的时机是 与大的关系不同 科技对普通人来说意味着什么。所以就像大 科技行业的声誉非常低，而且 人工智能为何如此昂贵，就像 这势必会成为一件大事。 需要耗费大量资源， 人们说美国是所谓的“ 用这种方式把经济押注在人工智能上 建设。感觉就像拥有这些东西一样 同时交织在一起只是 这使得沟通变得异常困难。 环境。对我来说，这样做会有好处。 去和世界上更多的人交谈。 讨厌大型科技公司，并将人工智能视为一种 继续此过程。 而你实际上做的一件事 推荐， 你提到的其中一种解药 呃，就是要在整个过程中找到自主权。 系统，而不是某种坐姿 以一种无力的方式回归并消耗 人工智能迅速地吞噬着它。 通过互联网。更精细的机构 利用它来构建东西、构建应用程序， 建造。所以你有一个真正有帮助的 你需要培养直觉，但第二点是…… 赋予你力量，因为你将要 了解它的工作原理，以及它的作用 弱点在于，它允许它给予 你的声音拥有这样说话的力量。 糟透了，这太糟糕了，这是滥用。 这项技术的运用，正是其良好用途。 科技。而且你更了解情况 进入系统后，你就可以…… 更好地理解它，你就能掌控局面。 作为消费者，它更好。我认为 你提出的自主性问题很有道理。 而不是置之不理，而是说： “好吧，我不打算用它了。”我认为 从长远来看，这样做可能更有益于健康。 我说：“好吧，它已经公开了。我不能再说了。” 把它还回来。”你知道，就像互联网一样。 那时候的电脑，也就是电脑刚问世的时候。 我该如何充分利用它？以及如何 它能帮助我提升自己吗？这 不过我担心的一件事是，如果 你只需把它完全用于某件事即可 你喜欢做的事，你热爱的那件事 已经不存在了，而且可能 我觉得这可能会导致职业倦怠。 例如，如果我使用LM来完成我所有的操作 现在对我来说，编程已经不存在了。 我只是在管理一些事情而已。 帮我编写代码。比如说，两年。 以后，如果我每天只做8个小时， 请帮我写点代码。我感觉 仍然满足了吗？比如，这就像 是的。我的意思是，这难道不是在伤害我吗？ 就我对工作的热情而言， 对我正在做的事情感到兴奋吗？我是否依然 为自己创造了一些东西而感到自豪？所以，呃…… 关于享受这个话题，那就是…… 很有意思。我们应该直接扔掉 里面有这个，最近 对约791名专业人士的调查 开发者。专业级（10级以上） 多年经验。 那可是很长一段时间。 是的。 作为一名初级开发人员。 嗯，是的，在这个时代。呃，所以 这里在很多方面取得的结果是…… 奇怪。所以他们把它分解成…… 初级和高级开发人员。但我的意思是 这正好表明，无论是初级还是高级职位 高级开发人员 在他们发布的代码中使用人工智能生成的代码。 所以这不仅仅是为了好玩而已。 中级水平的学习内容。 这是他们发布的代码。所以是25%。 像他们中的大多数人一样，使用大约 50% 或 更多的。有趣的是，对于…… 超过 50% 的代码属于这一类 你的发货是人工智能生成的，高级 开发人员更有可能这样做 所以。但你不希望人工智能夺走什么 你所爱的东西。 是 我认为这正体现了我的经验。 我即将公布的这些具体结果 说。所以加起来大约占总人口的80% 觉得这样更有趣一些 或者使用起来更有乐趣 人工智能作为工作的一部分。 我认为这取决于具体任务。嗯，为了 例如，就我个人而言，我有一个 我有时会在网站上做一些修改。 在网站上。我个人并不喜欢 这。所以从这个意义上讲，如果人工智能可以 请帮我实现一些功能。 网站：我完全赞成。是它的 伟大的。但与此同时，当我 如果条件允许，能够很好地解决复杂问题。 我发现了一个漏洞，我追查这个漏洞，然后我找到了。 虫子，这是世界上最棒的感觉。 感觉就像获得了好多快乐，哦 感觉棒极了。但现在 如果你连思考都不去想的话 关于这个bug，你直接去…… 法学硕士。嗯，你永远不会遇到这种人 感觉，对吧？但随后可能会 尽量做到折中，无论你尝试什么。 你自己找不到，你就用…… 获得法学硕士学位后，你就不会感到沮丧了。 因为它能帮助你，让你继续前进。 你喜欢的东西。所以我觉得 看了这些统计数据，我也这么认为。 区别在于，或者说，不在于…… 考虑到它是对所有因素的平均值 在不同的情况下，我们可能不会这样做，所以我们 不知道这是否与核心任务有关 如果是为了一些琐碎的事情， 否则人们就不会享受到这种乐趣了。 所以从某种意义上说，人工智能对……真的很有帮助。 做一些很琐碎的事情，嗯，很费时间。 工作。嗯，例如我的妻子 前几天她好像有个播客节目 就像书一样，呃，就像书的讨论一样 读书俱乐部，她就像个转校生。 节目笔记从 Spotify 到 YouTube 和 然后链接不知怎么断了，呃，她 在某些剧集中出现是因为…… 定制很多书籍，比如 100 个链接或 某件事，而且那本来会是件很…… 进去逐个修复链接真是太麻烦了 手动操作，所以我建议，嘿，我们来吧 我们尝试将文本复制到chachib中， 它修复了它们，而且只用了两个小时。 逐个链接进行修复。你 我知道，这使得那种类型的工作变得非常困难。 更加流畅。没有丝毫沮丧。 固定的。我认为每个人都有使用场景。 人工智能在哪些方面有用，例如 那。那也太无聊了。 非常普通。就我个人而言 既然我们在谈论编程，呃…… 你提到了调试，呃，很多…… 对我来说，快乐的源泉是…… 问题更多出在光标那边，而不是堵塞处。 代码方面，我有一个朋友，我有一个 一对……那叫什么来着？ 像我这样的程序员，就不会那么孤独了。 你把调试描述得这么精彩 不，我不认为我会说调试 就像喝完水之后一样 一直在经历或沙漠，为了 天。所以你就像我一样，跳过了整个过程。 沙漠地带，你正在遭受苦难。所以 比如有时候，有个……也挺好的。 朋友，他真的找不到 虽然有缺陷，但可以给你一些启发。 关于代码，你们在一起 和那位朋友一起经历 沙漠，然后一起找到那杯饮料 水。所以至少对我来说，呃，也许吧。 体现了孤独感 编程经验。那就是 快乐之源。是的，也可能是。 与延迟满足有关。我是一名 你知道，即使是小时候，我也是这样的人。 就像圣诞礼物这个想法一样， 拥有它们，比获得它们更好 实际上收到了礼物。我会 期待着我得到那一天 礼物，但之后就结束了，而我 失望的。或许这算什么呢？ 比如说，食物也是如此。我认为 当你真正……的时候，食物会更美味。 饥饿的。嗯，还有，是的，你说得对。 调试并不总是…… 我知道，呃，太好了。就像经常发生的那样 令人沮丧，但是，嗯，如果你能的话。 如果解决了就太好了，但是还有…… 也像一个甜蜜的金发姑娘地带， 如果太难了，那你知道的。 浪费你的时间，但我认为这是 然而，另一个挑战是人们将如何应对。 我的意思是，我们之前看过的那张图表。 我们看到，资深开发人员 交付的AI生成代码数量超过了 初级的，我认为这非常 有趣的是，凭直觉你 我觉得应该是初级开发人员干的。 因为他们不知道该怎么做。 先做这件事，因为他们更…… 初级用户，所以他们使用人工智能来做到这一点。 事物。这可能意味着人工智能是 还不够好，无法完成这项任务。 但这也可能意味着专家们更加…… 善于使用它。他们知道在哪里 以及如何更好地使用它和进行回顾 他们编写代码，并且比其他任何代码都更信任代码。 所以我认为社会中的一个问题是…… 未来会怎样呢？你如何…… 如果你从不尝试，就成不了专家。 你自己做这件事，我认为有一种方法 对我来说，学习的方式总是很关键。 是通过自己尝试做一些事情，比如数学。 如果你查看教科书的答案，就会发现答案也很重要。 是的，你会学到一些东西，但我认为你 如果你先尝试一下，学习效果会更好。 然后你就会欣赏这个解决方案了。 方式不同，因为你知道如何表达 把它融入你的思维框架，嗯，如果 LMS一直都在这里，对吧？ 实际上要走完整个流程 遇到困难时，你愿意吗？ 挣扎，因为挣扎并不美好。 对，我的意思是它现在很吃力，如果你 使用LM来完成所有事情 你永远不会真正接受这一点 下一步，然后你或许不会 获得你将获得的解锁 专家利用法学硕士学位，所以就像你一样 我知道，我觉得好像有…… 进球的最佳位置，或许这就是诀窍所在。 这里你可以安排专门的离线时间 你每天学习2小时，而且 剩下的时间用LLM，但我认为 对人们来说，保持警惕也很重要。 我认为，投资自己才是最重要的。 不仅仅是你懂法学硕士的所有知识。 是的，我们在一起 我们每个人都属于文明。 必须找到那个目标日志区域 呃，在编程语境中…… 开发者。现在我们已经有了这些 一段引人入胜的对话由此展开 包括训练前和训练中期。 让我们进入训练后环节。 训练后有很多有趣的事情要做。所以 有哪些有趣的想法？ 培训后？ 2025年最大的挑战是学习 这种强化学习与 可验证的奖励。你可以扩大规模 在那里接受训练，意味着要做很多事情。 这种迭代生成等级 循环，这样模型就可以学习两者。 工具使用方面的有趣行为 以及软件方面。可能正在搜索 它们自行运行命令并看到 输出结果以及训练 这使得这种推理时间尺度能够非常精确地缩放。 一切都很顺利，结果也正是如此。 这种范式与此联系得非常好。 而这种强化学习训练能够 推理时间尺度但推理 时间尺度可能在以下方面被发现： 方式不同，所以有点像这样 模型变化带来的完美风暴 而他们的训练方式是 这样做的一个主要因素是…… 改变了人们的态度 训练后 非常显著。 你能描述一下由……推广的RLVR吗？ Deepseek R1？你能描述一下它是如何运作的吗？ 作品？ 是啊，挺有意思的。嗯，我当时在队里。 他们提出了 RLVR 这个术语， 这是我们在DeepSeek之前开发的Tulu 3版本， 也就是说，我们并不居功自傲。 为了让民众普及 缩放强化学习。但就像什么一样有趣呢？ 学术界顺便提到的能力 命名并影响话语 因为只有封闭的实验室才能这么说。 很多。这是你可以做的事情之一。 作为一名学者，你可能不会 拥有训练模型所需的计算能力 但你可以用另一种方式来表达： 最后我把它描述成就像…… 社区可以围绕这一点团结起来。 RLVR术语，非常有趣。进而 Deep Seek 是做这件事的人 训练突破，那就是他们 扩大了强化学习的规模，这 你已经有了能够生成答案的模型， 如果完成情况良好，则对完成情况进行评分。 对，那么这种准确性就是你的 对强化学习的奖励。所以 强化学习通常是一种 在环境中行动的代理 环境赋予它一种状态，并且 获得奖励，然后你努力最大化收益。 这份奖励。就语言而言 模型，奖励通常是准确性 在一组可验证的任务上，是否 包括数学题、编程任务等等。 开始变得模糊不清，比如 像这样的事实领域也存在于 一些可验证的方法或限制 您的指示就像只回应 以字母 a 开头的单词。就像所有…… 这些事情在某种程度上是可以验证的。 而其核心思想是，你找到一个 还有很多类似的问题。 可验证，然后让模型尝试一下。 在采取这些强化学习步骤的过程中，多次出现这种情况： 这些强化学习梯度更新。这 基础设施由此发展而来 从人类反馈中强化学习 那个时代他们的得分是多少？ 尝试优化是一种后天习得的奖励 人类偏好总体模型。所以 你某种程度上改变了问题领域。 这样一来，优化过程就可以继续进行了。 规模要大得多，这有点像 引发了一场重大变革，改变了…… 模型的功能以及人们如何使用它们。 RVR 可以修改哪些类型的域？ 到 数学和编程是最著名的学科。 然后还有很多工作要做。 这就是所谓的规则，即 与人们可能拥有的某个词有关 听证会上，LM 被当作法官来对待，这就像…… 每个问题我都会有一组问题 在我的训练数据集中。然后我就会拥有 另一种语言模型，并询问它什么 这个问题的良好答案看起来会是什么样子？ 就像这样，然后你就可以尝试解决这个问题了。 反复很多次， 根据此评分标准进行评分。所以 这不一定像……那样可以验证。 虽然涉及数学和代码领域，但这个评分标准的 想法和其他科学问题 可能有点含糊不清。 很多注意力都集中在哪里 他们正试图推广这套…… 将这些方法融入到这类更多领域 模型可以在开放式领域中运行 学到更多。我想那叫做 基于人工智能反馈的强化学习 正确的？ 那是它以前的说法。 人类学宪法人工智能中创造的概念 纸。所以它就像很多这样的事情一样。 万物皆有周期。 RLVR 也只是退了一步。所以 我认为有趣而美好的事物 这就是你问LM的问题，我们来问问吧。 比如说一道数学题，然后你就知道了。 正确答案，然后你就可以去读法学硕士了。 就像你说的，自己想办法解决。但是，它是如何做到的呢？ 真的吗？我的意思是，你其实并不真的 限制它。有一些 您可以添加的约束条件，例如使用 同一种语言，不要切换 西班牙语和英语。但假设 你基本上不用插手。你只有 给出问题和答案。 那么LM就必须你知道的 任务是得出正确答案。但 这里最美妙的地方在于接下来发生的事情。 实际上，LM会这样做 一步一步的描述，就像你知道的那样 就像作为学生一样，或者像作为……是的 数学家，你会如何推导出…… 解决方案。它会给你，或者会 按照这些步骤操作，确实会有帮助。 该模型旨在提高自身的准确性 然后就像你说的，还有推论。 规模化。因此，推断的尺度比较松散。 这意味着基本上要花费更多计算资源 在使用LM进行推理期间和 这里的推断尺度是： 该模型会使用更多令牌，而且 我认为他们在R1论文中展示了 模型训练时间越长，时间就越长。 回应是，它们会生长。 他们使用更多代币的时间越长，它就越容易变成 更贵的东西会变得更贵 对于简单的任务，但这些解释 它们有助于提高模型的准确性。 还有许多有趣的论文 展示模型解释的内容并不能 不一定非得正确，或者也许 这甚至与答案无关，但是 不知何故，它仍然有助于模型。 就像这样，事实上它是…… 解释一下，我觉得这也是我再次…… 不想将这些拟人化 法学硕士，但这有点像我们人类 如果涉及到复杂的数学运算，请正确操作。 比如说，在数学课上你遇到的问题 通常你会带一张便笺纸，然后写下来。 你一步一步地把一些东西划掉， 该模型还具有自我纠正功能，并且 我想那就是顿悟的时刻。 R1论文，他们称之为“顿悟时刻”。 因为模型本身认识到了这一点 犯了个错误，然后说：“啊，我……” 好像出了点问题，让我试试。” 我觉得这太酷了。 仅仅给出正确的答案就能解决问题。 回答并让它自己想办法 从某种意义上说，它确实做到了。 人类会怎么做。尽管亚当斯 不要像人类那样思考，这有点像 就像一个有趣的巧合。以及 另一个不错的副作用是它很棒 对我们人类来说，这些步骤经常可见。 它能建立信任，而且我们也能从中学习，我们 可以再三核实。有很多 就在这里。我认为一些争论 今年有很多争论。 如果像这样的语言模型啊哈 我觉得那些顿悟时刻有点装出来的。 因为在岗前培训中，你基本上 我已经看遍了整个互联网。所以你 确实见过有人解释 他们的工作甚至在口头上也像…… 数学讲座的文字稿。你试过 哦，我搞砸了，那又怎样？ 强化学习就是这个RLVR 非常擅长的是放大这些 这些行为非常有用 使模型能够进行更长时间的思考 检查其工作情况。我同意这一点。 这次培训非常棒 该模型会学习如何放大这种效应。 以一种非常有效的方式 最终答案会更好。我可以给予 你也需要一个实际操作的例子。我当时 使用 RLVR 训练 Gwen 3 基础模型 数学 500。基础型号有一个 准确度约为15%。只需50步 就像几分钟内使用 RLVR 一样 模型准确率从 15% 提高到 50%。和 那么你不能告诉我的是…… 学习任何关于基础知识的东西 关于数学 奎因的例子很奇怪，因为 今年已经发表了两篇论文。一 我参与的那个讨论数据的会议也在其中。 奎因的污染情况，特别是 他们接受过很多这方面的训练。 我们曾有过一个特殊的中期训练阶段。 大概过了一分钟。真奇怪。他们训练 针对几乎完全相同的问题 那。 确切地。所以你可以看到 基本上，强化学习并没有教授…… 对任何新获得的数学知识进行建模。你 50步之内做不到。所以 知识早已存在于……之中 训练前准备。你只是在解锁它。 我仍然不同意这种观点。 前提是，有很多怪异的事情 你无法证明的复杂性 因为其中一件事表明 奇怪的是，如果你拿了昆恩3 所谓的基本型号，你可以 你可以通过屏幕上的谷歌搜索功能进行搜索。 谷歌喜欢数学数据集拥抱脸 你可以提出一个问题，然后…… 如果你把它放进昆恩3基地，你就会这么做。 所有这些数学题都包含文字。 就像爱丽丝有五个苹果一样 拿一个，然后把三个给任何人 这些文字题 基于奎因的模型解释了人们为什么 如果你改变了……，就会怀疑他们。 用数字表示，但保留文字。 Quen会像非常高产一样生产。 不用工具也能产生非常高的质量 精度，例如十进制表示 答案意味着有一些类似的东西 在某个时候，它暴露出了问题。 与测试集几乎完全相同 它使用工具来获取非常 高精度答案，但一种语言 没有工具的模型永远不会真正发挥作用。 给你。所以，情况一直就是这样。 研究界争论的焦点是 例如，这些加强作用有多少？ 学习论文，用于培训 昆恩，以及专门针对此的测量 就像数学基准测试那样，已经…… 多篇论文都在讨论 污染程度就像你能承受多少一样。 相信他们吗？我觉得这就是…… 导致RLVR声誉受损 关于格式，因为你可以得到 这些收益来得如此之快，因此 必须已存在于模型中。但 这里面有很多复杂之处，我们 它其实并不像是受控的。 实验。所以，我们其实并不…… 知道。但如果不是真的，嗯……我会 我说蒸馏法行不通，对吧？ 平均蒸馏法可以起到一定的作用 程度如何，但问题是我认为 LM研究中最大的问题是 污染是因为我们不知道 除非你有数据，否则数据里有什么？ 新的数据集真的不可能 还有你提到的数学问题。 数学数据集，这是一个问题和 然后回答并给出解释。 但甚至还有一些更简单的东西 比如 MMLU，这是一道多项选择题。 如果只是改变格式，基准测试就会出现问题。 有点……嗯……就像我不知道你用什么 用点号代替括号 差不多就是这样。模型精度 将会大相径庭。 我认为这就像…… 这是模型问题，而不是普遍问题。 这甚至都不是出于恶意 LM的开发者们就像是：嘿，我们想要…… 在该基准测试中作弊。就是这样。 在某个时候，我看到了某些东西。 认为评估的唯一公平方法是 LLM将有一个新的基准，即 在LM的截止日期之后 已部署。我们能否列出具体内容？ 那种包罗万象的配方 那将进入培训后阶段， 你提到我们的RLVR真的很棒 令人兴奋的有效方法，也许我们应该 复杂的 RHF 仍然非常 扮演何种角色，其重要组成部分是什么？ 关于训练后还有其他一些想法 我觉得你可以大致理解这一点。 我认为你可以把它看作是…… 第一个推理是 01。 可能的模型，或者最新的模型是什么 模型是，他们实际上有你 将在以下方面进行类似的干预： 这些是从训练中期开始的地方 以及据传能够实现的事情 01 及类似型号非常谨慎 数据整理，其中你提供 一大类，比如所谓的 推理痕迹，这正是模型 正向过程中的词语生成 那就像是在反思如何分解一个 问题分解成中间步骤 尝试解决这些问题。所以在训练中期 你需要有类似的数据 这样做是为了当你移动时 主要通过这种方式进入后续培训阶段。 它可以通过可验证的奖励来学习，然后 今天发生的事情是，你 弄清楚要给哪些问题 模型以及训练时间。 以及你能进行多少推理。 启用该模型以用于求解 这些可验证的问题。所以作为模型 某些问题没有好转的可能 像模型那样更长时间才能解决这些问题 百分之百的时间都是如此，因此存在 信号非常弱。如果我们拉 如果我们看一下GRPO方程，这个 因这个而闻名，因为本质上 给予代理人的奖励是基于 衡量一个行为的好坏的标准是什么？ 完成情况是相对于其他情况而言的。 针对同一问题的答案。所以如果所有 这些问题的答案都一样。 这类算法中没有信号。 所以他们正在做的就是寻找 更难的问题，这就是为什么你会听到 关于科学领域之类的事情 这就像太难了一样 在那里什么都能得到。如果你 弄个实验室什么的，就这么简单。 生成大量代币或难度更大 软件问题。所以边疆 所有模特都在努力向这些更难的方向发展。 他们可以学习更多领域，并接受更多领域的训练。 问题，模型将学习更多 同时掌握多种技能。连接到此的 RHF 链路是 有点像RHF过去是、现在仍然是的样子 就像是画龙点睛之笔。 在这些模型中，它使模型更 通过改进组织或发挥作用 风格或语气。有很多不同的东西 这能引起不同受众的共鸣。 有些人喜欢非常古怪的东西 模型和 RHF 可能擅长实现 那种性格，有些人讨厌。 这就像 Markdown 的项目符号列表一样 模型确实如此，但实际上并非如此。 非常适合快速解析 信息。还有早期的杰夫这个人 反馈阶段对于……来说真的非常棒 将此内容纳入模型中。 一天结束了。所以，这就是 chatbt 的由来。 对人们来说，这种用途非常神奇。 实际上保持了相当稳定。这 格式化也有助于模型获取 例如，更擅长解决数学问题。所以 这就像风格与……之间的界限 格式和您使用的方法 用来回答问题实际上是嗯 它们在很多方面都密切相关。 当你训练这些模型时 这就是为什么 ROF 仍然可以说制造 模型在数学方面表现更好，但这些 可验证域名是一个更重要的因素。 直接执行此操作的原因是 这样就更有道理了。 问题界定，这就是为什么它如此 最终都会汇聚在一起，但是 总结起来就像中期训练一样。 该模型具备它所需的技能 学习强化学习和可验证的奖励是允许的 该模型尝试了很多次。所以放一个 将大量计算转化为反复试验 在解决难题的过程中学习。进而 RHF就像是完成模型，制作 它易于使用，而且形状有点像圆形。 模型已退出。 您能否就计算量发表一下看法？ RLVR需要吗？ 它只涨不跌。所以我觉得 Grock 4 因声称他们使用 类似的计算量 训练前和训练后。返回 规模化讨论涉及 用于扩展的硬件截然不同。 预训练非常依赖计算资源， 就像这场关于失败作品的讨论一样， 究竟可以进行多少次矩阵乘法？ 你一次性就能完成。而且因为 RL，你正在生成这些答案， 你正在现实中尝试这个模型 世界环境，最终会变成 因为你更依赖内存，所以 生成长序列和 注意力机制具有这种行为 其中，你会得到二次方增长 随着年龄增长，记忆力也会逐渐衰退。 序列。因此，计算变得非常 不同的。所以你在预备训练期间 我们会讨论一个模型。我认为如果 我们又回到了拜登时代 行政命令，就是 就像 10 的 25 次方次翻滚来训练一个 模型。如果你在后期处理中使用浮点运算- 训练就奇怪多了，因为…… 现实就像有多少小时一样。 你们分配了多少块GPU？我 从时间角度考虑，强化学习计算 越来越近了，因为你刚刚 无法将所有东西都整合到一个系统中。喜欢 预训练的计算密度非常高。 所有GPU都在彼此通信。 其他方面，它效率极高，尤其是在…… RL 包含所有这些动态部件，而且它可以 生成所需时间很长 100，000 个令牌的序列。喜欢的话就点赞吧 想想GBT 5.2 Pro需要一个小时， 这就像如果你的训练跑有…… 你需要抽取一个小时的样本进行测试。 确保这件事得到高效处理。 所以我觉得以GPU小时数或者类似的方式来说 实际运行时间为挂钟时间。 可能接近天数 作为预备训练，但他们可能 同时使用的GPU数量并不多 时间。有一些经验法则，其中 实验室就像你不想让你的 训练前的跑步训练持续时间比这更长 一个月，因为他们失败了 灾难性的。如果你是 计划举办一场为期 2 天的大型集群活动 几个月后，它在第50天失效了。 机会成本实在太大了。所以你 我不太想只跟你们这些人说这些。 他们不想把所有的鸡蛋都放在一个鸡蛋里。 篮子就像 GBT4 一样，就像 终极YOLO跑，没人想要 以前做这件事需要大约三个月 经过数月的训练，每个人都…… 我很震惊它居然在我设想的地方奏效了。 人们变得更加谨慎了。 现在逐步推进。所以RL VR更…… 假设你可以无限量地使用 训练或继续受益于 RLHF 因为这是个人偏好，所以你可以调整它。 达到某个临界点后，它就不再…… 确实有必要花更多时间在现实生活中。 把这部分预算考虑进去。所以，只需后退一步。 嗯，偏好调整。所以有 多人可以提供多种 比如说，对同一事物的解释 事情就是这样，而且两者都可能正确。但 在某个阶段，你会学习某种风格。 这根本说不通，你知道的。 反复迭代。我最喜欢的例子是 比如亲戚问我用什么笔记本电脑 他们应该买。我给他们一个 解释或者问他们，比如“嗯，什么？” 你的使用场景和他们一样吗？ 例如，优先考虑电池寿命和 贮存。其他人也喜欢我们 例如，我们会优先考虑内存和 计算结果，但两个答案都是 正确，但不同的人需要 不同的答案和偏好 调整得好，你正在尝试平均。 感觉你好像在索取数据 标签商会告诉你是否正确 写下你首选的答案，然后你 接受这方面的训练，但到了某个时候，是的，你 了解平均首选答案和 我认为没有理由保留 因为你知道，要花更多时间训练它，所以要更长时间。 这只是RLVR的一种风格，你 实际上，我们让模型很好地发挥作用。 法律模型能够解决越来越复杂的问题。 难题，所以我认为 分配更多资源更有意义 长期预算用于LRVR，而且也包括 目前我们处于 LRVR 1.0 O 混合状态 它仍然像那件简单的事一样。 我们有问答环节，但是 我们对那一样东西什么也不做。 介于两者之间。所以，我的意思是，那里也存在问题。 谷歌也发表了多篇研究论文。 例如，在过程奖励模型方面 它还会给出分数 解释是否正确 解释，我认为这就是答案。 接下来，假设我们的 LVR 2.0 O 为 今年重点关注中间问题 并回答如何利用这一点。 信息解释以改进 解释并帮助它获得 准确度更高，但是…… 这是其中一个角度，而且还有 deepseek 数学版本二论文 他们还有一些有趣的推论。 规模化在那里一开始就很好。 嗯，开发了分级模型 它们本身就是一个独立的模型，我认为 那将是其中一个方面， 就像内森提到的那样，将会是 LRVR正在向其他领域发展。 域名。 人们感到兴奋的地方是 值函数与之非常相似。 因此，过程奖励模型 有点像过程奖励模型 给每件事物分配好感度 推理过程中的一种中间步骤 价值函数适用的过程 语言模型中每个词元的价值 生成。这两者都是 语言学中很大程度上尚未得到证实 建模和推理模型时代。 人们对价值更加乐观。 出于某种原因，功能一直运行。 现在。我认为过程奖励模型是 在这一预发布阶段尝试了很多东西。 擦除模型时代之前和很多 人们用它们遇到了很多麻烦。 所以我觉得很大程度上是人为因素造成的。 类似价值模型的本质非常 强化学习的悠久历史。 它们是首先要考虑的事情之一 核心在于像深层加强一样 学习现有知识就像训练价值一样。 这其中的模型。所以现在 人们为之兴奋的文学作品 尝试价值模型，但非常 几乎没有证据，而且 在试图扩大规模的过程中出现的反面例子 过程奖励模型。事情 并非总能在未来成立。我认为 我们通过交谈展开了这场讨论。 关于规模化以及一种简单的方法 用类似这样的方式总结你的意思 你不想做太多的右旋高频（RHF）， 最终信号尺度是 人们一直在研究 RHF 语言 多年来，尤其是在高强度模式下，模型一直备受青睐。 内嗅盘聊天，这是第一个 发布训练好的推理模型 使用 RLVR 打开 ais1 时，有一个缩放图 如果你增加训练量 对数计算会得到线性 评估次数增加，这导致 我认为已经多次重现了。 Deepseek 的剧情也类似，但是…… 对于 RLHF，不存在缩放定律，如果您对数 增加计算量，你会得到一些 事实上，性能是开创性的扩展 RLHF 的论文是关于缩放定律的 奖励模型过度优化，所以它是 这就像是和RLVR划清界限一样。 以及我们现在和将来拥有的方法 未来它们将遵循这种规模化趋势。 范式就像最好的运行方式一样 可以让它额外运行 10 倍，然后你 性能提升几倍，但你不能这样做 这与RHF有关，而且这即将发生 定义领域以及人们如何 我会以托儿的身份去接触他们。 人们在学术上从事RHF研究，这就是 描述它的好方法是像做…… 你可能并不需要最好的RHF。 额外的 10 倍或 100 倍计算能力，但要做 你做的最好的RLVR游戏，我觉得就是这个。 我认为这是一篇开创性的论文。 什么是元实习？它叫什么？ 这就像强化物分级的艺术。 利用语言模型进行学习，他们的什么 他们将其描述为规模强化学习的框架 以及他们的渐进式实验 大约是 10，000 B200 小时，这就像 成千上万的 每项实验花费数千美元，他们确实做到了。 很多都是这样的，成本也差不多。 普通人无法获得 学术界，这是一个艰难的平衡 它正在试图弄清楚如何 向每个社区学习。 我想知道我们是否可以考虑一下这个 稍微跑题一下，谈谈…… 教育与学习。如果你是 正在听这段话的聪明人 对编程感兴趣的人 我对人工智能感兴趣，所以我猜想是构建 从零开始做点什么也是不错的选择。 开始。所以你能带我走吗？ 就像你会推荐的那样 有人会这么做吗？所以我个人会先开始。 就像你说的，呃，实施一个简单的 从零开始构建一个可以在……上运行的模型 你的电脑。目标不在于你是否 从头开始构建一个类似模型 你每天都会用到的东西 个人项目。好像它不会继续下去 担任您的私人助理，取代 现有的开放式重量模型或 CHPD。 这是为了看看究竟有哪些东西被放进去了。 法学硕士（LLM）究竟能学到什么？ 从这个意义上讲，预训练是如何运作的。 最好在您自己的电脑上操作。嗯，还有 然后你会了解岗前培训的内容， 监督式微调， 注意力机制。你得到一个可靠的 了解事物运作的原理。但是 总有一天你会达到极限 因为小型模型只能做到这一点。 很多。学习的问题在于 关于大规模LLM，我认为是 制作起来要复杂得多，呈指数级增长 更大的型号，因为这并不是说…… 模型只是变大了。你必须 现在考虑对参数进行分片。 跨多个GPU运行。你甚至为了 KV缓存有多种方法可以 执行它。其一是理解 它的作用就是不断增长缓存。 这就像一个逐步积累的缓存。 一步一步来，比如说合并列表 让它生长。但那样的话，就不是…… 在GPU上表现最佳。你不会那样做的。 你需要预先分配一个张量，然后 把它填上。但这又增加了另一个问题。 20 到 30 行代码，并且对于每个 你添加了这么多代码，我觉得 读书的诀窍基本上在于…… 了解法学硕士课程的运作方式。它不是 将成为你的生产级LLM。 但一旦你拥有了它，你就可以 了解生产水平LM。 所以你总是试图构建一个LLM（法学硕士）。 这可以装进一块GPU里。 是的。我拥有的大部分都是我拥有的 部分型号附赠一些额外资料。我 想想他们中的一两个人可能 需要多个GPU，但目标是 把它放在一块GPU上，而且很漂亮 关键是你也可以自己验证这一点。 当你编写这些代码时，感觉就像在玩 RLVR 一样。 你可以从零开始，也可以使用现有的 拥抱脸变形金刚的模型 图书馆嗯，所以拥抱的脸 Transformer库很棒，但是如果你 我想了解一下LMS，我想这就是了。 这不是最好的切入点，因为…… 代码之所以如此复杂，是因为它必须 它必须满足如此多的使用场景 也有一些人在生产中使用它。 必须是 它很复杂，而且真的很 交织在一起，非常困难。它不是 线性读取。它最初是作为 先是微调库，然后发展壮大 类似于标准表示 每种模型架构和方式 加载完成。所以拥抱脸就像 获取模型的默认地点和 transformers 是一款软件， 可以实现。所以人们可以轻松加载 模型并用它做一些基本操作。 所有开放的前沿实验室 体重模型有一个拥抱阶段 变形金刚版本，就像来自 deepseek 到 GPTOSS。所以就像…… 您可以加载的规范重量 那里。但同样地，甚至包括变压器。 该库未在生产环境中使用。 人们当时使用 sglang 或 vlm，而且 这又增加了一层复杂性。 我们应该说变压器 库里大概有400个模型。 所以这是一个试图……的库 实施了很多LLM，所以你拥有 庞大的代码库。基本上就像 巨大的。感觉就像……我不知道，也许吧。 数百万条，数十万条 代码，并发现它就像理解 你想了解的部分是 在哈希堆栈中找到那根针。但 它的美妙之处在于你拥有 可运行的实现，因此您可以 从它倒推过去。我会 建议这样做，或者我也会这样做：如果 我想了解例如如何 几乎已经实现了3个，我会考虑一下。 模型中心配置中的权重 文件，然后你就能看到哦，他们用了 他们使用了很多层，比如说一个组。 查询注意力或多头注意力 那样的话，你就能看到所有的 组件就像人类可读的 I 不认识配置文件中的100行代码 然后，比如说，你从你的GPD2开始。 模型并添加你所知道的这些内容 这里最棒的地方在于你可以加载 预先训练好的重量，看看它们是否…… 在你的模型中工作，并且你想匹配 使用以下方法得到相同的输出： 变压器模型，然后你就可以使用了 基本上，这是一个可验证的 奖励你正确地设计你的建筑 然后有时候需要一些时间 我一天之内几乎要和三个人在一起 挑战在于如何利用绳索来保持这个位置。 嵌入物中，它们有一个纱线延伸部分，并且 那里有一些自定义的缩放设置。 我无法完全匹配这些 事情，以及在这种斗争中，你有点像 理解事物，但最酷的是 最后你知道你做对了。 因为你可以进行单元测试。你可以 对照参考资料进行检查 实施方面，我认为这或许…… 学习的最佳方法之一 基本上就是逆向工程 某物。是的， 我认为这是…… 所有有兴趣获得 如今的人工智能应该做到这一点。我觉得 这就是我喜欢你的书的原因，就像我 从这种强化学习中衍生出了语言模型， 机器人领域。就像我从未拿过一样 有时间去学习所有东西。 基本原理和这个变压器 我所描述的建筑风格是这样的： 像深度学习这样的基础性学习 这是我过去必须学会的一件事 人们需要这样做。我认为 很多人都会去那里 我该如何将“不知所措”应用到…… 产生影响或找到类似职业道路 因为像人工智能和语言模型这样的 这些基础知识如此易于获取， 有学习动力的人会学会它。 然后问题就变成了：我该如何获得这些周期？ 我的目标是为研究做出贡献，而且 我觉得我其实相当不错。 对此持乐观态度，因为该领域 移动速度如此之快，以至于很多时候 像我这样的最优秀的人并没有完全解决问题 问题在于存在一个更大的下限。 看起来像是一个更大的问题需要解决 那是很容易实现的，所以他们 继续前进，我认为我所经历的很多事情 RHF这本书试图做的是 例如采用交易后技术 只需描述人们如何看待…… 它们如何影响模型以及什么 人们正在做某事，然后就…… 令人惊讶的是，我竟然想到了这么多事情。 就像人们停止研究它们一样。 或者不这么做，所以我认为人们试图获得 掌握基本要领后，范围会缩小。 很好，然后阅读相关内容。 论文和参与 生态系统。就好像你真的 随机用户在网络上的接近程度 来自顶尖研究人员，无人能及 知道X上所有匿名账户的所有者是谁 机器学习非常受欢迎，无论出于什么原因。 原因，而且没人知道这些人是谁。 人们觉得这可能只是随机事件。 深入研究这些东西的人 尤其是有了人工智能工具之后，就更容易做到这一点了。 就像“保持”一样，我不明白这种“保持”。 我认为深入研究这个问题非常有用。 这件事，但是有很多研究 类似这样的区域可能有三个 你需要阅读的论文，然后 其中一位作者可能会发邮件。 还你钱。但你必须投入一个 这些邮件花费了很多心思。 了解该领域。就像我想的那样 对于一个新手来说，这很容易需要几周时间。 努力让自己感觉能够真正理解 比如，什么是非常狭窄的区域？但我 考虑在拥有之后缩小范围。 基本原理对人们非常有用 因为 我好像对……产生了浓厚的兴趣。 就像性格训练一样 如何让模型变得有趣？ 是讽刺的还是严肃的，比如…… 你对数据做了哪些处理才能做到这一点？而且是 就像牛津大学的一名学生伸出援手一样 我。他就像是说：“嘿，我对……感兴趣 就这样。”我给他提了建议，我说， “那份文件现在已经存在了。”感觉就像， 我不知道，大概有两三个吧。 世界上那些非常 对此很感兴趣。他是一名博士生。 这会让你获得优势。但是就像 对我来说，那是我一直期待的话题。 有人可能会说：“嘿，我有……” 需要花些时间在这上面。”而我 当然还有很多非常狭窄的领域。 有些事你会觉得，“哦，它 没有……这说不通。 对此，我的回答是。”我认为答案是 就像有太多信息一样 后来人们都说，我不能 抓住其中任何一个。但如果你只是 我觉得实际上应该固定在一个区域里。 有很多有趣的事情 学习。是的，我认为你不能尝试这样做。 这一切都是因为那会非常 如果压力过大，你会精疲力竭。 你试图跟上所有事情的步伐。为了 例如，我自己就没有跟上进度。 计算机视觉领域长期以来一直专注于此。 在学习管理系统 (LMS) 上。但回到你的书上来， 例如，我认为这也是一个 非常棒的一本书，而且非常精彩 为了学习，花点钱是值得的 关于 RLHF。我不会出去的。 阅读RL HF论文，因为我会成为你。 将会花费 这与此相矛盾。我刚刚编辑了这本书。 我当时就想，有一章讲的是…… 肯定像X文件那样，只说一件事 但X文件却说了另一回事，我们会…… 看看结果如何。 有哪些事情是必须经历的 部分目录 我们可能错过的想法 从更宏观的角度来看待培训后的情况。所以 首先，你需要进行问题设置。 培训概述 偏好有哪些 优化中的偏好数据 工具奖励建模正则化 指令调谐拒绝采样 强化学习 I 政策 梯度直接对齐算法 然后是宪法人工智能和人工智能反馈 推理和推断时间尺度 工具使用和函数调用合成 数据和蒸馏评估 然后是开放式问答环节。 优化风格和信息以及 然后是产品用户体验角色和帖子 训练。那么，有哪些值得考虑的想法呢？ 提到将两者联系起来 教育部分和研究 成分？你提到了那个角色。 培训内容相当有趣。 品格训练很有趣 因为从中获得的收益太少了，但是 我们讨论了人们如何参与 这些模型，还有我们喜欢的，感觉很好 之所以使用它们，是因为它们具有积极意义，但是 那样做可能会走得太远。或者也可能太…… 积极的，本质上就是 如何更改您的数据和/或 做出决定，使其完全符合预期 你想要的，而且像 OpenAI 那样，它有这个东西 称为模型规格，其本质上是 他们的内部准则规定了他们应该做什么 希望模型能够做到，并且他们会发布 这对开发者来说，本质上就是你 可以知道OpenAI的失败之处是什么 他们接受的训练就像他们拥有的那种 他们的意图尚未实现。 与他们喜欢的东西相比 实际上你想做，但你却不想做。 比如，这种透明度非常好。 但所有这些策展方法 文件及其易读性 他们并不广为人知。我认为 这本书的设计方式是…… 强化学习章节显然是 人们想要什么，因为每个人都听到了。 关于RLVR，情况也一样。 算法和数学原理都一样，但它是 就像你可以在非常中使用它一样 不同的文件。所以我认为核心 偏好 就像偏好有多么混乱一样 基本上是对我之前写的一篇论文的重新阐述。 几年前。这本质上是 本章将解释为什么 RHF 是 永远无法完全解决，因为就像 即使是RL的设置方式也是如此。 嗯，它假设偏好可以 量化和多种偏好 可以简化为单个值。我 我认为这与经济学有关。 致沃诺曼·摩根斯顿的文学 效用定理。就这样…… 在这一章里，所有那些哲学思考， 经济和心理背景， 它会告诉你哪些东西会被压缩成什么样子。 进行 RHF。所以就好像你拥有了一切 这一点，然后在书中后面又出现了。 就像你用这种RL数学来制作 数字上升。我认为这就是…… 为什么我认为这会非常有意义 人们之所以要进行研究，是因为 这就像量化偏好一样。 就像人类拥有的东西一样 设计这个问题是为了…… 偏好是可以研究的。但也有善良的人。 关于基本辩论的讨论，例如…… 例如，在语言模型响应中。 你关心的事情各不相同。 无论是准确性还是风格，以及何时 你正在收集他们所有人获得的数据。 压缩成这样，我更喜欢这样 比另一个更甚，就像那样。 正在发生，而且有很多哲学思考 其他领域也有很多研究 进入这个世界的方式 我觉得你真的应该这么做吗？ 社会选择理论是以下领域的一个分支： 经济学原理及你应该如何做 汇总偏好，还有像我这样的人 我去参加了一个出版的研讨会。 一份白皮书。我当时就想，你怎么能这样？ 考虑运用社会选择理论 适用于 ROHF？所以我最希望的是人们 他们对即将到来的数学感到兴奋 并且有一些地方可能会让他们绊倒。 深入了解并学习这种更广泛的知识。 语境。我觉得有件很有趣的事…… 只需记录所有技术报告即可 我喜欢推理模型。所以在…… 第十四章，有点像…… RLVR 的简要概述，就像…… 一张巨大的表格，我只是想在上面列个清单 我使用的每一个推理模型 喜欢。所以我觉得…… 教育，很多方面都需要像这样。 这一点，就像我喜欢的那样。 因为语言模型非常好。 在数学领域，就像一篇著名的论文 直接偏好优化 就像一种更简单的专业解决方法 问题在于RL的推导 附录中跳过数学步骤和 我感觉自己为了这本书付出了很多努力。 重新推导了一遍，然后我就想：这是什么？ 他们用的那个对数技巧到底是什么鬼？ 改变数学公式，但这样做是为了 语言模型就像这样 日志技巧，我就像我不知道是否 我喜欢这种数学形式。 商品化。我认为像某些人 挣扎着阅读这个附录 我认为遵循数学规律是有益的 学习和我 是的。所以我们实际上要回到 这通常只是关于……这个话题。 教育。你们俩都提到了…… 文字挣扎 相当多。所以，如果你是……的话，它还是有价值的。 在这个过程中不挣扎。 你没有完全理解…… 正确的学习方法。我想 一些供应商已经开始 研究教育模型，这些模型是 旨在不给予实际上我还没有 用过它们，但我猜它们是 旨在不提供所有信息 立刻 并让人们为此付出努力。所以，我 认为你可以训练模型来做这件事 这将是一份极好的贡献。 就像书里提到的所有这些东西一样 你必须重新评估每一个决定。 就它而言，这是一个很好的例子。我 我觉得你有机会工作 在人工智能方面，我也有过类似的经历，我当时就像…… 哦，我想这应该是 这很有道理。我做了类似的事情 那。呃，前几天也做过这件事。 例如，我有时会玩电子游戏。 我闲暇时喜欢玩电子游戏，比如我 就像那种带解谜元素的电子游戏，所以你 比如塞尔达传说和银河战士，还有…… 我玩这个新游戏的时候卡住了， 已经卡住了，不过没关系，我 我知道我不想像两个人一样挣扎 两天后，我用了LLM，但是后来 你说，嘿，请不要添加任何 剧透警告，你知道我在这里。 接下来我该怎么做？ 我想数学也可以用同样的方法。 你说，好的，我在这里 我卡住了，别给我 完整的解决方案是什么？但什么是“东西”？ 我可以试试，你知道，就像你那种人一样。 仔细探究，但问题在于 我认为这需要自律。 很多人做数学题就像我一样。 这意味着有很多人喜欢 数学，但也有很多人 他们需要把它作为家庭作业来完成。 那就像走捷径一样，是的，我们 可以发展教育学硕士学位，但是 其他LLM课程仍然存在，而且还有 仍然很想选择另一个法学硕士学位。 我认为很多人，尤其是在 大学，他们懂这些东西 他们对此充满热情。他们是 他们对此有自知之明，并且他们也明白这一点。 这不应该是一件容易的事。 我觉得我们只需要开发一个 味道不错。 嗯。 我们谈论研究品味，比如 学校对你应该了解的事情的品味 正在努力 还有一些你不应该有的东西 继续挣扎，这很难知道 因为有时候你没有好的…… 对未来发展方向的长期愿景 真正对你的职业生涯有帮助。 但你必须，你必须培养这种能力。 品尝。是的。 我当时可能在和我的未婚夫或 和朋友们谈起这件事，感觉就像…… 在这短短的十年窗口期内，所有的一切 作业和所有考试都可能 数字化，但在此之前，每个人都有 因为要在蓝皮书里做所有的考试。 别无他法。现在之后 人工智能，每个人都需要掌握。 蓝皮书和口试，因为每个人都需要。 作弊简直易如反掌。就是这样 短暂的一代，有着不同的 教育体系就像一切 可能是数字化的，但你仍然 无法作弊。而现在我正要离开 回去。太搞笑了。 你提到了品格培养。只是 把视角拉远，讨论一个更一般性的问题 关于这个话题。计算量是多少？ 需要并且通常需要做出贡献 研究人员？ 有没有一些地方不太拥挤 在需要计算的地方，你可以 真正作为个人做出贡献 研究员 是指性格培养方面吗？我 我认为这项研究建立在……之上 对大约70亿个参数进行微调 与劳拉一起做模特就像…… 本质上，你只需要对一个小的方面进行微调。 模型权重的子集。我 不清楚具体有多少GPU小时 那需要一些时间，但并非不可能。 并非所有学者都能做到这一点。所以 一些学者的处境就是这样。 糟糕，你唯一能做的就是 在进行推理时，你已经关闭了 模型或开放模型，然后你就能得到 他们完成的工作，你可以查看 仔细观察并理解这些模型。 这非常适合用于评估 当你成为前任时，你想成为…… 最擅长创造代表性问题 模型失效或表现出某些缺陷 我认为你可以具备的能力 用这个方法取得突破。所以我觉得我 认为最高目标是 从事评估工作的研究人员 想要拥有职业发展势头是…… Frontier Labs 取走您的评估报告。 所以就好像你不需要拥有 每个项目都会这样做。但如果你去 来自一所没有计算机的小大学 然后你弄明白了克劳德的一些事情 挣扎着，然后是下一片云 模型在博客文章中像这样显示： 这就是你职业生涯的火箭飞船。我认为 那很难，但就像如果你 希望尽可能扩大范围 以最小的计算量产生影响 类似这样的东西，就是获取 范围很窄，需要学习 模型的发展方向。所以你需要 比如构建一个测试工具，看看哪里 并非云4.5会失败。如果你要去 如果我要开始一个项目，那就重新做一个 我的研究项目需要考虑在哪里进行。 8个月后的模型将是 挣扎中。 那么，开发全新的产品又如何呢？ 有什么想法吗？ 这是权衡取舍。我认为如果 你在攻读博士学位，你也可能…… 感觉用语言工作风险太大了。 模型。我打算做更长期的事情， 就像什么 究竟是什么将定义…… 语言模型发展十年， 我觉得我最终会成为一个 一个非常务实的人。我是说， 我去读了博士学位，感觉就像我得到了 最坏的情况，我能去伯克利。 拿到硕士学位后，我就去科技行业工作。它是 我在这方面非常务实。在 比如人们所拥有的工作生活 在这些人工智能公司。数量 例如，OpenAI的平均薪酬是 每年超过一百万美元的股票 每位员工。任何一个正常人 美国进入这个人工智能实验室的途径是 彻底改变你的人生。所以我是 相当实用，就像仍然存在…… 在职场有很多晋升机会。 如果你专注于语言模型，那么 结果就像是，看看这些工作岗位。 但从研究的角度来看， 变革性影响和这些学术 获奖者，并有望成为下一个颜乐泉 从不工作到不在乎 语言模型开发非常重要。 从这个意义上讲，这是一笔很大的经济牺牲。 案件。 所以我能和一些很棒的人一起工作。 学生们会问：我应该去吗？ 在人工智能实验室工作？我当时就想： 你在顶尖大学攻读博士学位，或者 你要离开去实验室。 我感觉自己不知道。比如如果你去 在顶尖实验室工作，我不怪你。 不要随便去一家初创公司工作。 那可能会降到零，但如果你是 去OpenAI的时候，我就想，这可能是 值得放弃博士学位。让我们更 仔细思考一下。在哪里 你会推荐什么？ 是否有人愿意做研究贡献？ 所以，选择就只有学术界，所以去吧。 获得博士学位，并花5年时间发表论文。 计算机资源有限。 呃 还有一些研究实验室更…… 专注于公开组体重模型，因此 在那里工作或在已关闭的前沿实验室工作， 研究实验室， 开放人工智能、人格化可解释人工智能等等。 嗯，这两个梯度更接近闭合状态。 你得到的钱越多，你往往就越容易…… 而且你获得的学分也会减少。所以在 构建类似投资组合的条款 你做过的事情，比如这非常 清楚地了解你作为一名……所做的一切 学术方面，你已经做到了这一点。 相比之下，如果你打算像…… 交易这一相当合理的进展 因为他只是机器中的一个齿轮 也可能非常有趣。所以我认为是这样。 截然不同的职业道路，但是 比如成为……的机会成本 研究人员的水平很高，因为他们拥有博士学位。 学生基本上得不到任何报酬。 所以我觉得最终会给人们带来回报。 拥有相当稳定的安全保障体系， 他们意识到他们可以在 他们想要实现的长期目标是 非常有趣的工作，而且收获颇丰。 有趣的工作。所以它相当像 能够成为这样的人是一种特权。 我打算完成我的博士学位，然后好好想想。 之后再拿出来，因为我想这样做。 而且我认为很多学术界人士都喜欢在…… 与此同时，学术生态系统是 资金削减的冲击 还有一些其他的东西。所以，数量就这么多。 我理解不同的权衡取舍。 很多人都会说：“哦，我是……” 我实在应付不了这项筹款工作。我 拨款无故被削减了 政府方面，或者我不知道发生了什么。 即将发生。”所以，我认为有很多 不确定性和权衡取舍，在我的 意见倾向就像接受一样 一份高薪且有意义的工作 影响。所以，这就像又不像 你拿着工资却闲坐着 OpenAI。像尖端科技一样建造 那些事物 改变数百万人的生活 与科技的关系 但就出版而言，他们越来越…… 越来越神秘。所以，所以你是 出版越来越少，越来越少 更少，所以你正在经历 能产生大规模的积极影响，但这却是 你只是机器里的一个齿轮。 我觉得老实说，情况并没有改变。 就这么多。呃，所以我一直在…… 学术界。我已经不在学术界工作了。 与此同时，我也不想 我怀念在学术界的时光。但我 在讲到那部分之前，我想先说一下， 我觉得变化不大。我 嗯，我当时在用人工智能工作。 或者机器学习方法，嗯，用于 应用与计算生物学 与合作者和很多人 直接从学术界跳槽到谷歌 我觉得反过来也一样。 然后。教授们就像你知道的那样。 令人难过的是，他们的学生都去了大学。 因为他们无法继续经营下去，所以这个行业就垮了。 从这个意义上讲，他们的遗产，而且我认为 是一样的，就像它一样 我觉得变化不大。 唯一改变的是规模。 但你知道，酷的东西总是 在已关闭的行业中发展起来 你不能谈论这件事，而我 我觉得现在的区别在于……嗯，你的 你喜欢谈论什么？ 你的作品发表或者你知道你 更倾向于封闭式步骤，那是一个 当然，补偿是有区别的。 但我觉得一直都是这样。 所以这真的取决于你知道在哪里。 你感觉很舒服，而且也 没有什么永远是唯一正确的。 现在还有第三种选择，那就是 嗯，创办一家初创公司，那可真是一大堆事儿…… 创业对很多人来说都是非常冒险的举动。 但高风险可能很高 加入即可获得奖励。 我认为工业实验室相当安全。 你也知道向上流动的可能性。说实话， 我认为，如果你曾经去过…… 如果是在工业实验室，就更容易找到了。 未来的工作。但话说回来，你知道， 你知道，就像，是啊，多少钱？ 你喜欢这个团队和工作。 礼仪事项与你喜欢的方式 出版工作？我的意思是，出版业 压力很大。嗯，你知道，就像…… 会议的接收率可能是 任意妄为，令人非常沮丧，但是 而且回报丰厚。如果你有纸质文件 发表后，你会感觉很好，因为你的 上面有名字。你的身高很高 成就，你知道 我觉得我的朋友们…… 教授们平均而言似乎比其他人更快乐。 我在一家前沿实验室工作的朋友们 一定要完全诚实，因为那只是 接地气和前沿实验室 一定要做这个996，这基本上 是“一直在工作”的缩写。 你能把996描述成一种文化吗？ 可以说，中国发明了它。 呃，在硅谷被收养。是什么 996是什么？仅上午 9:00 至晚上 9:00 一周六天。 一周六天。那是什么？ 72小时。 好的。那么，这基本上是什么呢？ 硅谷人工智能公司的标准 谷？这种磨练越来越普遍了。 心态。是的。我的意思是，或许不是。 就是这样，但我认为还有 一种趋势正在朝着这个方向发展。而且是 有趣的。我觉得它差点翻了。 因为当我身处学术界时，我感觉 就像那样，因为作为一名教授，你 你必须写拨款申请，你必须做你自己。 你必须教书，你也必须做你的 研究。这就像同时做三份工作一样。 而且，这比全职工作还要繁重得多。 你想获得成功。嗯，我觉得 就像内森刚才说的那样 教授们与实验室相比 认为他们可能更少…… 比在前线工作时压力或工作量更大 因为实验室 他们工作很努力。他们真是太…… 和学生一起工作让我感到满足 并拥有持续的跑道 指导和使命感 非常注重人际关系。我认为在一个时代 当事情进展非常迅速且 非常混乱的环境反而会带来丰厚的回报 人们。是的。而且我认为在创业公司里， 我认为是这种压力。就像你 必须做到，而且感觉就像是这样。 人们投入的精力真的非常重要 时间，但是这真的很难，因为 你必须不断拿出成绩，而我已经 曾在创业公司工作过。我玩得很开心，但是 我不知道我是否能一直做下去。 节奏很有意思。呃，还有…… 就像我们在……中讨论的那样 开始。这些模型正在跨越式发展 他们彼此之间，而且他们总是 就像尝试迈出下一步一样 与竞争对手相比。只是 无情。我觉得现在 我认为这种跳跃式的性格和 拥有多个玩家实际上是 被低估的语言建模驱动力 在这个过程中，竞争是如此深刻。 根深蒂固于人们和这些公司之中 有意创造了非常强大的 人类文化等文化被认为是如此 在文化上像深切投入和 有条理的。我的意思是，我们听到的太少了 来自他们以及所有在 Humanetic 工作的人 似乎非常契合，就像是 在一个文化氛围非常紧密的环境中， 这种竞争动态就像 谈谈一件将会产生影响的事情 你努力工作，创造出美好的事物。 更好的。所以我认为，这带来的 以人力资本为代价的是 喜欢 你只能这样做一段时间。 人们确实都快要精疲力竭了。我 我想我写过一篇关于职业倦怠的文章 就像我尝试过进出这个领域一样。 我自己尤其努力想成为一个…… 经理全面培训。真是太疯狂了 完成这项工作。 《苹果在中国》这本书 作者：帕特里克·麦基。他谈到了 苹果工程师们付出了多少努力 他在中国建立了供应链，然后他 就像他们挽救了婚姻一样 他在播客中透露，他参与了多个项目。 就像有人死于这种程度的…… 努力工作。所以我觉得就像 这是一个创造的理想环境。 基于人力成本的进步和我 会有很多东西，有一个 很多人的人力成本都来自996。 我们以这就像……开始。 人们真的非常努力。我也读过这篇文章。 书。我认为他们有一个暗号。 如果有人必须回家消磨时间 为了挽救婚姻，他们和家人一起努力。 真是太疯狂了。然后同事们想 好吧，这就像是红色警报一样。 情况。我们必须放那个人走。 这个周末回家。嗯，但是…… 同时，我认为他们并非被迫的。 去工作。他们真的太…… 我想我应该是对这款产品充满热情吧。 那就是你，你陷入了那种境地。 我有时也会有这种心态。 学术上，同时也是一名独立人士 人。我有时候会工作过度 而且这样做不健康。我曾经有过，你知道，我 背部有伤。我颈部有问题。 因为我没有休息，而我 或许应该接受的。但事实并非如此 因为没有人强迫我。它是 因为我想工作，因为 这就是 OpenAI 和他们想要的。 完成这项工作。 是的。但是，还有，还有a 感到一股热情正在高涨 尤其是在硅谷 考虑到尺度定律的概念，存在…… 这种炒作让世界…… 几周内发生了翻天覆地的变化，而你 想成为其中的核心，然后 你知道，嗯，我拥有这个很棒的 有幸与人交谈 各种各样的人类以及来自 在那里我可以看到所有这些气泡， 世界各地的回音室效应，这是 观察我们人类是如何形成的，真是令人着迷。 他们。我认为可以公平地说： 硅谷就像一个回音室。 呃，有点像筒仓和气泡。我认为 泡泡其实非常有用 有效的。这不一定是 负面因素，因为它可能是极端的 高效。可能是史蒂夫 工作机会 因为你只是 互相说服对方取得突破 迫在眉睫，而且需要说服每个人 除此之外，你还要…… 突破即将到来。嗯。 伯恩·霍巴特写了一本分类书 气泡，但本质上其中一个是 金融泡沫就像 投机取巧是不好的，而其他的 一个是，我不知道该怎么称呼它，但是 有效地用于建设，因为它 促使人们去建造这些东西， 我认为人工智能确实参与其中，但我担心 关于它向金融领域的过渡 就像泡沫一样 是的，但也包括在思想领域。 气泡 你正在制造现实扭曲场 这意味着你偏离了…… 现实，以及如果你离现实太远 现实 同时你也在工作，你知道996和你 你可能会忽略一些基本方面。 人类经验包括在内 硅谷，这很常见 硅谷的问题就像是…… 非常具体的地理区域，您可能 不理解中西部的观点 体验其他所有方面 美国不同人群 遍及世界各地，还有你，还有你 你们彼此用某种方式交谈 互相说服对方相信某件事 而那样做会给你带来真正的麻烦。 人工智能是否会取得巨大成功并成为…… 要么是一项强大的技术，要么它就不是。 无论选择哪条路线，你都能找到属于自己的道路。 陷入困境，所以你必须考虑所有因素。 而你，是一位年轻人 正在考虑你想做什么 关于你的生活，那就是我不关心的事情。 即使真正理解这一点，但SF AAI梗图已经发展到这种程度了 永久底层阶级就是其中之一。 这就是最后6个的想法 2025 年的几个月是唯一的时间 在人工智能初创公司中创造持久价值 或者模型，否则所有值都将是 被现有公司和你捕获 因此，生活将会很贫穷，就像那样。 旧金山现象的一个例子是这样的 我仍然认为，对于年轻人来说， 如果你能利用它，你就能做到 非常热衷于想要 对人工智能产生影响，例如身体上的影响 旧金山是最有可能的地方 你要这么做，但它有这个功能 有利有弊 我认为旧金山是个很棒的地方，但是 这里有点泡沫，如果 你进入了那个泡沫，那就是 非常有价值，赶紧离开。 读历史书，读文学作品。 访问世界其他地方 Twitter 并非如此，Substack 也并非全部。 我想我会说这是我的其中之一 我的一位同事要搬去旧金山了。 我好像需要给他弄一份…… 女巫的季节，这是一个 旧金山从1960年到1985年的历史 这就像嬉皮士的复兴一样。 就像他们所有同性恋者一样的革命 有点像是在接管这座城市，而且 文化兴起，随后是艾滋病毒和艾滋病。 危机和其他事情，就是这样。 就像那件事发生得如此近期，如此之多 动荡和伤痛，但也像爱一样…… 旧金山，好像没人知道这件事。 这。这是一个很棒的读书季。 巫婆。我推荐它。我的一堆旧金山 朋友们都推荐了那些外出的人。 对我来说就是这样，我觉得就像…… 我曾像在那里生活过那样生活，而且 没能理解这个背景，而且…… 就像最近发生的事一样。是的。好的。我们开始吧 呃，我们聊了很多，我们聊了很多 关于很多事情。嗯，当然 关于最近那些令人兴奋的事情 今年，但今年呃，其中一件事 你们提到的令人兴奋的事情是…… 燕尾服融合模型的缩放和仅 对文本融合的另一种探索。 你能谈谈那是什么以及什么吗？ 这种可能性存在 不同类型的方法 比目前的学习管理系统（LMS）更好吗？ 是的。所以我们经常谈论…… 变压器架构和自动 激进的变压器架构 特别喜欢 GPT，但它却不行 这意味着没有其他人在做任何事情。 别的。所以人们总是处于“让我们”的状态。 提醒大家留意下一个重大事件 因为我觉得这几乎就像 嗯，是啊，不这么做太蠢了，因为当然可以，对吧？ 现在Transformer架构是 这样做效果最好，而且还有…… 现在除了你，什么都没有。 我知道最好不要这样做。 把所有鸡蛋都放在一个篮子里。人们 正在开发其他替代方案 到自激式变压器。 其中之一就是例如文本 扩散模型和听众可能知道 图像扩散模型 生成方式类似于稳定扩散 使它流行起来。就像一张纸 关于图像生成。那时的人们 使用生成对抗网络（GAN） 网络，然后还有这个 扩散过程，其中你迭代地 对图像进行去噪处理，结果如下： 随着时间的推移，图像质量一直保持得很好。 稳定扩散是一家公司。其他 公司构建自己的扩散机制 模型，然后人们现在就觉得，好吧 我们也可以尝试对文本进行此操作吗？ 你知道，这在直觉上是有道理的。 因为感觉好像……好吧，呃，不是这样的 像像素一样连续的东西 我们可以区分它就像一个 那么，离散文本该如何实现呢？ 那个巢穴噪音过程，但它是某种程度上的 类似于鸟类模型 就像你回到谷歌时一样 最初的变形金刚，所以他们就像 编码器和解码器 解码器 这就是我们目前在GBT中使用的技术。 等等，编码器更像是 嗯，一种类似的技术，比如说，其中 你有多个代币需要填充 相反，GPT 模型是并行运行的。 它们会以自动递增的方式一次充值一个代币。 你完成句子的时候 一次一个代币，在鸟类模型中，你 假设我们有一段文本，比如说一个句子，它包含 缝隙，呃，你想把它们遮盖起来，然后 其中一次迭代正在填补这些空白 文本传播有点像那样。 假设你从哪里开始呢？ 一些随机文本，然后你来填写。 缺失的部分，或者你正在改进 逐个迭代地操作它们，你就会得到多个 迭代。而这里最酷的是…… 这可以同时处理多个令牌 同时。所以，这有点像…… 承诺使其效率更高。 当然，权衡取舍的代价是： 那么，质量如何呢？或许 速度要快。然后现在你有了这个 去噪过程的维度。这 你做的步骤越多，文本就越好。 变成。嗯，还有人，你知道，我 这意味着，你可以通过不同的方式进行扩展。 他们试图看看这是否可能有效 自动侵略的替代方案 就提供相同体验而言，该模型与此相同 以更少的计算资源获得更高的质量。我现在 我觉得你知道，那里有文件。 这表明，如果你想得到……，那就没问题。 同样的质量，你得把音量调大。 巢穴里传来嘈杂的脚步声，然后你就结束了 花费同样的计算资源，你会 投资于自动增值模型。嗯 另一个缺点是，它是平行的。 听起来很有吸引力，但有些任务 它们并不像你知道的那样平行 推理任务工具的使用可能在你 需要请代码解释器提供 给你一个中间结果，那就是 融合模型有点棘手。所以 有些是混合型的，但主要观点 我们能否将其并行化等等。 我觉得这目前是个很有意思的方向。 大部分都是研究，呃，这么说吧。 市面上有一些车型，比如拉达等等。 我还看到一些初创公司的一些案例。 已部署的模型没有大的呃 大规模扩散模型，但就像你一样 知道就像双子座的头晕指数那样 但谷歌发布了一项公告。 或者像某个网站，他们说他们是 启动 Gemini 扩散，他们将其 将其置于他们的 I nano2 模型背景下 然后他们基本上是这么说的 在大多数基准测试中，我们都能达到相同的质量。 生成速度更快。所以你 提到了下一步计划。我不认为 文本扩散模型将取代 自发性递增LLM，但它将是 或许可以快速、便宜地买到一些东西 规模化任务。或许是免费版 未来大概就是这样。 我认为有几个例子可以说明这一点 我听说实际上是 已开始使用。我认为 举例说明为什么这如此重要 更好的。例如，当 GPT5 进行以下操作时 30分钟内回复，正在生成 一次只能处理一个代币。以及这种扩散 这个想法本质上是生成所有内容。 那些完成，所有这些标记 一次性完成，即 为什么它可以更快。我觉得 或许很合适。我所在的创业公司 听证会就像代码创业公司一样，你 你有代码库，而且你有人 这实际上就是氛围编码，而且他们 假设进行了这项更改，代码差异如下： 模型给出了一个巨大的回应 但它不必有那么多。 外部环境，你可以获取它 利用这些扩散作用，速度非常快。 模型。这就是我所听到的关于一个的情况。 例如，他们使用这些文本 扩散产生非常长的差异 因为这样做是自动递增的 模型需要几分钟才能完成，而这段时间 例如，面向用户的产品会导致 人员流动频繁。所以就像每一秒你 流失大量用户。所以我认为 事情会变成这样，那就是…… 将会成长并有所收获 申请，但我其实是这么想的。 不同类型的模型是 将会用于不同的用途 比以往更早。 所以我采取了一种权衡取舍的方式。我认为 工具使用点就是…… 阻止他们变得像大多数人一样 通用型，因为像云代码一样。 这与搜索类似 自发递归链被中断 用了一些外部工具，我不知道 如何使用扩散装置来实现这一点？ 那么，这种工具的未来发展方向是什么呢？ 今年以及未来几年呢？你 我认为会有很多de 那里的发展是如何整合的 对整个堆栈？我确实这么认为 我的意思是，这主要取决于 专有LLM侧。嗯，但我认为我们 在开源软件中将会看到更多这样的内容 工具，我的意思是，这是一个巨大的 解锁后你就可以真正 将某些任务外包给第三方 记忆到实际 你知道，就像不是有LM（可能是指某种游戏或软件）那样。 记住 23 + 5 等于多少，只需使用 a 计算器。 所以你认为这有助于解决问题 幻觉？ 呃，不是彻底解决，而是减少它。嗯，所以 法学硕士仍然需要了解他们喜欢什么 何时请求工具调用。以及 第二个问题是，这并不意味着…… 互联网上的信息总是正确的。你可以这样做 网络搜索。但假设我问的是谁 比如说，在1998年赢得了世界杯。 仍需找到合适的网站 获取正确的信息。所以你 仍然可能访问错误的网站 并给我提供错误信息。所以，我 我不认为这能彻底解决这个问题，但是 从这个意义上讲，它确实有所改进。嗯 今年早些时候还有一篇很棒的论文。 我想应该是1月……呃，12月31日吧。 严格来说还没到2026年，但也差不多了。所以 例如递归语言模型 那真是个不错的想法，可以借鉴一下。 这甚至更进一步。所以只是为了 解释一下，呃，所以内森，你也提到过 早期做酷的研究比较困难。 在学术界，由于计算机技术 预算。如果我没记错的话，他们确实这么做了。 所有与GPD5相关的内容。所以他们没有 甚至可以使用本地模型。但这个想法是 假设你有一个很长的上下文任务。 与其让LLM解决所有问题 就像一枪毙命，或者甚至像…… 将其分解成子任务。 你让LM决定何时以及什么是 一个好的，比如说一个子任务，然后 递归调用 LLM 来解决这个问题。 我也觉得类似的事情。 然后添加工具，你就知道每一种工具了。 也许你每个月都有一大堆问答任务。 一个人上网收集 信息，然后你把它提取出来 最后缝合起来，再把线头缝回去。 一起。嗯，就像我觉得那里有…… 将会有很多解锁使用的东西 就像你那样，你不会 不一定能改进LLM本身，你 改进LLM的使用方式和内容 LLM 可以使用。目前存在的一个缺点是 工具的使用要求是您必须提供法学硕士学位。 获得使用工具的权限，这将 信任他人，尤其如果你想要的话。 解锁诸如获得法学硕士学位之类的东西。 替你回复邮件，或者干脆不回复。 但可以帮你排序或选择 替你做这些事之类的。我 我不知道今天我是否还会授予法学硕士学位。 可以访问我的电子邮件，对吗？我的意思是…… 这就像冒了很大的风险。 我觉得最后一个还挺酷的。 关于工具使用方面的问题。我认为 你暗示过这一点，我们俩都…… 我们各自以自己的方式看待这个问题，那就是 开放式模型与封闭式模型使用的工具 开放模型的运作方式截然不同 人们走向拥抱的脸，而你 下载模型，然后下载该人的模型。 会想：哦，我想要什么工具？ 我不知道我的搜索是什么 首选搜索提供商，但有人 其他人可能更关心不同的搜索方式。 创业公司，你在那里发布模型 需要适用于多种工具 适用于多种使用场景，这确实 难就难在你表现得像个 通用推理引擎模型，即 实际上，GPOSS 的优点是什么？但是关于 封闭模型，你正在深度整合 将特定工具融入您的体验中。 我认为开放模式将会 有些事情难以复制。 我喜欢用封闭模型来做这件事。 那就就像我不知道，你可以 参考公共和私人混合体 信息。还有一件我一直珍藏的东西。 我每隔3到6个月尝试一次，就像…… 网络上的代码库，它只是 促使模型进行更新 我的一些GitHub仓库。和 就像那种安全感一样。 云环境真是太棒了 就像把它寄出去，然后做这件事一样 然后回来找我。而这些将 可能有助于定义一些本地问题 开和关 细分市场。但我认为最初是因为 当时大家都在争相获取这些工具。 利用开放模型的工作方式 后脚有点像 不可避免的。我觉得有很多东西。 这些资源中有很多资源 前沿实验室，但当……时会很有趣 开放模型可以解决这个问题，因为它…… 可能需要更多一些 灵活且可能很有趣 可能适用于此的模型 递归思想就像是一个 编排器和工具使用的模型。所以 希望这种必要性能够推动一些事情的发生。 那里的创新很有意思。所以 持续学习，嗯，这是 长期以来 我认为这是一个非常重要的问题。 随着成本的增加，其重要性也日益凸显。 模型训练量增加。所以可以 请解释一下什么是持续学习。 以及它在今年可能有多重要 并在未来几年内做出 进步。这与此密切相关 某种程度上，科幻小说中关于通用人工智能（AGI）的时代精神是这样的。 什么是人工通用 人工智能以及什么是人工智能（ASI） 超级智能是什么？ 我们今天拥有的语言模型 能够做到。我认为语言 模型可以解决很多问题，但是 人工智能领域的一个重要里程碑是 本质上，当人工智能可以取代任何事物时，人工智能就可以取代任何人。 远程办公人员接收信息 解决并完成数字任务。 而我则强调了这一局限性。 人们认为语言模型将 没有以同样的方式从反馈中学习。 那是一名员工。所以如果你雇佣了一个 编辑器，编辑器会出错，但是你 我会告诉他们。如果你雇佣了一位优秀的 编辑，他们不会再这样做了。但 语言模型不具备这种能力。 自我改造并学习 迅速地。所以我们的想法是，如果我们要去 实际上要达到某种程度 就像一般的适应性智能一样 可以融入任何远程工作中 在这种情况下，它需要能够学习 从反馈和工作中快速获得信息 学习。 我个人更看好语言领域。 通过提供模型来实现这一点 它们都配有非常好的背景信息。你说 就像你可能在线下说过的那样 你可以撰写大量文档 在这些模型中，你会说我拥有这一切 信息。以下是所有博客文章 我写过的所有文章。我喜欢这种类型的 写作。我的声音就是基于此，但是 很多人不提供这个 模型，而且这些模型并非设计出来的。 要考虑到这些背景信息 以前就像aentic模型一样 刚开始，所以是这种状态 权衡利弊，我们是否需要更新 该模型的权重与此有关 持续学习才能让他们成为那样的人 快速学习，否则反驳的观点是：我们 只需要给他们提供更多 背景和信息，以及他们将 看起来像是学得很快 只是需要很多背景信息，并且 非常聪明，所以我们应该提一下。 这里涉及一些术语，所以需要持续学习。 指的是改变权重 持续 以便模型能够根据实际情况进行调整。 对新传入的信息这样做 持续快速且频繁地 很快。呃，然后就是你那件事。 另一面提到的是 通常指在上下文中 学习。当你学习新知识时，会发现…… 巨大的上下文窗口。你可以继续 每次都用额外信息加载它 你提示系统的时候，我 认为两者都是合法可见的。 作为学习的一部分。 这只是你所在的地方的一个不同之处。 进行学习。 说实话，我觉得应该继续。 学习权重更新。 我已经有不同口味的了。 我的意思是，如果你仔细想想，我 我认为这里的区别在于你是否…… 在个性化定制模型上进行操作 对于每个人来说，或者你在全球范围内这样做吗？ 模型比例，我认为我们有这个。 已经从GDP 5升至5.1了 以及 5.2。或许不会立竿见影，但它 它就像一次精心策划的快速更新 精选更新，呃，那里有 你知道的，反馈就是它 无法通过社区获得反馈。 他们更新了下一代模型的权重， 所以，我的意思是，有点像…… 那种味道，嗯，还有更精细的等级 例如，一个更细致的例子是： RLVR 你运行它，它会更新问题。 你不能对每个都这样做。 因为太贵了，所以不建议给别人。 更新每个人的体重 我认为这就是问题所在，除非 你明白我的意思，即使是在 OpenI 规模下也是如此。 建造数据中心也太…… 昂贵的。我认为这是唯一可行的办法。 一旦设备上有了东西。 成本由消费者承担，例如 苹果试图用苹果做什么 将它们置于基础模型之上 打电话，然后他们从电话中学习 经验。虽然有点相关，但 呃，这种……也许 拟人化的术语，但记忆 有哪些不同的观点？ 如何向这些设备添加内存的机制 正如你越来越多地看到的那样，系统就是这样。 如此个性化的记忆，尤其如此 所以现在主要就是……呃，背景。 基本上就是把东西塞进去 然后回忆起当时的语境，但 我觉得它还是太贵了。 因为你必须像我的意思是你可以 c 但它仍然需要花费代币。 第二点是你只能这样做。 很多。我觉得它更像是…… 个人喜好或风格。我的意思是很多 人们在解数学题时会这样做。 问题。你说，呃，基本上就是你 可以补充之前的知识等等，但是 你也对它有某种偏好。 提示。做我上次喜欢做的事 诸如此类。但 它确实不会解锁新的内容。 能力。所以，就那一件事而言 人们仍然使用 Laura Laura 适配器。这些基本上是用来代替 更新整个权重矩阵 是两个较小的权重矩阵，即 你有点像是在并行或叠加。 就像三角洲一样，但是嗯，是的，你你 在某种程度上可以做到这一点，但是 再说一遍，这是经济学，所以…… 还有论文，例如劳拉学到的。 少了，但忘得也少了，就像你知道的那样 要想学习，就没有免费的午餐。 你需要使用更大的重量，但是 变得更贵，然后如果 学得越多，忘得越多，而且…… 就像你必须找到那个金发姑娘一样 区域基本上 我们其实很少提到这件事，但是 这段讨论中隐含的意思是 上下文长度也有很多 那里有可能出现的创新 我认为这是人们普遍接受的。 这是一个计算和数据问题。 在你能做到的地方，有时就像 小型建筑相关的东西，比如 注意力差异，所以如果你有我们 谈到混合注意力 模型，这本质上是指如果你有 看起来像一个状态空间模型 在你的变压器内部，就像那些 更适合，因为你必须 用更少的计算资源来模拟最远距离的情况 沿着标记。而且我认为，但是那些 它们并非免费，因为它们必须是免费的。 伴随着大量的计算或嗯 正确的数据。那么有多少序列 你在世界上拥有10万个代币吗？ 这些东西从哪里弄来的？我觉得 结果就是价格相当昂贵。 以扩大规模。所以，我们已经到了…… 很快就达到了一百万代币。 输入上下文长度，我会 预计它会继续增长，而且会如此。 达到两百万或五百万吧 今年，但我预计不会发生这种情况。 就像一亿。那将是 就像一次真正的突破。我觉得 这些突破是有可能实现的。喜欢 持续学习这件事，我想到的是…… 作为一个研究问题，你可以…… 或许会有突破性的进展，只是 使变压器的工作效率大大提高 而且价格便宜。比如这些东西 很多科学现象都可能导致这种情况发生。 注意，但转动曲柄就会是 随着时间的推移，持续增长。我认为 我也考虑了极端情况。 天下没有免费的午餐。所以，那一个 为了尽可能降低成本，你采取了极端措施 假设有一个具有单个 SPA 的 RNN。 你保存所有内容的状态 之前的内容。这就像一个特定的u 固定尺寸的物品。所以你从来没有真正 培养记忆力，因为那是你。 把所有东西都塞进一个州。但 那么，上下文越长， 你忘记的信息越多，因为你 你不能……你不能……我的意思是压缩 全部整合到一个状态。然后是 另一方面，你还有变压器。 它试图记住每一个令牌， 有时候，如果你想看的话，这很棒 提供具体信息，但非常 因为有KV缓存，所以价格昂贵。 增长的 um 点积增长 但就像你说的，曼巴蛇 我的意思是，它们都具有相同的层次。 问题就像你尝试使用循环神经网络（RNN）一样。 将所有内容压缩到一个状态 在那里，你的选择会更挑剔一些。 我觉得这就好比金发姑娘的故事。 他们再次使用 Neimotron 3 进入该区域。 就像关注度的良好比例一样 全局层需要哪些？ 信息涵盖一切 与拥有这些相比，更容易获得 压缩状态，我想就是这样。 我认为我们可以通过寻找方法来扩大规模。 更确切地说，是金发姑娘比例。 就像介于两者之间的区域，比如计算之类的 使其运行成本足够低，但 也使其拥有足够的力量成为 这里还有个有用的信息，另外再补充一点。 递归语言模型论文 其中一篇试图……的论文 先解决长篇背景问题，那又怎样？ 他们发现的本质上是代替 把所有东西都塞进这个长长的 上下文：嗯，如果你把它分解成这些 较小的，嗯，多个较小的任务，所以你 通过创建多个较小的文件来节省内存。 你可以获得更好的通话质量 比让LLM尝试更准确 一切都同时发生，我的意思是，这是一个全新的局面。 我们将会看到你明白的范式。 可能还有其他口味，所以我 想想我们还能做些什么 改进长篇上下文，但随后 就像内森说的那样，我认为 问题在于预训练本身。 没有那么多长篇上下文文本 文件与其他文件一样。所以是 学习起来更难，基本上就是学习管理系统（LMS）的学习。 表现得像那样等等。 等级。就像有一些规则一样 拇指基本上就是你预先训练的地方 就像我们预先训练的语言模型一样 例如 8k 上下文长度，然后扩展 经过训练可以达到 32k，还有一些 经验法则，就像你一样 基本上是将训练量增加了一倍 上下文长度大约需要 2 倍的计算时间。 那么你通常可以喜欢两到四倍 再次检查上下文长度。所以我认为 很多事情最终都变成了某种样子。 预训练时的计算边界是 就像我们之前讨论的那样，每个人都在谈论这件事。 关于计算能力的大幅增长 今年的顶尖实验室，这应该 在一些更长的上下文窗口中反映出来 但我认为在训练后方面 还有一些更有趣的事情 因为我们有代理人，所以代理人 我们将管理此上下文 他们自己的，现在使用的人 云代码很多人都害怕压缩 这时克劳德完全接管了它。 10万份工作和合同 把它整理成项目符号列表，但接下来呢？ 模型可以，但我不是小说家。 当然，已经有人在研究这个问题了。 本质上，该模型可以控制 它何时压缩以及如何压缩，以便您可以 本质上就像训练你的强化学习算法 其中压实是一种动作 它缩短了历史，然后 问题表述将是：我想要 为了保持最高的评价分数 我在模型中得到的 将其历史压缩到最低限度 因为这样才能达到最短长度。 你需要完成的代币数量 这种复合汽车 激进预测，所以它实际上是 这里面的问题设置相当不错。 其中，类似这些智能体模型 学会运用它们的语境 这不是一味地向前耕耘。 最近一个有趣的例子 应该是 Deepseek 版本 3.2，其中 他们喜欢那种稀疏的关注。 他们基本上拥有的机制 就像一个非常高效的小型轻型设备 索引器，而不是关注所有 它选择的令牌，好的，哪些令牌？ 我真的需要它吗？我的意思是，它是 几乎又回到了最初的想法。 注意力，你有所选择，但 注意力总是集中在你身上，也许 有些重量为零，但你可以使用 它们都一样，但它们更像 好吧，我们还是把那部分屏蔽掉吧，或者像这样 甚至连那都不要做，即使…… 滑动窗口的注意力也 有点像那种想法，你有那种感觉。 固定式卷帘窗 因为你不需要所有东西 时间。偶尔，有些层你 或许可以，但这很浪费。但就目前而言， 我觉得，是的，如果你把所有东西都用上的话。 你这样做很安全。它给你 性价比最高，因为你 绝不错过任何信息。而现在，我 认为今年也会更加…… 正如你所说，花了一年时间才弄明白如何 在这方面要更聪明些。我认为是对的 现在人们想要下一个 最先进的 最先进的技术恰好是 蛮力攻击是昂贵的手段，然后 一旦你拥有了它，就像你说的，保留它。 呃，准确性嘛，不过我们来看看我们怎么做。 现在可以更便宜地做到这一点，就像你耍的那些小技巧一样。 知道 是的，所有关于规模化的东西，比如…… 我们选择 Quad 4.5 Sonnet 型号的原因 首先是因为你可以训练它。 速度更快，而且你不会击中这些目标。 尽快计算出墙体，它们就可以…… 尝试更多方法，最终得到模型 即使更大的型号速度也更快 实际上更好。我认为我们应该说 有很多令人兴奋的东西 人工智能领域正在发生的事情。嗯，我的脑子里有 最近一直非常专注于 机器人技术。所以，我们今天实际上几乎 完全没有谈到机器人技术。呃 关于图像生成有很多东西。 视频生成。 嗯，我觉得可以公平地说…… 最令人兴奋的研究工作 强度 呃，热情存在于LLM空间中，即 为什么我认为我们有理由这样做 真正专注于我们正在攻读的法学硕士学位 正在讨论。但如果能带来就太好了 在某些特定情况下，可能是 有用。例如，世界模型。 人们对此越来越兴奋。做 你认为这会有什么用处吗？ 来年将迎来世界模型法学硕士（LLM）的学习。 空间？ 嗯，是的。我也认为法学硕士也是如此。 这里有趣的是…… 想想如果我们能解锁更多LLM能力会怎么样 它还会自动解锁所有内容 其他字段是否解锁，但 就像这样，进展会更快，因为你 认识很多研究人员和工程师 就像我们之前说的，使用LM进行编码，这样即使 如果他们从事机器人方面的工作，如果你喜欢的话。 优化这些LLM，它们将帮助您 你知道，编程就像是种回报。 但是，嗯，是的，所以世界模型是 有趣的是，它基本上就是你所在的地方 让模型运行模拟 从某种意义上说，这个世界就像一个小玩具。 真正的东西可以再次解锁 诸如此类的能力是洛克希德·马丁公司（LM）的。 不知情的情况下，它可以模拟事物， 呃，我觉得这就像…… 想想那些法学硕士，他们碰巧也工作。 通过预先训练，然后进行…… 下一个代币预测，但我们可以这样做 这甚至有点像你知道的 从某种意义上说，我很老练，所以我是 这么说就像……我觉得…… 这是纸质 kod 世界模型的问题。 嗯，所以他们基本上是应用了 再次将奖励模型的概念引入LLM 他们之所以这样做，不仅仅是拥有。 下一个代币预测和可验证 奖励检查答案正确性 他们还确保中间环节 变量是正确的，你知道，就像这样 有点像模型正在学习 从某种意义上说，它本质上是一个代码环境。 我觉得这很有道理。 这样做虽然很贵，但是…… 就像让事物变得更加复杂 就像建模一样，嗯，就像建模整个过程一样。 不仅仅是结果，呃，所以它 可以增加更多价值。我记得我 曾是一名研究生，嗯 所以有一个名为 CASP I 的竞赛 想想他们在哪里研究蛋白质结构 预测就像他们预测的那样 蛋白质的结构并非 当时这个问题尚未解决。所以从某种意义上说 这真是太好了，我认为我们 也需要类似的资源用于法学硕士项目。 你在那里做基准测试，但没有人 所以你提交了结果，但没有 一个人知道答案，然后…… 有人透露了这件事，但是呃 Alpha Fold一问世就大获成功。 呃，你知道这个基准，我的意思是那里 也有多次迭代，但我 还记得第一个吗？嗯，我不是…… 该子领域的专家，但首先 其中一个明确地对物理量进行了建模 你知道物理学中的相互作用 分子也像角度一样 不可能的角度，然后是下一个 我认为他们已经把这个版本去掉了。 所以，仅靠蛮力扩展就能做到 向上，我认为我们目前使用 LMS 正处于 在这种蛮力扩展中，因为它 碰巧有效，但我确实也这么认为。 在某些情况下，这样做或许是有意义的 把这个“你”的东西带回来，我觉得…… 世界模型，我想那就是我所在的地方。 我觉得这可能真的挺酷的 嗯，我的意思是，是的，当然也包括为了 机器人技术，那完全是…… 与LMS无关。 是的。是的。在机器人学领域，这非常 明确地。所以问题就在这里： 运动操控。运动是 很多问题都已解决，尤其是在…… 学习领域。但有很多 与初始蛋白质一样，其价值也相同。 折叠系统引入 传统模型方法。 所以你不知道，这不太可能 你可以学习这种操控方式。 或全身局部操作 问题从头到尾。 这就是梦想。但后来你意识到 当你领略人类的奇妙之处 手和现实的复杂性 你会意识到，在这个世界上，这真的很难。 一路学习下去，我 我猜是 AlphaFold 2。我很期待。 我觉得应该考虑机器人学习空间。 它整体上变得越来越像 所有的兴奋都让我兴奋不已 对语言模型的投资总体而言 他们现在的情况就像…… 培训变压器的基础设施 这就像一个通用的建模方法 正在成为世界级工业 无论在何处，只要有工具，那就是 机器人技术的局限性就像…… 好得多，计算能力更强了。 然后，除此之外，他们还会服用这些 语言模型并将其用作某种 您可以在此处的中央单元进行操作 围绕这些有趣的探索性工作 它某种程度上已经奏效了， 然后我看到它逐渐演变成某种…… 就像我们之前讨论过的拥抱脸