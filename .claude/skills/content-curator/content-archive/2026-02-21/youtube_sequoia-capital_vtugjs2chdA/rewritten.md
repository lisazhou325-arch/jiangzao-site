1. "提示工程让 AI 回答得更好；上下文工程让 AI 思考得更好。"
2. "我们没有换模型，只是优化了 harness，排名从第 30 名之外跳进了前 5。"
3. "上下文腐烂是长时程 agent 的头号杀手——关键指令被淹没，决策质量开始崩塌。"
4. "Ambient agents 不等你发指令，它们监听事件流，在你需要之前就已经在工作了。"
5. "记忆将成为 agent 产品的护城河——从历史 traces 中学习并更新指令，这才是真正的持续智能。"

📝 创作说明
嘉宾：Harrison Chase
选题方向：LangChain 创始人 Harrison Chase + 上下文工程如何解锁长时程 Agent
内容评分：信息密度 9/10，数据支撑 8/10，洞见深度 9/10
目标字数：2100 字
核心价值：揭示 agent 工程的核心瓶颈与解法，以及从对话框 AI 到环境感知 AI 的范式转变

---

## 不换模型，排名从第 30 跳进前 5

2025 年，LangChain 的工程团队做了一个实验。

他们参加了 Terminal Bench 2.0 基准测试——一个专门评估编程 agent 能力的榜单。底层模型没有换，只是重新设计了 agent harness（agent 脚手架）的工程逻辑。结果：得分从 52.8% 提升到 66.5%，排名从第 30 名之外跃升至前 5 名。

这个结果让很多人不舒服。因为它意味着：你花大价钱追的那个最新模型，可能不是你 agent 表现差的真正原因。

Harrison Chase 在 Sequoia Capital 的播客上把这个实验当作切入点，讲了一件他认为整个行业都没想清楚的事：**长时程 agent 的核心瓶颈，不是模型，是上下文管理。**

## 提示工程已死，上下文工程才是正题

LangChain 在 2025 年的官方博客里给出了一个定义：

"上下文工程是一门艺术与科学，研究如何在 agent 执行路径的每一步，都恰到好处地为其上下文窗口填充所需信息。"

Andrej Karpathy 用更简洁的方式说了同一件事："在下一步所需的时机，用恰好合适的信息填满上下文窗口。"

这和提示工程有什么区别？

提示工程关注的是单次请求的措辞——怎么问才能让模型回答得更好。上下文工程关注的是整个任务执行过程中，模型能"看到"什么——历史记录、工具输出、检索结果、记忆片段，全部加在一起，构成了模型做决策的信息环境。

一个类比：提示工程是写好一条 SQL 查询；上下文工程是设计整个数据库的 schema、索引策略和视图定义。

为什么这个区别在 2025 年突然变得重要？因为 agent 开始真正跑起来了。

## 长时程 Agent 为什么现在才能用

Harrison Chase 在 2022 年 10 月以业余项目的形式创建了 LangChain，当时他还在机器学习初创公司 Robust Intelligence 工作。最初的 LangChain 是一个概念验证：把 LLM 和工具连接起来，看看能做什么。

那时候，"让 LLM 在循环里跑"这个想法已经存在了——AutoGPT 就是典型案例。但实际效果很差，更多是演示而非实用。

Chase 的判断是：现在不一样了。"长时程 agent 终于开始真正工作了，尤其是在编程和研究领域。这背后有两个驱动因素：更好的模型，以及更成熟的 agent harness 工程。"

模型的进步是显而易见的。但 harness 工程的成熟，才是 LangChain 真正押注的地方。

## 上下文腐烂：被忽视的头号杀手

当一个 agent 开始执行多步骤任务，上下文窗口会发生什么？

工具调用的输出、检索到的文件内容、对话历史、中间推理结果——这些东西会不断堆积。即使模型的上下文窗口已经扩展到几十万 token，问题依然存在：**关键指令会被淹没在噪音里，模型的决策质量开始下降。**

Chroma Research 在 2025 年 7 月的研究证实了这一点：即使对于简单任务，随着输入长度增加，模型准确率也会持续下降。这个现象有个名字——"上下文腐烂"（Context Rot）。

LangChain 提出了四种应对策略：

**Write（写入外部存储）**：把中间结果持久化到上下文窗口之外——文件系统、数据库、向量存储。不要让所有东西都堆在窗口里。

**Select（按需检索）**：只在需要时把相关信息拉进上下文。RAG（检索增强生成）是这个策略的典型实现。

**Compress（压缩）**：对工具输出和历史记录做摘要，保留关键细节，丢弃冗余。

**Isolate（隔离）**：通过多 agent 架构，让每个子 agent 只处理自己的上下文片段，防止不同任务的信息相互干扰。

这四个策略，构成了 LangChain 在 2025 年推出的 Deep Agents SDK 的核心设计逻辑。

## LangGraph：把 Agent 变成有状态的图

要理解 LangChain 的技术路线，必须理解 LangGraph。

LangGraph 是 LangChain 推出的 agent 编排框架，核心理念是：把 agent 的交互过程转化为有状态的图结构（stateful graph）。每个组件是图中的一个节点，节点之间的连接定义了信息流动的方式。

这个设计解决了一个关键问题：状态管理。

传统的 agent 实现往往是无状态的——每次调用都从头开始，没有记忆，没有上下文延续。LangGraph 通过检查点（Checkpointing）机制，让 agent 可以暂停、恢复，甚至"时间旅行"——回到某个历史状态重新执行。

更重要的是，LangGraph 原生支持人机协作（Human-in-the-Loop）：在关键决策节点暂停工作流，等待人工审批或干预，然后继续执行。这对于需要高可靠性的企业场景至关重要。

LangChain 的 B 轮融资 1.25 亿美元、估值 12.5 亿美元，投资方包括 Sequoia、Benchmark、CapitalG 等，很大程度上押注的就是 LangGraph 在企业 agent 编排市场的潜力。

## 记忆：Agent 产品的真正护城河

Chase 在播客中提出了一个让人印象深刻的判断：**记忆将成为 agent 产品的核心竞争力。**

他把 agent 的记忆分为三种类型：

**语义记忆（Semantic Memory）**：关于世界的事实性知识——用户的偏好、公司的业务规则、领域知识。

**情节记忆（Episodic Memory）**：agent 过去行动的示例——"上次遇到这种情况，我是这样处理的"。

**程序记忆（Procedural Memory）**：给 agent 的指令或提示——随着使用经验积累，这些指令会自动更新和优化。

LangChain 为此推出了 LangMem SDK，专门处理跨会话的长期记忆。核心能力是：从历史 traces 中学习，自动更新 agent 的指令（程序记忆）。

这意味着什么？一个 agent 用得越久，它就越了解你的工作方式，越能预判你的需求。这种持续学习能力，是封闭系统很难复制的。

"持久记忆——从历史 traces 中学习并更新指令——将成为护城河，并解锁持续的价值。"Chase 说。

## Ambient Agents：下一个范式

Chase 在 AI Ascent 2025 和 Interrupt 2025 上提出了一个更激进的愿景：**Ambient Agents（环境感知 Agent）**。

今天大多数 AI 产品的交互模式是：用户发出指令，AI 响应。这是"对话框 AI"的范式。

Ambient agents 不一样。它们不等你发指令，而是持续监听事件流——邮件、Slack 消息、日历变动、系统日志、代码提交——在检测到需要处理的信号时，自动启动工作，在需要人工决策时才打断你。

这是从"工具"到"同事"的转变。

为了让这个模式可用，Chase 提出了"Agent Inbox"的概念——类似电子邮件收件箱，但收集的是 agent 需要人工审批或决策的请求。你不需要盯着 agent 跑，只需要定期处理它发给你的"待办事项"。

但他也强调了一个前提：**信任需要人机协作机制来建立。** 即使 agent 越来越自主，也必须保留用户审批、干预和回溯调整的能力。没有这个机制，ambient agents 只会让人焦虑，而不是解放生产力。

## Agent Engineer：一个新职业正在诞生

Chase 在 Interrupt 2025 的主题演讲中提出了"Agent Engineer"这个概念——一种融合了编程、提示工程、产品感知、机器学习理解和业务流程转化能力的新角色。

这不是软件工程师的升级版，也不是数据科学家的变体。它是一个全新的职业形态，需要同时理解：模型的能力边界在哪里、业务流程如何被拆解成 agent 任务、如何设计 harness 让 agent 可靠运行、如何评估和调试 agent 的失败模式。

LangSmith——LangChain 的可观测性和评估平台——正是为这个角色设计的。"好的评估始于好的可观测性"，Chase 说。Klarna、Elastic 等企业已经在用 LangSmith 追踪 agent 的行为，理解它在哪里失败，以及为什么失败。

从 2022 年的业余项目，到 2025 年的 12.5 亿美元估值，LangChain 走过的路，其实是整个 agent 工程领域从概念到实用的缩影。Chase 的判断是：2025 年是长时程 agent 的元年，而上下文工程，是这个元年里最被低估的核心技术。

不换模型，排名从第 30 跳进前 5。这个实验的意义，远不止一个基准测试的成绩。
