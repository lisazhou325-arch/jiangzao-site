And I think if you sort of try to shoehorn an AI into these like tiny little boxes and then you add, you know, kind of this code layer around it, you're sort of missing the point of what can be done with AI today. I think if you build, you know, for the ability for these AI agents to take any standard operating procedure and be able to run that process end to end, that's the direction that we're sort of taking at at pace. On this episode of Training Data, we sit down with Jamie Cuff, the founder and CEO of Pace to explore how AI agents are quietly revolutionizing insurance and what that means for the future of work in high complexity, highly regulated environments. Jamie shares why the real breakthrough isn't just automating tasks, but architecting AI to handle nuanced endto-end processes previously thought to require a human touch and human judgment. We dive into building trust with some of the biggest and oldest companies in the world, why forward deployed engineers are becoming a secret weapon for AI companies, and how AI replacing BPOS could fundamentally rewire entire sectors of the economy. Enjoy the show. &gt;&gt; Jamie, thank you for joining us. &gt;&gt; Thanks for having me. It's great to be here. um we would love to dig right into what you're building. I'm curious, you started a company last year. What are you building and why? &gt;&gt; Yeah, so PACE is the agentic process outsourcer for insurance. Um and what that means is you know we have seen over the last you know couple of decades big shift from onshore to BO work and our thesis is that over the next decade we're going to see a big shift from outsourcing to outsourcing to AI and so we focus exclusively on insurance carriers helping them to automate a lot of the critical back office operations that traditionally are being outsourced to BPOS. &gt;&gt; Can I ask about the path that brought you here? So top your class at Princeton, investor at Sequoia, rising star at Retool, insurance BPOS. Not obvious that that would have been the next step on the journey. Can you explain kind of how you got there? &gt;&gt; You know, it's a secured path. And what's what's funny is I actually started there. So I I grew up around insurance my whole life. I was I born in London, grew up between New York, London, and Bermuda, which are kind of all the the capitals of insurance. And the through line there is um my dad actually ran operations for a reinsurer and then a Lloyd's cover holder in London. And so I kind of always knew about this problem. Um but you know starting my company out of out of college didn't like immediately run towards that until I got to retool and actually retool a ton of our customers came from financial services. Um and you know from the outside I think a lot of people think of retooling and think startups but you know retools is really attacking a lot of this you know bigger market around custom software and the places where there's most custom internal tooling are the businesses that are most operationally intensive and financial services firms are a lot of those because they don't have a lot of great software that's been built off the shelves. And so what we were seeing is a lot of like very large you know legacy insurers um were using retool all the way through to the most tech forward ones you know had like the ethoses and the vouchers you know those types of businesses all the way through to progressive and bircher halfway and businesses like that at that point was you know being in a forward deployed engineering capacity you kind of get this front row seat to seeing a lot of the problems that that you know these companies are are handling um was really cool is a lot of times people would build retail applications that would actually help to streamline some of their BO operations. And so I got to sort of see a lot of the problems I think you know my dad was also dealing with in his business of you know policy administration uh claims submission intake you know a lot of the core workflows that are critical to insurance operations um and at the time you know I think with software you can make a little dent on on BO spending you can make it like 10% better um and I think that was like a lot of the promise of you know OCR and and RPA and some of these uh sort of prior technologies ies. But what happened after the chat GPT moment and you know when I was lucky to be working on a lot of retool AI and some of the the new products coming out of retool you saw this opportunity to now completely change the economics of that industry. Um and so instead of you know augmenting outsource services with software you could actually go and completely replace the vertical service. Um and so insurance is a particularly good starting point for that because the lingua frank of the industry is emails and PDS. &gt;&gt; Um and the main reason for that is there are a lot of intermediary players and there's no like common system on which they all work. And so you know with the lack of an API the sort of alternative is you know email, PDFs, phone calls. Um and so now you know AI agents really are have the ability to kind of bridge that gap. Um and so what gave rise to a lot of BO work which was this sort of like manual data entry handling of these documents and emails um is now also what's you know perfectly positioned this for AI agents and so we see that as a really good starting point within the sort of opportunity to build the agentic process outsourcer across many industries longer term. So Jamie, how do you build a better business than the last generation of BPOS even though you're taking over the same workflows and a lot of the same spend that's going on today? Yeah, people often ask like kind of you know what keeps me up at night and that's the main thing that's that's the main thing that I keep the main thing which is you know we are very lucky right now to be getting with you know lots of incredible customers and you have this sort of opportunity we could build you know a very large company just you know being a a BPO is you know there are multiple tens of billions of dollar public companies um that you know are running at you know 10 15% gross margin with you know tens to hundreds of thousands of people doing this work and obviously those are great businesses and um you know except exceptional teams but for us we think there's like a much much bigger outcome and so when I actually talk with our team about kind of what we're shooting for that's like that's the failure case uh so we you we build this sort of multi-billion dollar BO but don't change anything about the economics of the industry. M &gt;&gt; the goal of what we're going for is how can we take that from you a 10% gross margin business to an 80% gross margin business where instead of having hundreds of thousands of people it's hundreds of thousands of AI agents and a small team of insurance experts. Um and so that you know I think is a much much larger company. Um and then I think the last step uh is how do we do that not just in one vertical but across many verticals. And so those are the two things I think about and I think people say like okay you know push gross margins to later or it's not that important or you know I think people have a lot of perspectives on gross margins. I think it is important um and I don't think it's important to necessarily have from from day one but you need to have a path to it. And you know people talk a lot about flywheels and the flywheel that we want to create is every time we're making improvements in the product the gross margins go up. Um, and so that's the big thing that I think we're we're pushing on is, you know, even if we're lower gross margin today, as we take on harder and more complex tasks, how are we just constantly seeing that number shift up over time? &gt;&gt; As you're building with agents and starting to plug into these email and document processing workflows, I'm curious what you're seeing is working in practice. We've talked to folks from OpenAI here. We're doing fine-tuning. They have all the data. They have this amazing infrastructure. We've seen companies um with much lighter processes on the back end. What actually works for you in practice? &gt;&gt; Yeah. So a lot of the types of workflows that we focus on are these sort of like missionritical processes that are you know have been outsourced and so they want you to do that work sort of end to end. And so I think you know the the prior generation preI when you're tackling these problems yes like extracting data from unstructured documents is great but it's sort of just like one part of the problem. It's extracting it you know it's maybe reasoning over that applying the sort of human judgment and then it's also being able to sort of write back into those internal systems and really sort of solving what previously could only have been done with humans. One way you could think about this is, hey, let's build one of these sort of like workflow DAG kind of builders and sort of infuse sort of AI nodes in different places where you're like, okay, now we can do, you know, document extraction or we can do an email sending back and forth or something like that. Part of the reason that, you know, BO work exists is it was so hard to codify that work deterministically. And the reason is there was this sort of human judgment component and lots of edge cases that came came up. And I think if you sort of try to shoehorn an AI into these like tiny little boxes and then you add, you know, kind of this code layer around it, can be done with AI today. Uh I think that's actually like if that product stance is actually like relatively short on AI. Um, I think if you build, you know, for the ability for these AI agents to take any standard operating procedure and be able to uh uh run that process end to end, that's the direction that we're sort of taking at at pace. &gt;&gt; So, do you have a human in the loop right now or no? &gt;&gt; So, for the vast majority of our of our workflows, there's no human in the loop. Um, it's AI processing end to end. We do have our own operations team um that we're building out for sort of the most complex workflows and kind of the the way we see that sort of like role of human in the loop is you we have our operations team to do it. We can escalate to our customers but primarily where that is used is in the onboarding process. Um, so as we're sort of getting customers up and running, we basically want to be able to just label a bunch of examples and make sure that the agent is doing this, you know, at, you know, starting out of the box is, you know, maybe 90% accuracy and then how do we get it up to, you know, the 99.5% plus that, you know, our customers require to be in, you know, critical um, in these critical workflows. Um, and so that's sort of where we see this sort of human labeling component and then a self-improvement loop that sort of helps us get there. And then over time, we just sort of reduce the amount of human in the loop there and move that sort of operations team to work on the next most difficult task. &gt;&gt; So when you engage with an insurance carrier and they have x number of workflows that they're currently outsourcing or that could be outsourced to some sort of traditional insurance bo I presume you can't do all of them today. Yeah, pretty amazing. If you could &gt;&gt; which can you do today and and how do you engage such that you kind of pick off the workflows that are sort of really applicable to AI today and then how do you sort of grow over time to take up more of those workflows? &gt;&gt; So we tend to focus on the use cases that are one already really nicely outsourced. So they have to already be using a BO at scale. The reason for that is it's already codified as a standard operating procedure. there's already a way to um check for accuracy because you know this is already being reviewed usually by someone uh internally or at least sort of like QA on a sampling basis. The last part is sort of as you think about the change management it's much easier to sort of spin down a BO service than it is to sort of retrain or move a W2 workforce. So we start with operations team BO the large carrier. we tend to focus on the most uh high volume use cases uh where we think there's the biggest ROI. So you just look at kind of the line item for BO where are they sort of spending the most and where can they get the most ROI from AI? &gt;&gt; Usually what that means is we start at the very top of the funnel. So submission intake where they're getting in new risk extracting that data &gt;&gt; running their business logic over it and then writing back into their own you know new business underwriting platforms. The same uh can happen also on the claim side. So first notice of loss or claims intake getting that information into their internal systems. And then once you do that you know customers ask you to sort of work down the policy servicing life cycle and to you know endorsement processing and other policy administration tasks all the way through to billing and on the claim side the same thing you know from claims intake all the way through to payout and quality assurance. So that's usually the path we take. What's a typical before and after situation? You know, human EPO and then pace AI BO like what what sort of what sort of metrics change, you know, when they go from before and after? &gt;&gt; Yeah. So, it's interesting in the the BPO world. I think a lot of where you start is okay there's a new technology that can now help me save a lot of my costs and um you know with come VPOS's I think you know the MPS is quite low and it's a massive line item you know for a lot of our customers you know eight figures plus of spend and because it starts oftent times with with cost and that's big and you know for for some of our customers we've been able to achieve you know 50 to 75% cost savings um you know in a very short period of time working with them. Um but usually what happens after that is they realize that there are a number of other things that are actually much more important to them. Um and usually it's a things that previously just couldn't be done with BPOS that now with sort of AI working at superhuman speeds you now have this sort of capability to to do. So, uh, an example of that is, you know, if you think about a submission intake process, usually, uh, that carrier that's receiving that submission is not the only one that's receiving it. And so, if you can get back much faster, you can actually close business faster. &gt;&gt; Same thing, uh, you we think about scalability. So, like, you know, around uh, BO work is not just kind of like, you know, perfectly uh, linear over the course of the year. It's highly seasonal. So you can think like a gen one enrollment period or you know hurricane season like we're in right now. Um and so you know if there's a massive spike of hurricane claims you have to go and spin up a bunch of other BO uh you know workforce to do that work. And now you can have AI sort of working for you 247 to just crank through that backlog before it even becomes a backlog. Um so those are a few of them. And then I'd say the last thing is sort of observability which is a lot of this BPO work in the past has been sort of a black box. it was very hard to see kind of like what was getting done, what stage, you know, each task was in, where the bottlenecks might be. And some of this is sort of just like good oldfashioned software workflows, which is, you know, now that you're sort of able to do this work with agents and sort of be able to literally see exactly the task is taking and the reasoning and the why is you can now surface a lot of that information back to customers such they can actually redesign their workflows, not just do the same stuff that they were doing with their VP. I'm curious as you work with these massive companies with these missionritical like core business workflows such as processing claims or payouts. What does it take to actually help them succeed? Like on our end we see studies from MIT saying 95% of AI pilots fail and then we also see our portfolio companies not failing. What do you see and how do you make sure that you see a lot of companies not failing? &gt;&gt; Yes. Exactly. &gt;&gt; Yeah. You know, I think the 95% number I think, you know, hit the headlines and everyone like, "Oh my gosh, like what's going on?" Um, you know, I think the the truth is is definitely that getting AI working in production is not like, you know, a a done deal when you walk in. Um and there are certainly like you know challenges that um you know we've seen across the industry of like you know other vendors or or building in house um where you know they haven't been successful and so for us what we we really focus on is one of our core values of the company is closing a distance &gt;&gt; um and we've been lucky that every single one of our pilots has been 100% successful um and going through to production &gt;&gt; um and I'm very proud of that. &gt;&gt; Yeah. How did how did you pull that off? That's not normal. &gt;&gt; Yeah, I think the main thing is we really believe in in forward deployed engineering. Um, so uh you know I think that might be a little hot take and I'd be curious for your thoughts on this but you know my thoughts on this. You know, I think we're just taking, you know, you talked uh the other day about kind of like technology out versus customer back and we're just very much taking the customer back um point of view. You know, when we're going in there, we're going in with on-site with our customers, we're flying to them. We we deeply understand the insurance industry and we are only focused on these workflows. We have, you know, a ton of insurance experience on our team. And so that immediately as we go into these customers and they they talk to us and they're like, "Okay, they're speaking our language. They understand what we're doing." Um, but the next thing is like we have to do the hard work. And oftentimes that's doing the hard work upfront, not necessarily like, you know, once you're live in production with your seven figure plus contract. It's, you know, working with a customer as a partnership to prove out that this can work. And this is even more important in AI where people, you know, there were a lot of, you know, uh, exciting demos early on that maybe didn't pan out. And so, you know, we focus on with our customers just really helping them get to value and get to something in production as quickly as possible. So what that means is for our forward deployed engineering team um this is a team I was really lucky to build out at retool and I think at the time deployed engineering you know after me palunteer like reto had maybe one of the most like scale deployed engineering teams and the profile that really really works for for deployed engineering is basically former founders um &gt;&gt; so it's like engineers that want to be commercial or commercial people that are technical and the critical thing is just do whatever ever takes to make the customer successful. So it's understanding the use case. It's helping them when you when they need help with an AI model, we help them prompt tune and make that successful. It's diving into the operations data and figuring out how to create a really clean eval set for them. It's helping them get integrated into their internal systems. And it's all the sort of like hard work uh that actually makes these these pilots successful. Um, &gt;&gt; how do you, one thing I'm curious about because we've seen this in a bunch of the other kind of domain focused AI application companies. Do you hire AI people and teach them insurance? Do you hire insurance people and teach them AI? Do you just hire athletes and, you know, they learn as they go? How do you think about sort of the the kind of the intersection of the technical skills, the domain knowledge? What do you look for? Yeah, I think the critical thing is you got to hire both on the team and you know sit them really closely together alongside your customers and and and that way you kind of like get this constellation approach where everyone kind of like learns from each other. Um, you know, for us like that means hiring people, you know, directly from the insurance industry that have worked on, you know, exactly these sort of mission critical operations at, you know, top five carriers at scale. Uh, and then sitting them right next to, you know, a uh, you former YC founder that has, you know, worked on, you know, an AI company that is like at the cutting edge of, you know, building AI agents and then them coming together to get this done for the customer. Um, so I think it's sort of that our experience has been there's not that many people that are already, you know, ramped up on AI agents and then, you know, in the insurance world, we've been lucky to find some, you know, incredibly forward thinking people that are excited about helping usher in this change. I think part of that is, you know, people resonate with the thesis of many have worked in kind of like the BO world and they see, okay, like this is where this is where the world is going. And uh I've been super super impressed by people that we've been able to get from both of those backgrounds and their ability to pick this up really really quickly um to sort of get the full set of skills you need. And back back on the topic of Ford deployed engineers. Yeah. &gt;&gt; Is that a temporary phenomenon because the capabilities coming out of the AI world are not quite there in terms of what we need to deliver a full reliable solution to customers or do you think 10 years from now you guys still have four deployed engineers on every account? &gt;&gt; Yeah, I think I need to uh I'll answer this. I'll I'll flip the script to you of uh some of your thoughts. Um, so I actually think that you and I both agree on the end state. Um, and the short term is I think you it's hard to go wrong actually uh getting more and more deployed engineers into working with our customers. And the main reason is we have this sort of flywheel both within our customers of helping them, you know, get successful with the product and then going on to larger and larger use cases. um you know where we can really expand into this sort of like very large set of budgets that they have around BPO spend. And then the same thing um we have a flywheel sort of internally which is you know our our for deployed engineers can work inside of our product and work with our customers but they can also ship code &gt;&gt; uh and code into the brush codebase and they do and so that's something we like test the interview you know at the on-site and then you know throughout their work &gt;&gt; and so what's really important is you have this just like very very tight feedback loop of working with the customer and you see some issue and then you immediately go back and fix it. It's not like I create this ticket and I pass it to somebody else who maybe does it and then maybe I get it back to the customer. It's just so you get that done really really quickly. And so what should happen over time or we're already seeing is deployment times are going down. The amount of work that deployed engineers are doing is becoming much much higher leverage because we're sort of pushing that back into software workflows. So in the short term I'm like very pro continuing to build with our customers and build early with for deployed engineering but I agree with you that I think the long term is you like software codified workflows is ideal right you know we enable our customers to build inside of our product you know and and it's not all just for deployed le you know we maybe get the first one or two up and running and we have customers where we've turned around and now they have nine 10 in production uh because you know they have a business analyst that has just been kind like building out additional workflows. &gt;&gt; Yeah. &gt;&gt; And so that's very much you the way that we think about building the product. &gt;&gt; And I think the critical thing is when you think about a team, you got to make sure that like kind of the layers and where you're investing in the team match up with that. So if your forward deployed engineering team is like this and your engineering team is like this, you're going to have kind of a problem where you're not actually like really really investing in the product. for us right now you know uh basically 80% of our team is engineering and then we have four deployed engineering at the very top we have this go to market team um and I think as long as you keep that in balance we're going to be able to really get that flywheel going &gt;&gt; um but yeah I think the timelines is maybe kind of like the big thing that I'd be curious your thoughts on which is sort of &gt;&gt; for me I think it's okay for us to continue doing this for a long period of time is it just makes our customers successful and And you know, maybe we can check back in, you know, 10 years as we're going public. I actually think it's a great story to have in the public markets of seeing you've got this big forward deployed engineering team and you're just constantly figuring out how to make them higher and higher leverage so they can do more and more. So &gt;&gt; yeah, I think we're pretty well aligned on this. You know, our observation on this market has been maybe to overstate it a bit. If you think about bottoms up distribution versus top down distribution as two ends of the spectrum, you kind of want to be pegged out at one end or the other. You don't want to be stuck in the middle. You know, bottoms up chat GPT is a bottoms up distribution product. Open evidence is a bottoms up distribution product. Like these are not comprehensive solutions, but they are wonderful tools that people see and they love and they figure out what to do with. And I think on the top down end of the spectrum, you know, Harvey is a solution for loss. Sierra is a solution for customer communications. You guys are a solution for insurance, right? And I think if you're going to go the solution route, we're at a moment in time in this market where the thing that you're selling to your customers is kind of trust as much as anything else. Like they can see the magic of AI. They want to believe in the potential, but they can also see the issues and they can see where it can go wrong. And I think the role that you guys or Harvey or Sierra plays in some ways is just saying, "Hey, trust us. We're going to make sure you're good, right? Like we're going to make sure that this new world of AI is to your benefit, you know, and it's going to make your business better and we're going to do whatever it takes to make that happen." Y &gt;&gt; and so I think I think Ford deploys engineers in that context, you know, not only like really helps to give the customers confidence to your point, it also creates that feedback loop into the organization so that you're not theorizing as to what problems you can go solve, you're actually there where the rubber meets the road and and constantly like going deeper and deeper and deeper into their workflows. &gt;&gt; Yeah, I think that's spot on. The trust point is so important also particularly in our industry. I mean, insurance is sort of like the business of trust, you know. &gt;&gt; Yeah. We have a one of our other values is be the rock which is basically like our customers are there. &gt;&gt; Be the rock or be the rock. &gt;&gt; Be the rock. Okay, &gt;&gt; got it. Um, be the rock. And basically the the idea there is like our customers are there for their customers. They're insured on their hardest days and we are there for our customers every single day. Um, and that's what we that's what we want to do. Love it. And uh you know this industry is like the industry is built around trust. I think a lot of what we think about is working with like the most trusted brands the very very top insurers or the top end of the market building that brand of trust and credibility and the results that speak for themselves and then you know looking to you know expand through through the market. I think similar to you know Sierra and Harvey and a number of other companies have done that really really well which is you go and work with the top top customers in that industry where you can get you know they have the highest volumes they have the highest ROI they're the ones that stand the most to gain make them really successful and then the product sort of speaks for itself as you go to your next set of customers. &gt;&gt; We've gotten two values out of you so far. We got close the gap and be the rock. What else? What are the other company values? So we're two for two on good ones. What else do you have? We only have one more. Okay. Um, &gt;&gt; keep them short. Uh, the last one is uh my favorite, which is set the pace. Um, &gt;&gt; so, uh, you know, you both know me really well and, uh, I think, uh, I have like a pretty high level of like urgency and playing, maybe impatience at times, maybe just like, you know, uh, uh, I just feel, we feel very, very lucky to be in the position that we're in. I mean, it is such an amazing time to be building a business. Uh, I'm sure you all see this from your vantage point as well, to be investing in businesses as well. And we are so lucky to be working with the companies that that we're working with and to be you know charting this path and uh you know I think it's it's ours to go and and and make this future reality and so I feel set the pace really encapsulates that um you know the goal naming the company pace it's all about speed and that's a lot of the value that our customers are seeing but it's also what we want internally and then I think it's also a it's sort of intentional it's like this step a pace towards like kind of our our bigger mission. Um, and we're moving as fast as we can to get there. &gt;&gt; Nice. &gt;&gt; Tell us about that bigger mission. I'm curious where you go once you've gone deep in insurance. There's a lot of room to expand, but your your ambitions are much bigger than that. &gt;&gt; Yeah. And maybe it starts actually when I was lucky to be an intern here. Um, one thing I learned that summer was that uh Andrew Reed, his favorite company is Constellation Software. I don't know if that's hopefully that's still the case. &gt;&gt; I'm pretty sure technically we'd have to say that his favorite company is Figma. &gt;&gt; Figma. Yeah. Okay. &gt;&gt; Or Robin Hood or CLA or you know &gt;&gt; we can uh we can rerun this to say his favorite nonsequoia portfolio company in the public market. not investment advice is constellation. up. Um and uh so uh for those who don't know about constellation and I think what is really really exciting about that company um you know until actually I think last week was you know run by this incredible founder Mark Leonard uh who built this company for 30 years and his vantage point was let's build a business that can span many many different verticals and what they did in software ware was basically aggregate all of these niche vertical industries that in and of themselves were not you know scaled enough to to be sort of like legendary long-term businesses but at scale in a sort of federated model that they have is an incredible business that's you know compounded massively over the last couple of decades in the public markets to I think one of the largest companies in Canada you know like 70 80 billion dollars and there's this really interesting opportunity right now to do kind of the same thing that was done in software but for the services market. &gt;&gt; Um you know as as we've talked about the services market is like orders of magnitude larger and so if you look at BO spend uh BO spend in just banking financial services insurance which is sort of the markets that we see immediately in front of us um is about 400 billion a little bit under 400 billion &gt;&gt; about the same as global cloud software &gt;&gt; every year. &gt;&gt; Yeah. 70 billion of that in insurance and basically have the full BFSI BO spend the same as like all cloud software. And so you know if we can be a platform on which you can aggregate all of these niche vertical services across BFSI and maybe beyond longer term there is just a huge opportunity there and I think the most interesting opportunity is that it's not just about aggregating them it is also about transforming the economics of the industry. Yeah. Yeah. This is one of the things that I think is interesting about about PACE or other kind of domain specific application layer AI companies is a lot of the markets that people are going into are are like sneaky big, &gt;&gt; you know, much bigger than you might realize because they're not household names. They're not B2B SAS products, right? &gt;&gt; Um the other thing that I think is interesting, and you alluded to this earlier, but um I just want to hit on it again. Um this idea of going after the BO spend, right? You have a clean interface with your customer because there's already an interface between the customer and the BPO. You have um concretely defined objectives because they have to define those to be able to interact with the BPO. You sort of have built-in eval because when that work comes back, they're checking it somehow to make sure that it's actually right. And a lot of times they're doing, you know, champion challenger models with different BPOS. Yep. And so I feel like this interface that you found, it's not just the it's not just that the services spend is big. It's also that the sort of the route to market that you've chosen with the BO interface is also like a really clean way to do it. And I think that that strikes me as an important aspect of what you're building too. &gt;&gt; Yeah, I think that's exactly right. I mean I think a lot of our customers are really tuned into the fact that AI has this opportunity to dramatically transform their business particularly in areas where there is this high volume of highly repetitive tasks that require you know human judgment. you look at your BO and that's exactly where that is and the fact that there's already the standard operating procedures that we can model in our product and then you know the ability to do the accuracy checking of the built-in eval also do the change management afterwards much faster so that customers can really get you know hard cost savings hard ROI savings is really great and then it's also helpful you know as we go to market with our customers is that there's a baseline in place And you know transparently sometimes that baseline is not as high as we think it you know should be. Um you know the the average accuracy rates in um APOS is like you're making 5 to 10% error rates. And that's like that's you know kind of where I think most people feel it is. But for some of our customers we've seen it's actually like much much higher. And the main reason is like if you're doing, you know, when people talk about accuracy, you know, with AI, they're usually like, okay, is the can the AI be as accurate as a human? We think in some a lot of the use cases we're working on, it could be way more accurate. &gt;&gt; And the reason is so like let's say you're doing like a claims QA or a policy QA, you've got a 300page document, you know, maybe this big claims file and you've got like hundreds of rules. &gt;&gt; Yeah. And you know, if you're looking at this thing at, you know, the 15th on a Friday and you're trying to figure out, okay, how do I apply these like hundred rules to this policy document, you know, that's that's a really hard task for any any person to do. And chances are you're going to miss some, you know, on page 298 of this, you know, 100page rule list. And that's something that AI is really, really good at and can do that same thing, you know, at the same quality every single time. And so the consistency you can have, you can really scale your best BPO rep. That's I think they kind of like promise. &gt;&gt; Yeah. I think anybody who's ridden a Whimo in San Francisco, you know, appreciates the benefit of like a driver that always has perfect attention, has seen every corner case a million times, you know, like I think that we have the existence proof that a properly trained AI can do a lot of jobs better than most people. And I think applying that to all these other verticals makes sense. &gt;&gt; Tell us a little about what it looks like concretely when you're on site with a customer. like what are some of the things that you're hearing from them? What how do you get implemented and then what are the metrics that you track to at the end to make sure that you were successful? Like we've talked at a high level. I'm curious just to get some specific examples. &gt;&gt; Yeah, absolutely. Um so a lot of our uh engagements start with you know we usually start with kind of the the office of the COO. So really understanding, you know, where do they is the opportunity for AI and coming together on some sort of I hesitate to say proof of concept because I actually think like PC's are not really you kind of get this bad rap and they're not really the right thing to do in AI. It's basically just like get them to success as quickly as you can. And so what we focus on is like it's not like on dummy or demo data. It's like how can we actually go in and and make them successful. So we pick something to work on and then uh what's really critical is you define the success criteria up front which is like where do we want to get to and sometimes like you know we encourage customers to give us like their hardest success criteria like we we want to show them that like you know we feel confident in our product and and uh we're up for that challenge. Um &gt;&gt; and so to find us success criteria up front is really really important. Um, and then it's really about like having this great partnership and we're super lucky with that with a lot of our customers is you can just we fly on site. We work with them. We we take in their st existing standard operating procedures and these are usually like these documents that are, you know, 50 to 100 pages long. They have like 60 different steps and it's like, you know, there'll be like a highlight in this document of like you got to get this thing out from here and then you got to enter it into this like admin panel and there'll be a little like red box around it. Like it's crazy. Like are there are there like shadow SOPs? So like if you just implemented the standard operating procedures exactly as they're given to you, would that actually give them what they want or are there kind of like &gt;&gt; shadow rules that are not codified in the document that you would figure out over time? Like people are actually doing things a little bit different than what the procedures say. &gt;&gt; Yeah. So I think we're lucky that because we work mostly on BPO workflows, they had to be like pretty well codified because like you know you got to hand these off to folks, but there is always a little bit of gap there. And that's part of what when you close the distance to the customer, you like figure that out really quickly. &gt;&gt; Going back to it, basically we take these standard operating procedures, we get them into our what we call agent operating procedures. And so in our product that means is there's sort of it's almost like a notionlike document where you can basically write out all the steps that you're that you need to do in natural language and then use various different tools along the way that are spec you know enable these agents to do everything that they would need to do in the insurance industry. So a good example is you know we have a lot of tooling for long context retrieval and extracting information from uh you know really really challenging uh document sets. Um we have a tool for you know doing human reasoning over lots of rules. We have a tool for you know writing back into a lot of the sort of like mission critical vertical uh systems of record. And then similarly a lot of you know our customers deal with systems that don't have APIs. Um either they haven't built been built out yet or you know they might not even own that end system because it's you know some some intermediary. Um think like a broker working with a carrier portal. And there you know we actually just use web agents to be able to sort of write back to this. And so that's the critical part that I think a lot of the the FD work drives is like building out these these tools with our customers to make them uh to be able to get these these agents live. And the critical thing is sort of doing whatever it takes to get them live. And you know, if there's the AP if there's an API, we'll use the API. If there isn't, we're going to use the web agents. We're going to make them successful. Um and then the last thing is sort of getting live into production from there. And so, you know, we've been been lucky with a lot of our customers. We've been, you know, we're working on again in the context of their most mission critical use cases. A lot of cases, we have been their fastest company ever to PSC and their fastest company ever to production. &gt;&gt; That's been awesome to see. &gt;&gt; That's just going on site and spending time with them. &gt;&gt; As you build these agent workflows, technologies come a long way over the last even 12 months here, but I'm curious what's on your wish list for things that you wish were easier or what you want to come next. &gt;&gt; Yeah. Um, you know, I think we're we've definitely like benefited a ton from the the scaling curve of of reasoning models. Um, particularly for our kind of very complex documents that we we handle and that is, you know, not 100% solved problem, but for us a lot of the document attraction stuff we are able to get, you know, much better than human reliability. The next frontier I think really for us is is is web agents. Um and so yeah, for any folks listening from the big labs here, we'd love uh the best possible web agents, please send them our way. Uh we are really really lucky to, you know, be a company I think is running a lot of those workflows and has a lot of really great use cases in insurance. It's sort of like the canonical kind of like task is you're basically doing CRUD operations on insurance admin panels. M I'll be honest they look very different from like booking a restaurant or booking a flight or a lot of the sort of like web agent demos that we see and so a lot of our work is just making those successful so web agents would be really great and I think the last one is sort of thinking about uh longer terms so the opportunity for RL and reinforcement fine-tuning in what we do um because of the way that we've structured our product and because we are you know long AI and what it can do um longer term, you know, our our product is set up in a way where it's not sort of this workflow diagram builder which where you know the AI agent only has context for you know that individual block that it's in and you would never you know the the analogy I draw here is like if you had your best you know person on your team you're not going to like put them in this in this box and be like okay you need to categorize you know these documents and not have any sense of what happened before or after in the workflow. And so what we've really built into the product is the AI being able to make the decisions end to end and follow these these agent operating procedures. And so what that means longer term is it really sets us up well to benefit a lot from RL. Um because the agents are are working from input all the way through to output in a way that is highly gradable where you can see kind of the accuracy of of the work that's being done. there's an expected output that you can grade against and create a reward function. It makes it very very easy to uh to actually do RL for each of these individual workflows for our individual customer at scale. And so I think if you think about kind of the long term of the product, it's not codifying all this stuff into determinism to try to make the agent successful. it's really giving the agent sort of this perfectly modeled world that it can work in and being able to do sort of RO on end to end um across all the tool calls. And so I think that's one of the big wish lists um and sort of areas that we see the world going. &gt;&gt; What has surprised you about building with AI or what advice would you have for other founders who are building in AI or thinking about doing so? I &gt;&gt; think two things have surprised me. One is how much fun it is. I mean this is like such a great time to be building and there's all this stuff you people talk about being able to build faster with AI and certainly that's the case you know we're lucky we use a lot you know the cursors and cloud codes and codeexes that help our team be really really successful but even more than that there's all this stuff that was like really hard to codify in software &gt;&gt; that is now really like easy to codify with LM &gt;&gt; u and so like we've been able to just build workflows that like traditionally I think would have taken you know decades to build the software and all the sort of knobs and dials and requirements to sort of get those live in production because you can offload a lot of that to the agent. &gt;&gt; Uh so it's a really fun time to be building. Um the second thing I think it's really really important uh and maybe it's some advice for founders is to go be a forward deployed engineer and ideally come do a pace but I really do think that is like the best training ground for uh for becoming a founder because you go and spend a lot of time with customers you see you know their problems and you help them get it into production and that's you know really at companies like you're either building or you're selling and for deploy deployed engineers should you do both. Um, so that's my that's my big advice. If you're thinking about starting a company, it will get you close to problems. It'll get you working on the right stuff and you'll build the right skill sets to to build the company. &gt;&gt; I was very lucky without a retool. I think uh, you know, I was very fortunate. I think both David uh Sher, our CEO, and Brian Shrier, uh who's lucky we're lucky to be working with again on Pace, uh really were very kind to sort of take a big bet on me um early on at at Retool to sort of figure out how do we build out our our post sales motion? How do we take a lot of our new products, you know, from zero to 100? And uh I think that really really set me up to start a company in a way where you know the it is it's never easy but it has felt much much more tractable this time than the first time I started a company. And I think that is yeah I'm very very grateful for that. Um and I I encourage other folks to sort of like find that that that path and find people like that that will kind of um uh back you again and again and um yeah feel very fortunate for that. &gt;&gt; Awesome. Shall we do some hot takes? &gt;&gt; Let's do it. &gt;&gt; Okay. What was your hot take from interning at Sequoia? What did you learn? &gt;&gt; Other than Andrew Reed's love of constellations. &gt;&gt; Um, I'm not sure if you remember this one, Pat, but we were out on the, you know, like the back patio in the 2800 office, and I think you asked me a similar question, which was sort of, what did you find most surprising about Sequoia? And uh my answer then is still my answer today. Uh which is uh Sequoia is a place that has benefited an incredible amount of success, but no one ever rests on their laurels here. Uh we were very lucky to be incubated out of Sequoa's office in in New York. And every time you walk out of the elevators, there's this sort of graphic that's going on on the screen there that says we're only as good as our next investment. And it's awesome. Like I I just love that mentality. And I think that's like one thing that should permeates also over to our culture at Pace is just like, you know, every quarter you're set back to zero. Every new customer, you got to make them successful. I mean, they care that you've done this in the past, but like you're really meant to, you know, like you got to make them successful. And so, you know, you're only as good as your next customer. &gt;&gt; Love it. Love it. &gt;&gt; All right. Company number two. What are you doing differently this time? &gt;&gt; I think there's a couple of learnings. um that I think have been pretty critical this time and there's a couple things we've done the same which &gt;&gt; great &gt;&gt; were also great. Um so one of the ones that um I feel like I was very lucky to learn at RTOL is one of Retool's values was Retool as a business. Um and basically you know retool was very focused on delivering value for our customers and revenue and I think we take a very similar perspective which is you know there's a lot of things you can do when you're starting a company and a lot of them are kind of distractions. M &gt;&gt; um you know like most times fundraising distraction most times like um you know uh working with like I don't know employers or sitting at the office or whatever a lot of these things can be like kind of retraction like you want to make them run but you want to be spending as much as time as possible working with your customer and so that's like one of my biggest takeaways is just go and you can't spend too much time on that uh working with your customer, making them successful and focusing on moving the metrics that really matter, which is revenue growth, gross margins, a lot of the things that we think a lot about. Um, I think the other big thing is who you work with. Um, and uh, I was incredibly lucky in my last company, I have an amazing co-founder. Um, and this time, uh, with Pace, I actually started the company as a solo founder and have this incredible team that we've been able to build. And it was one one interesting thing. This is a hot take. Uh people like really or there's like a sentiment that I think people don't really like solo founders generally seeking as like a as like an investment. And I actually think that makes complete sense when you're at the very early stages, you know, the sort of like existential stages of a company because you you know makes a lot of sense to have a co-founder there to like help you through, you know, wandering the desert or whatever and making making the company successful. Um and very thankful to my co-founder for that. my last company. But once you have figured out exact you know where you're going and it's all execution risk like for pace everything is execution risk now like it's so clear what we're doing it's just executing &gt;&gt; uh you there are a lot of benefits of of starting a company solar founder and the team that you can build. So we've been super lucky. Um you know our first engineer was like Rachel's second engineer got Yogi. Second hire was um uh also in the Sequoia portfolio. Luis who was head of corporate engineering at Loom and both of them and all also our broader team you they take on a lot of the roles that uh in the sort of capacity that I think traditionally might have been kind of just a conversation with like a co-founder where you don't actually like involve the team. So like a lot of our team was involved in you know shaping our values. A lot of the team is involved in uh critical go to market hires. A lot of our team is involved in product decision-m that might traditionally have just been made by by co-founders. I think it actually lets you hire a much much stronger team and build a a stronger culture. &gt;&gt; And the last thing that we definitely kept the same is working uh working with Sequoa and working with uh with Ryan you Lauren has been fantastic and I'm very very thankful for that. I think one of the amazing things is being able to work with a partner that has known you almost, you know, over a decade. Um, you know, I was lucky to meet Brian when I was still in college. Uh, and I think, you know, this this is kind of a funny story how how we met was, uh, Brian gave this talk and the talk was basically about how uh, like mentoring and, uh, how to sort of like build these sort of great mentor relationships. I think his advice was basically like lead with value and then you'll figure out kind of like how to um how to go from there like kind of giving up front basically. And I think at the time he dropped this like small Easter egg of hey I'm actually going to the Princeton campus to talk with the uh like the Princeton president about you know entrepreneurship on on campus and I'd love to know what to say. And so you know I kind of was like interesting. I think I could probably help with that. So, I pulled an all nighter and basically sent him this like 20-page report of, you know, here's where we think where I think, you know, Princeton entrepreneurship could uh could use your help. And that became, you know, a lot of what, you know, he's since seen basically every step of my career along the way. Um, you know, from from Zoya to starting my first company to Retool and going to many board meetings where I learned a ton from him. Um, all the way through to starting this company. and to be able to have amazing partners like like like Brian like you Lauren where we can you have a really strong sort of board uh relationship where it's sort of almost feels like that sort of like co-founder relationship where much like in the trenches together I think is incredibly unique to me and I think makes uh Pace a much stronger company because of it. &gt;&gt; Thank you for joining the show. It's been amazing to have you and hear the full story behind Pace that's just beginning. &gt;&gt; Thank you for having me. This is a blast.